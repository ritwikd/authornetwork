"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&queryText%3D.LB.Publication+Title%3A+Hardware%2FSoftware+Codesign+and+System+Synthesis+.LB.CODES.PLS.ISSS.RB.%2C+2014+International+Conference+on.RB.",2015/07/23 13:46:57
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN","ISBN","EISBN","DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Prediction and control of bursty cloud workloads: A fractal framework","Ghorbani, M.; Yanzhi Wang; Yuankun Xue; Pedram, M.; Bogdan, P.","Electr. Eng. Dept., Univ. of Southern California, Los Angeles, CA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","9","Cloud Computing is a promising approach to handle the growing needs for computation and storage in an efficient and cost-effective manner. Towards this end, characterizing workloads in the cloud infrastructure (e.g., a data center) is essential for performing cloud optimizations such as resource provisioning and energy minimization. However, there is a huge gap between the characteristics of actual workloads (e.g., they tend to be bursty and exhibit fractal behavior) and existing cloud optimization algorithms, which tend to rely on simplistic assumptions about the workloads. To close this gap, based on fractional calculus concepts, we present a fractal model to account for the complex dynamics of cloud computing workloads (i.e., the number of request arrivals or CPU/memory usage during each time interval). More precisely, we introduce a fractal operator to account for the time-varying fractal properties of the cloud workloads. In addition, we present an efficient (online) parameter estimation algorithm, an accurate forecasting strategy, and a novel fractal-based model predictive control approach for optimizing the CPU utilization, and hence, the overall energy consumption in the system while satisfying networked architecture performance constraints like queue capacities. We demonstrate advantages of our fractal model in forecasting the complex cloud computing dynamics over conventional (non-fractal) models by using real-world cloud (Google) traces. Unlike non-fractal models, which have very poor prediction capabilities under bursty workload conditions, our fractal model can accurately predict bursty request processes, which is crucial for cloud computing workload forecasting. Finally, experimental results demonstrate that the fractal model based optimization outperforms the non-fractal based ones in terms of minimizing the resource utilization by an average of 30%.","","","","10.1145/2656075.2656095","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971828","Algorithms;Design;Management;Theory","Cloud computing;Computational modeling;Fractals;Mathematical model;Optimization;Predictive models;Servers","cloud computing;fractals;parameter estimation;power aware computing;predictive control;resource allocation","CPU utilization;CPU-memory usage;Google;bursty request processes;bursty workload conditions;cloud computing workload control;cloud computing workload forecasting;cloud computing workload prediction;cloud infrastructure;cloud optimization algorithms;complex cloud computing dynamics forecasting;energy consumption;energy minimization;forecasting strategy;fractal behavior;fractal framework;fractal model based optimization;fractal operator;fractal-based model predictive control approach;fractional calculus concepts;networked architecture performance constraints;nonfractal models;parameter estimation algorithm;queue capacities;real-world cloud traces;resource provisioning;resource utilization;time-varying fractal properties","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"A framework of awareness for artificial subjects","Jantsch, A.; Tammemae, K.","Vienna Univ. of Technol., Vienna, Austria","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","3","We review the concepts of environment-and self-models, semantic interpretation, semantic attribution, history, goals and expectations, prediction, and self-inspection, how they contribute to awareness and self-awareness, and how they contribute to improved robustness and sensibility of behavior. Researchers have for some time realized that a sense of “awareness” of many embedded systems' own situation is a facilitator for robust and dependable behaviour even under radical environmental changes and drastically diminished capabilities. This insight has recently led to a proliferation of work on self-awareness and other system properties such as self-organization, self-configuration, self-optimization, self-protection, self-healing, etc., which are sometimes subsumed under the term “self-*”.","","","","10.1145/2656075.2661644","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971836","","Educational institutions;Engines;History;Monitoring;Predictive models;Robustness;Semantics","artificial intelligence;embedded systems;fault tolerant computing;optimisation","artificial subject awareness;embedded systems;environment model;self-awareness;self-healing;self-model;self-optimization;semantic attribution;semantic interpretation","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"HEFT: A hybrid system-level framework for enabling energy-efficient fault-tolerance in NoC based MPSoCs","Yong Zou; Pasricha, S.","Dept. of Electr. & Comput. Eng., Colorado State Univ., Fort Collins, CO, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","In emerging CMOS process technologies, network-on-chip (NoC) fabrics are increasingly becoming susceptible to transient faults. Fault-tolerance mechanisms that are typically employed in NoCs usually entail significant energy overheads that are expected to become prohibitive as fault rates increase in future CMOS technologies. We propose a system-level framework called HEFT to trade-off energy consumption and fault-tolerance in the NoC fabric. Our hybrid framework tackles the challenge of enabling energy-efficient resilience in NoCs in two phases: at design time and at runtime. At design time, we implement an algorithm to guide the robust mapping of cores on to a die while satisfying application bandwidth and latency constraints. At runtime we devise a prediction algorithm to monitor and detect changes in fault susceptibility of NoC components, to intelligently balance energy consumption and reliability. Experimental results show that HEFT improves energy/reliability ratio of synthesized solutions by 8-20%, while meeting application performance goals, when compared to multiple prior works on reliable system-level NoC design.","","","","10.1145/2656075.2656087","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971820","System-level design;fault-tolerance;networks-on-chip","Bandwidth;Fault tolerance;Fault tolerant systems;Reliability engineering;Runtime;Tunneling magnetoresistance","CMOS integrated circuits;energy conservation;energy consumption;fault tolerance;integrated circuit design;integrated circuit reliability;multiprocessing systems;network-on-chip;transient analysis","CMOS process technology;CMOS technology;HEFT;NoC based MPSoC;NoC component;NoC fabric;application bandwidth;energy consumption;energy-efficient fault-tolerance;energy-efficient resilience;fault rate;fault susceptibility;fault-tolerance mechanism;hybrid system-level framework;latency constraint;network-on-chip fabric;prediction algorithm;reliability;reliable system-level NoC design;robust mapping;transient fault","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Improving formal timing analysis of switched ethernet by exploiting traffic stream correlations","Thiele, D.; Axer, P.; Ernst, R.; Seyler, J.R.","Inst. of Comput. & Network Eng., Tech. Univ. Braunschweig, Braunschweig, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Ethernet networks become increasingly popular in many distributed, embedded application domains. In safety-critical real-time systems, such as industrial control or driver assistance systems, formal performance analysis methods are required to verify the timing, e.g. by providing upper bounds on end-to-end latencies. These formal methods, however, often rely on overapproximations to keep the computational complexity at a tractable level. In distributed systems, these overapproximations can accumulate leading to overly conservative timing guarantees. Switched networks, such as Ethernet (especially with large topologies), are particularly prone to this effect. In this paper, we identify timing correlations between traffic streams in Ethernet networks and show how they can be exploited by a formal analysis to derive timing guarantees, which are up to 80% tighter.","","","","10.1145/2656075.2656090","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971831","Ethernet;automotive Ethernet;formal performance analysis;real-time systems","Abstracts;Switches;Timing","approximation theory;computational complexity;local area networks;real-time systems;telecommunication traffic;timing","computational complexity;distributed embedded application domains;distributed systems;end-to-end latencies;formal performance analysis methods;formal timing analysis;overapproximations;safety-critical real-time systems;switched Ethernet networks;timing correlations;traffic stream correlations","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"From self-aware building blocks to self-organizing systems with hierarchical agent-based adaptation","Liang Guang; Plosila, J.; Tenhunen, H.","Univ. of Turku, Turku, Finland","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","3","How to develop a self-aware system from modularized design components is a major challenge on this theme. The authors introduce a hierarchical agent-based system architecture, which enables self-organization and self-adaptation upon parallel embedded systems. Self-organization is achieved by dynamic clusterization, which groups self-aware components into a cluster and continuously updates the organization to account for application changes and internal errors. Self-adaptation is performed by hierarchical agents, based on the run-time organization, to monitor corresponding levels of components and reconfigure the system to improve ture achieves functional scalability via partitioning of agent ware/hardware co-design of agents.","","","","10.1145/2656075.2661646","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971839","embedded computing systems;hierarchical agent-based adaptation;self-awareness;self-organization","Abstracts;Hardware","embedded systems;hardware-software codesign;parallel architectures;power aware computing","agent intelligence;dynamic clusterization;energy efficiency;hierarchical agent-based adaptation;hierarchical agents;level-specific software-hardware co-design;modularized design components;parallel embedded systems;physical scalability;run-time organization;self-adaptation;self-aware building blocks;self-aware components;self-organization;self-organizing systems","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Code generation from a domain-specific language for C-based HLS of hardware accelerators","Reiche, O.; Schmid, M.; Hannig, F.; Membarth, R.; Teich, J.","Dept. of Comput. Sci., Friedrich-Alexander Univ. Erlangen-Nurnberg (FAU), Erlangen, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","As today's computer architectures are becoming more and more heterogeneous, a plethora of options including CPUs, GPUs, DSPs, reconfigurable logic (FPGAs), and other application-specific processors come into consideration for close-to-sensor processing. Especially, in the domain of image processing on mobile devices, among numerous design challenges, a very stringent energy budget is of utmost importance, making embedded GPUs and FPGAs ideal targets for implementation. Recently, the HIPA<sup>cc</sup> framework was proposed as a means for automatic code generation of image processing algorithms for embedded GPUs, based on a Domain-Specific Language (DSL). Despite of huge advancements in High-Level Synthesis (HLS) for FPGAs, designers are still required to have detailed knowledge about coding techniques and the targeted architecture to achieve efficient solutions. As a remedy, in this work, we propose code generation techniques for C-based HLS from a common high-level DSL description targeting FPGAs. Our approach includes FPGA-specific memory architectures for handling point and local operators, numerous high-level transformations, and automatic test bench generation. We evaluate our approach by comparing the resulting hardware accelerators to existing frameworks in terms of performance and resource requirements. Moreover, we assess the achieved energy efficiency in contrast to software implementations, generated by HIPA<sup>cc</sup> from the same code base, executed on GPUs.","","","","10.1145/2656075.2656081","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971833","Code generation;FPGA;GPU;domain-specific language;hardware accelerator;high-level synthesis;image processing","Computer architecture;DSL;Field programmable gate arrays;Hardware;Image processing;Kernel;Laplace equations","field programmable gate arrays;graphics processing units;high level synthesis;image processing;memory architecture;multiprocessing systems;program compilers","C-based HLS;CPU;DSL;DSP;FPGA-specific memory architectures;HIPA;automatic code generation techniques;coding techniques;computer architectures;domain-specific language;embedded GPU;hardware accelerators;high-level synthesis;image processing algorithms;mobile devices;reconfigurable logic","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"DAARM: Design-time application analysis and run-time mapping for predictable execution in many-core systems","Weichslgartner, A.; Gangadharan, D.; Wildermann, S.; Glass, M.; Teich, J.","Friedrich-Alexander-Univ. Erlangen-Nurnberg (FAU), Erlangen, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Future many-core systems are envisaged to support the concurrent execution of varying mixes of different applications. Because of the vast number of binding options for such mixes on heterogeneous resources, enabling predictable application execution is far from trivial. Hybrid application mapping is an efficient way of achieving run-time predictability by combining design-time analysis of application mappings with run-time management. Existing hybrid mapping strategies focus on computation resources and either ignore communication details or make significantly simplifying assumptions like unlimited bandwidth or exclusive usage. But, actual many-core systems consist of constrained and shared computation and communication resources where the run-time decision of whether a feasible application binding on a set of preoccupied resources exists or not is an NP-complete problem. As a remedy, we present a novel hybrid application mapping approach that considers constrained shared communication and computation resources. Here, (a) a design space exploration coupled with a formal performance analysis delivers several resource reservation configurations with verified real-time guarantees for each individual application. The configurations are then transformed to (b) a novel efficient intermediate representation that is passed to the run-time management where we (c) formulate run-time resource reservation and application binding as a constraint satisfaction problem and present an adequate solving mechanism. Our experimental evaluation shows that existing approaches may produce infeasible outcomes and are thus not applicable for predictable application execution, while the proposed approach enables predictable and efficient run-time management of dynamic application mixes.","","","","10.1145/2656075.2656083","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971850","dse;hybrid mapping;many-core;networks-on-chip;predictability","Availability;Bandwidth;Energy consumption;Performance analysis;Real-time systems;Routing;Space exploration","computational complexity;concurrency control;constraint satisfaction problems;multiprocessing systems;performance evaluation;resource allocation","DAARM;NP-complete problem;application binding;computation resources;concurrent execution;constrained shared communication;constrained shared computation;constraint satisfaction problem;design space exploration;design-time application analysis and run-time mapping;formal performance analysis;hybrid application mapping approach;many-core systems;predictable execution;run-time decision;run-time management;run-time resource reservation","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Generating situation awareness in cyber-physical systems: Creation and exchange of situational information","Preden, J.","Res. Lab. for Proactive Technol., Tallinn Univ. of Technol., Tallinn, Estonia","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","3","Cyber-physical systems depend on good situation awareness in order to cope with the changes of the physical world and in the configuration of the system to fulfill their goal functions. Being aware of the situation in the physical world enables a cyber-physical system to adapt its behaviour according to the actual state of the world as perceived by the cyber-physical system. Understanding the situation of the cyber-physical system itself enables adaptation of the behaviour of the system according to the current capabilities and state of the system, e.g., providing less features or features with limited functionality in case some of the system components are not functional. In order to build resilient cyber-physical systems we need to build systems that are able to consider both of these aspects in their operation.","","","","10.1145/2656075.2661647","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971837","cyber physical system;situation awareness","Context;Embedded systems;Mediation;Sensor systems;Systems engineering and theory","middleware","ProWare;cyber-physical systems;distributed proactive middleware;situation awareness generation;situational information;system component functionality","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Dark silicon as a challenge for hardware/software co-design","Shafique, M.; Garg, S.; Mitra, T.; Parameswaran, S.; Henkel, J.","Dept. of Embedded Syst., Karlsruhe Inst. of Technol., Karlsruhe, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Dark Silicon refers to the observation that in future technology nodes, it may only be possible to power-on a fraction of on-chip resources (processing cores, hardware accelerators, cache blocks and so on) in order to stay within the power budget and safe thermal limits, while the other resources will have to be kept powered-off or “dark”. In other words, chips will have an abundance of transistors, i.e., more than the number that can be simultaneously powered-on. Heterogeneous computing has been proposed as one way to effectively leverage this abundance of transistors in order to increase performance, energy efficiency and even reliability within power and thermal constraints. However, several critical challenges remain to be addressed including design, automated synthesis, design space exploration and run-time management of heterogeneous dark silicon processors. The hardware/software co-design and synthesis community has potentially much to contribute in solving these new challenges introduced by dark silicon and, in particular, heterogeneous computing. In this paper, we identify and highlight some of these critical challenges, and outline some of our early research efforts in addressing them.","","","","10.1145/2656075.2661645","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971829","","Computer architecture;Hardware;Program processors;Reliability;Silicon;Switches","hardware-software codesign;power aware computing","automated synthesis;design space exploration;energy efficiency improvement;hardware-software co-design;heterogeneous computing;heterogeneous dark silicon processors;on-chip resources;performance improvement;power budget;power constraint;reliability improvement;run-time management;safe thermal limits;thermal constraint;transistors","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"An efficient technique for computing importance measures in automatic design of dependable embedded systems","Aliee, H.; Glass, M.; Khosravi, F.; Teich, J.","Friedrich-Alexander-Univ. Erlangen-Nurnberg, Erlangen, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Importance measure analysis judges the relative importance of components in a system and reveals how each component contributes to the system reliability. In the design of large and complex systems, importance measure analysis can therefore be employed to guide an optimization tool which design decisions to investigate to gain higher reliability. While previous research has mainly concentrated on developing analytical importance measure techniques, the automatic and frequent computing of importance measures as required in the context of design space exploration has got very few, if any attention. This paper presents a highly efficient technique to compute the reliability and structural importance measures of components of a system. The proposed technique considers the reliability of a system implementation and subsequently analyzes the importance measures of its components based on a state-of-the-art Monte Carlo simulation. The technique can therefore estimate the importance measures of all components concurrently, highly improving the performance of the computation compared, e. g., to the well-known Birnbaum approach by the factor of 2n with n being the number of components. Moreover, we show how this algorithm can be extended to support importance measure analysis in the existence of transient faults which is essential since in future systems, transient faults are expected to cause relatively more failures than permanent faults. We integrated the proposed analysis approach in an existing multi-objective local-search algorithm that is part of an automatic system-level design space exploration which seeks for system implementations with highest reliability at lowest possible cost. Experimental results show that the proposed algorithm performs efficiently with negligible imprecision, even for large realworld examples.","","","","10.1145/2656075.2656079","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971819","","Algorithm design and analysis;Boolean functions;Hardware;Reliability engineering;Space exploration;Transient analysis","importance sampling;search problems","Birnbaum approach;Monte Carlo simulation;automatic design;automatic system-level design space exploration;complex system;dependable embedded systems;importance measure analysis;importance measure techniques;large system;multiobjective local-search algorithm;optimization tool;permanent fault;structural importance measures;system implementation;system reliability;transient fault","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Fault-aware application scheduling in low-power embedded systems with energy harvesting","Yi Xiang; Pasricha, S.","Dept. of Electr. & Comput. Eng., Colorado State Univ., Fort Collins, CO, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","In this paper, we propose a hybrid design-time and run-time framework for reliable resource allocation, i.e., mapping and scheduling of applications, in multi-core embedded systems with solar energy harvesting. Our framework is designed to cope with the complexity of an application model with data dependencies and run-time variations in solar radiance, execution time, and transient faults, with support for flexible schedule templates at design-time, and lightweight online adjustment mechanisms to monitor run-time dynamics and make adjustments to task execution strategy. Our experimental results indicate improvements in performance and adaptivity using our framework, with up to 29.5% miss rate reduction compared to prior work and 55% performance benefits from adaptive run-time workload management, under stringent energy constraints and varying system conditions at run-time.","","","","10.1145/2656075.2656084","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971848","Energy Harvesting;Soft Errors;Task Scheduling","Embedded systems;Energy harvesting;Program processors;Reliability;Schedules;Solar energy;Timing","embedded systems;energy harvesting;fault tolerant computing;multiprocessing systems;power aware computing;processor scheduling;resource allocation","adaptive run-time workload management;application mapping;energy harvesting;execution time;fault-aware application scheduling;lightweight online adjustment mechanisms;low-power embedded systems;miss rate reduction;multicore embedded systems;resource allocation;run-time dynamics monitoring;solar energy harvesting;solar radiance;transient faults","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Job arrival rate aware scheduling for asymmetric multi-core servers in the dark silicon era","Raghunathan, B.; Garg, S.","Dept. of Electr. & Comput. Eng., Univ. of Waterloo, Waterloo, ON, Canada","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","9","The rate at which jobs arrive for processing at servers in a data-center (i.e., the job arrival rate) can vary significantly with time. Each server in a data-center is a multi-core processor, allowing jobs to be processed with different degrees of parallelism (DoPs) (i.e., number of threads per job). In this paper, we show both analytically and empirically that the optimal DoP that minimizes mean service time varies with job arrival rate. In addition, we show that for asymmetric multi-core server processors (i.e., processors with multiple clusters, each consisting of cores of a different type, and assuming that only one cluster is active at any given time while the others are dark), the best cluster to select is also dependent on job arrival rate. Based on these observations, we propose a run-time scheduler that determines the optimal DoP and performs inter-cluster migration to minimize mean service time within a power budget. Experimental results demonstrate significant reduction in mean service time compared to job arrival rate unaware schedulers.","","","","10.1145/2656075.2656091","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971830","","Analytical models;Benchmark testing;Multicore processing;Program processors;Queueing analysis;Servers;Silicon","computer centres;multiprocessing systems;processor scheduling","DoP;asymmetric multicore server;dark silicon era;data-center;degrees of parallelism;inter-cluster migration;job arrival rate aware scheduling;job arrival rate unaware scheduler;mean service time;multicore processor;multicore server processor;run-time scheduler","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"TSP: Thermal Safe Power - Efficient power budgeting for many-core systems in dark silicon","Pagani, S.; Khdr, H.; Munawar, W.; Jian-Jia Chen; Shafique, M.; Minming Li; Henkel, J.","Dept. of Embedded Syst., Karlsruhe Inst. of Technol., Karlsruhe, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Chip manufacturers provide the Thermal Design Power (TDP) for a specific chip. The cooling solution is designed to dissipate this power level. But because TDP is not necessarily the maximum power that can be applied, chips are operated with Dynamic Thermal Management (DTM) techniques. To avoid excessive triggers of DTM, usually, system designers also use TDP as power constraint. However, using a single and constant value as power constraint, e.g., TDP, can result in big performance losses in many-core systems. Having better power budgeting techniques is a major step towards dealing with the dark silicon problem. This paper presents a new power budget concept, called Thermal Safe Power (TSP), which is an abstraction that provides safe power constraint values as a function of the number of simultaneously operating cores. Executing cores at any power consumption below TSP ensures that DTM is not triggered. TSP can be computed offline for the worst cases, or online for a particular mapping of cores. Our simulations show that using TSP as power constraint results in 50.5% and 14.2% higher average performance, compared to using constant power budgets (both per-chip and per-core) and a boosting technique, respectively. Moreover, TSP results in dark silicon estimations which are more optimistic than estimations using constant power budgets.","","","","10.1145/2656075.2656103","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971826","","Boosting;Multicore processing;Power demand;Steady-state;Temperature measurement;Thermal conductivity;Vectors","integrated circuit design;integrated circuit manufacture;power aware computing;thermal management (packaging)","DTM;TDP;TSP;chip manufacturers;constant power budgets;cooling solution;dark silicon;dynamic thermal management techniques;efficient power budgeting;many-core systems;performance losses;power budgeting techniques;power constraint;safe power constraint values;thermal design power;thermal safe power","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Tackling QoS-induced aging in exascale systems through agile path selection","Ancajas, D.M.; Chakraborty, K.; Roy, S.; Allred, J.","USU BRIDGE Lab., Utah State Univ., Logan, UT, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Network-On-Chips (NoCs) have become the standard communication platform for future massively parallel systems due to their performance, flexibility and scalability advantages. However, reliability issues brought about by scaling in the sub-20nm era threaten to undermine the benefits offered by NoCs. In this paper, we showthat QoS policies exacerbate the reliability profile of an exascale system. To mitigate this imposing challenge, we propose Dynamic Wearout Resilient Routing (DWRR) algorithms in QoS-enabled exascale NoCs. Our proposal includes two novel DWRR algorithms enabled by a critical-pathmonitor and a broadcast-based routing configuration. Using PARSEC benchmarks, our best algorithm improves QoS and long-term sustainability (Mean Time To Failure) of the system by an average of 16% and 25% compared to a state-of-the-art fault tolerant technique, respectively.","","","","10.1145/2656075.2656100","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971832","","Bandwidth;Degradation;Delays;Heuristic algorithms;Quality of service;Reliability;Routing","ageing;fault tolerant computing;network-on-chip;parallel programming;quality of service;reliability","DWRR algorithms;NoC;PARSEC benchmarks;QoS;agile path selection;aging;broadcast-based routing;dynamic wearout resilient routing algorithms;exascale systems;fault tolerant technique;network-on-chips;parallel systems;reliability","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Towards scalable symbolic routing for multi-objective networked embedded system design and optimization","Graf, S.; Reimann, F.; Glass, M.; Teich, J.","Friedrich-Alexander-Univ. Erlangen-Nurnberg, Erlangen, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Symbolic encoding for resource allocation, task binding, and message routing during multi-objective design space exploration (DSE) has gained significant attention in recent years. To determine the message routing, existing symbolic approaches typically rely on an explicit encoding of routing hops which results in a huge number of required variables and/or constraints. As a result, these approaches fail in case of large network diameters and/or a huge number of messages or resources and even for smaller problems, the convergence of the involved optimization process suffers. To tackle this shortcomings, this work proposes three novel symbolic routing encoding strategies that all avoid to encode hops explicitly, but are based on an encoding of individual links or complete sender-receiver paths, but still cover the same design space. The result is a more compact problem representation with less constraints and, in particular, less variables; the latter eliminates ineffective degrees of freedom from the search space and significantly enhances the optimization quality of a multi-objective optimization with even non-linear objectives. In an extensive test-suite, three major classes of wired networked embedded systems are considered: (a) hierarchical stars as in MPSoCs or automotive, (b) redundant backbone buses as common in rail systems or avionics, and (c) mesh-based architectures that often occur in NoC-based MPSoCs. For all three classes, the proposed approaches significantly outperform existing techniques in both scalability and optimization quality and, thus, considerably enlarge the field of application of a multi-objective DSE for the networked embedded system design.","","","","10.1145/2656075.2656102","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971818","","Embedded systems;Encoding;Optimization;Receivers;Resource management;Routing;Scalability","embedded systems;encoding;optimisation;resource allocation;routing protocols;system-on-chip","(DSE);MPSoCs;Multi-Objective Networked Embedded System;NoC-based MPSoCs;Optimization;Scalable Symbolic Routing;Symbolic encoding;avionics;complete sender-receiver paths;design space explo- ration;mesh-based architectures;message routing;multi-objective optimization;rail systems;resource allocation;search space;symbolic routing encoding strategies","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Policy-based message scheduling using FlexRay","Mundhenk, P.; Sagstetter, F.; Steinhorst, S.; Lukasiewycz, M.; Chakraborty, S.","TUM CREATE, Singapore, Singapore","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","This paper proposes a virtual communication layer for time-triggered networks, enabling a policy-based message scheduling as well as preemption which in turn simplifies real-time verification. The introduced layer is particularly advantageous in the automotive domain since it reduces the complexity of scheduling time-triggered communication systems and simplifies incremental changes of existing schedules. We propose a framework to schedule event-triggered messages based on a predefined policy in time-triggered communication slots, improving the network utilization while logically separating messages from different devices. Furthermore, we enhance the versatility of the system, allowing to transmit data that exceeds the size of one time-triggered slot. The proposed policy-based scheduling with fixed priorities enables the integration of mixed criticality applications in time-triggered networks, while ensuring hard deadline constraints. A prototypical implementation is provided for FlexRay, complying with the existing protocol and, thus, making it possible to coexist with the standard transmission scheme. Our experimental results demonstrate the advantages of the virtual layer, showing an increase in flexibility and significantly lower message latencies in case of asynchronous communication.","","","","10.1145/2656075.2656094","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971835","FlexRay;scheduling","Dynamic scheduling;Runtime;Schedules;Time division multiple access;Time factors;Vehicles","automotive electronics;on-board communications;protocols;scheduling","FlexRay;asynchronous communication;automotive domain;event-triggered message scheduling;message latencies;network utilization;policy-based message scheduling;protocol;standard transmission scheme;time-triggered communication slots;time-triggered communication system scheduling;time-triggered networks;virtual communication layer","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"HSAemu - A full system emulator for HSA platforms","Jiun-Hung Ding; WeiChung Hsu; BaiCheng Jeng; ShihHao Hung; YehChing Chung","Nat. Tsing Hua Univ., Hsinchu, Taiwan","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Heterogeneous System Architecture (HSA) is an open industry standard designed to support a large variety of data-parallel and task-parallel programming models. Currently, most of HSA hardware and software components are still in development. It is helpful to provide various heterogeneous simulation environments for HSA developers in developing HSA software stacks. This paper presents the design of HSAemu, a full system emulator for the HSA platform, and illustrates how those HSA features are implemented in the simulator. HSAemu provides an infrastructure of heterogeneous simulation environments by supporting required HSA features, including hUMA, hQ and HSAIL. Based on the infrastructure, HSAemu provide two simulation models, FastSim and DeepSim, for high-speed functional emulation and slow cycle-accurate simulation, respectively. In our preliminary experiments, HSAemu helps test a complete HSA software stack and profile system performance. Our case studies show that HSAemu is very useful as a hardware/software co-design tool for heterogeneous systems.","","","","10.1145/2656075.2656088","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971842","GPU simulation;HSA;parallel simulation","Computational modeling;Computer architecture;Graphics processing units;Hardware;Kernel;Synchronization","digital simulation;graphics processing units","DeepSim simulation model;FastSim simulation model;HSA hardware components;HSA platforms;HSA software components;HSA software stacks;HSAIL;HSAemu;data-parallel programming model;full-system emulator;hQ;hUMA;hardware/software co-design tool;heterogeneous simulation environments;heterogeneous system architecture;high-speed functional emulation;open industry standard;profile system performance;slow-cycle-accurate simulation;task-parallel programming model","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Workload-aware shaping of shared resource accesses in mixed-criticality systems","Tobuschat, S.; Neukirchner, M.; Ecco, L.; Ernst, R.","Inst. of Comput. & Network Eng., Tech. Univ. Braunschweig, Braunschweig, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","For mixed-criticality systems, safety standards (e.g. ISO 26262) require sufficient independence among different criticality levels, unless the entire system is certified according to the highest applicable level. We present a resource arbitration scheme that provides sufficient independence among different criticality levels w.r.t. timing properties. We exploit throughput and latency slack of critical applications by prioritizing non-critical over critical accesses and only switching priorities when necessary. By using an accurate representation of resource access patterns and workloads, the proposed arbitration scheme achieves an improved resource utilization compared to classical approaches that use simple access counters. The approach allows to provide service guarantees for critical applications, while reducing the adverse effects through strict prioritization on non-critical applications.","","","","10.1145/2656075.2656105","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971851","mixed-criticality;multicore;shared resource","Estimation;Interference;Monitoring;Safety;Switches;Throughput;Upper bound","resource allocation;safety-critical software;system monitoring","ISO 26262;access counter;critical applications;criticality level;latency slack;mixed-criticality systems;priority switching;resource access pattern;resource arbitration scheme;resource utilization;safety standards;service guarantee;shared resource access;strict prioritization;timing properties;workload-aware shaping","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"RunPar: An allocation algorithm for automotive applications exploiting runnable parallelism in multicores","Panic, M.; Kehr, S.; Quinones, E.; Boddecker, B.; Abella, J.; Cazorla, F.J.","Univ. Politec. de Catalunya (UPC), Barcelona, Spain","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Automotive applications increasingly rely on AUTOSAR for their design and execution. AUTOSAR applications comprise functions, called runnables, that are grouped into AUTOSAR tasks. Tasks are the unit of scheduling (UoS) of the AUTOSAR operating system as the legacy of the single-core platforms. However, on multi-core platforms using tasks as UoS considerably reduces the available parallelism due to communication dependencies, which in turn reduces the potential average and guaranteed performance obtainable with multi-cores. Furthermore, running tasks in parallel requires re-validating the functional correctness of the application, since current AUTOSAR applications are designed following a sequential execution model of tasks. In this paper, we propose a new allocation algorithm, RunPar, that considers runnables and not tasks as the UoS and assigns runnables that form tasks to different cores. RunPar improves the application performance, while keeping the sequential execution of tasks, hence not requiring any extra validation effort when migrating AUTOSAR applications from single-core to the multi-core platforms. We evaluate RunPar with a real automotive application, an Engine Management System (EMS) for which we observe an average WCET reduction on EMS' tasks of 26% and 30% in a two-core and four-core ECU.","","","","10.1145/2656075.2656096","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971845","","Automotive applications;Energy management;Multicore processing;Resource management;Timing","automotive electronics;multiprocessing systems;open systems;operating systems (computers);processor scheduling;resource allocation;software architecture","AUTOSAR operating system;ECU;RunPar;UoS;WCET reduction;allocation algorithm;automotive open system architecture;electronic control units;engine management system;multicore platforms;runnable parallelism;unit-of-scheduling","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Hardware/software co-design for a wireless sensor network platform","Chih-Ming Hsieh; Samie, F.; Srouji, M.S.; Manyi Wang; Zhonglei Wang; Henkel, J.","Embedded Syst. (CES), Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Wireless sensor networks have become shared resources providing sensing services to monitor ambient environment. The tasks performed by the sensor nodes and the network structure are becoming more and more complex so that they cannot be handled efficiently by traditional sensor nodes any more. The traditional sensor node architecture, which has software implementation running on a fixed hardware design, is no longer fit to the changing requirements when new applications with complex computation are added to this shared infrastructure due to several reasons. First, the operation behavior changes because of the application requirements and the environmental conditions which makes a fixed architecture not efficient all the time. Second, to collaborate with other already deployed sensor networks and to maintain an efficient network structure, the sensor nodes require flexible communication capabilities. Furthermore, the information required to determine an efficient hardware/software co-design under the system constraints cannot be known a priori. Therefore a platform which can adapt to run-time situations will play an important role in wireless sensor networks. In this paper, we present a hardware/software codesign framework for a wireless sensor platform, which can adaptively change its hardware/software configuration to accelerate complex operations and provides a flexible communication mechanism to deal with complex network structures. We perform real-world measurements on our prototype to analyze its capabilities. In addition, our case studies with prototype implementation and network simulations show the energy savings of the sensor network application by using the proposed design with run-time adaptivity.","","","","10.1145/2656075.2656086","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971817","FPGA;hardware accelerator;low power;multi-radio;reconfiguration;sensor networks","Abstracts;Computer architecture;Embedded systems;Hardware;Microcontrollers;Wireless sensor networks","hardware-software codesign;power aware computing;resource allocation;wireless sensor networks","complex network structure;energy savings;flexible communication capabilities;flexible communication mechanism;hardware-software codesign;hardware-software configuration;network simulations;real-world measurement;run-time adaptivity;sensor nodes;shared resources;system constraints;wireless sensor network platform","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"System-of-PUFs: Multilevel security for embedded systems","Choden Konigsmark, S.T.; Hwang, L.K.; Deming Chen; Wong, M.D.F.","Dept. of Electr. & Comput. Eng., Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Embedded systems continue to provide the core for a wide range of applications, from smart-cards for mobile payment to smart-meters for power-grids. The resource and power dependency of embedded systems continues to be a challenge for state-of-the-art security practices. Moreover, even theoretically secure algorithms are often vulnerable in their implementation. With decreasing cost and complexity, physical attacks are an increasingly important threat. This threat led to the development of Physically Unclonable Functions (PUFs) which are disordered physical systems with various applications in hardware security. However, consistent security oriented design of embedded systems remains a challenge, as most formalizations and security models are concerned with isolated physical components or high-level concept. We provide four unique contributions: (i) We propose a system-level security model to overcome the chasm between secure components and requirements of high-level protocols; this enables synergy between component-oriented security formalizations and theoretically proven protocols. (ii) An analysis of current practices in PUF protocols using the proposed system-level security model; we identify significant issues and expose assumptions that require costly security techniques. (iii) A System-of-PUF (SoP) that utilizes the large PUF design-space to achieve security requirements with minimal resource utilization; SoP requires 64% less gate-equivalent units than recently published schemes. (iv) A multilevel authentication protocol based on SoP which is validated using our system-level security model and which overcomes current vulnerabilities. Furthermore, this protocol offers breach recognition and recovery.","","","","10.1145/2656075.2656099","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971843","Hardware Authentication;Physically Unclonable Functions","Authentication;Computational modeling;Embedded systems;Hardware;Integrated circuit modeling;Protocols","cryptographic protocols;embedded systems;security","PUF design space;PUF protocols;SoP;breach recognition;component-oriented security formalizations;disordered physical systems;embedded systems;gate-equivalent units;hardware security;high-level protocols;mobile payment;multilevel authentication protocol;multilevel security;physically unclonable functions;power grids;resource utilization;security models;security techniques;smart cards;smart meters;system-level security model;system-of-PUF","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"On-chip self-awareness using Cyberphysical-Systems-on-Chip (CPSoC)","sarma, s.; Dutt, N.; Gupta, P.; Nicolau, A.; Venkatasubramanian, N.","Dept. of Comput. Sci., Univ. of California Irvine, Irvine, CA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","3","We presented CPSoC, a self-aware sensor-actuator-rich MPSoC platform that deploys the computation-communication-control codesign of CPS together with cross-layer adaptations to achieve multiple design objectives. The CPSoC paradigm enables on-chip self-awareness (selective or opportunistic) adaptation using the concepts of cross-layer physical and virtual sensing and actuations. In [3] we illustrate CPSoC's potential for self-awareness and cross-layer adaptations using several examples and have developed an FPGA prototype to emulate a typical CPSoC.","","","","10.1145/2656075.2661648","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971838","","Aging;Computer architecture;Delays;Predictive models;Quality of service;Sensors;System-on-chip","actuators;field programmable gate arrays;sensors;system-on-chip","CPSoC paradigm;FPGA prototype;control-communication-computing system codesign;cyberphysical-system-on-chip;on-chip cross-layer actuation;on-chip cross-layer sensing;on-chip self-awareness;on-chip sensing;physical environment;sensor-actuator rich many-core computing platforms","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"3M-PCM: Exploiting multiple write modes MLC phase change main memory in embedded systems","Chen Pan; Mimi Xie; Jingtong Hu; Yiran Chen; Chengmo Yang","Sch. of Electr. & Comput. Eng., Oklahoma State Univ., Stillwater, OK, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Multi-level Cell (MLC) Phase Change Memory (PCM) has many attractive features to be used as main memory for embedded systems. These features include low power, high density, and better scalability. However, there are also two drawbacks in MLC PCM, namely, limited write endurance and expensive write operation, that need to be overcome in order to practically adopt MLC PCM as main memory. In MLC PCM, two different types of write operations with very diverse data retention time are allowed. The first type maintains data for years, but takes longer time to write and hurts the endurance. The second type maintains data for a short period, but takes shorter time to write and hurts the endurance less. By observing that many data written to main memory are temporary and do not need to last long during the execution of a program, in this paper, we propose novel task scheduling and write operation selection algorithms to improve MLC PCM endurance and program efficiency. An Integer Linear Programming (ILP) formulation is first proposed to obtain optimal results. Since ILP takes exponential time to solve, we also propose a Multi-Write Mode Aware Scheduling (MMAS) heuristic to achieve near-optimal solution in polynomial time. The experimental results show that the proposed techniques can greatly improve the lifetime of MLC PCM as well as the efficiency of the program.","","","","10.1145/2656075.2656076","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971849","","Computer architecture;Nonvolatile memory;Optimal scheduling;Phase change materials;Resistance;Schedules;Scheduling","computational complexity;embedded systems;integer programming;linear programming;phase change memories;scheduling","3M-PCM;ILP formulation;MLC PCM;MLC phase change main memory;MMAS heuristic;data retention time;embedded systems;expensive write operation;integer linear programming formulation;limited write endurance;multilevel cell phase change memory;multiple write modes;multiwrite mode aware scheduling heuristic;polynomial time;task scheduling;write operation selection algorithms","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Cost-effective design of a hybrid electrical energy storage system for electric vehicles","Di Zhu; Siyu Yue; Sangyoung Park; Yanzhi Wang; Naehyuck Chang; Pedram, M.","Univ. of Southern California, Los Angeles, CA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","8","A comprehensive economic feasibility analysis and a cost-driven design methodology are essential to the successful application of hybrid electrical energy storage (HEES) systems in electric vehicles (EVs). This paper thus focuses on designing a cost-effective and high-performance HEES system for EVs, comprising of a supercapacitor bank and a lithium-ion (Li-ion) battery bank. In particular, the paper formulates the capacity provisioning problem for the EV HEES system so as to minimize the total system cost, utilizing accurate models of the battery cycle efficiency and state of health, characteristics of the supercapacitor bank, and dynamics of the EV. The aforesaid problem is subsequently solved by combining a gradient descent-based approach with a simulated annealing-based algorithm. Simulation results show that the proposed EV HEES system achieves 21% lower total cost per day and 30% higher fuel economy compared to a baseline homogeneous electrical energy storage system comprised of Li-ion batteries only.","","","","10.1145/2656075.2656082","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971847","Electric vehicles;cost efficiency;hybrid energy storage systems","Batteries;FCC;Power demand;Supercapacitors;System-on-chip;Vehicles","electric vehicles;gradient methods;secondary cells;simulated annealing;supercapacitors","HEES;battery cycle efficiency;cost effective design;economic feasibility analysis;electric vehicles;gradient descent based approach;hybrid electrical energy storage system;secondary battery bank;simulated annealing;state of health;supercapacitor bank","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Flattening-based mapping of imperfect loop nests for CGRAs?","Jongeun Lee; Seongseok Seo; Hongsik Lee; Hyeon Uk Sim","Sch. of ECE, Ulsan Nat. Inst. of Sci. & Technol. (UNIST), Ulsan, South Korea","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","For loop accelerators such as coarse-grained reconfigurable architectures (CGRAs) and GP-GPUs, nested loops represent an important source of parallelism. Existing solutions to mapping nested loops on CGRAs, however, are either designed for perfectly nested loops only, or expensive and inflexible. Efficient CGRA mapping of imperfect loops with arbitrary nesting depth still remains a challenge. In this paper we propose a compiler-hardware co-operative approach that is flexible and yet able to generate efficient mappings for imperfect nested loops. It is based on loop flattening, but to mitigate the negative impact of flattening we combine loop fission and a light-weight architecture extension that is designed to accelerate common operation patterns appearing frequently in flattened loops. Our experimental results using imperfect loops from multimedia and DSP domains demonstrate that our special operations can cover a large portion of nested loop operations, improve performance of nested loops by nearly 30% over using loop flattening only, and achieve near-ideal executions on CGRAs for imperfect loops.","","","","10.1145/2656075.2656085","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971825","","Arrays;Kernel;Nickel;Pipeline processing;Registers","parallel processing;program compilers;program control structures","CGRA;DSP domains;GP-GPUs;coarse-grained reconfigurable architectures;compiler-hardware cooperative approach;flattening-based loop nest mapping;light-weight architecture extension;loop accelerators;loop fission;loop flattening;multimedia domains;nested loop mapping;parallelism source","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Metronomy: A function-architecture co-simulation framework for timing verification of cyber-physical systems","Liangpeng Guo; Qi Zhu; Nuzzo, P.; Passerone, R.; Sangiovanni-Vincentelli, A.; Lee, E.A.","Univ. of California, Berkeley, Berkeley, CA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","As the design complexity of cyber-physical systems continues to grow, modeling the system at higher abstraction levels with formal models of computation is increasingly appealing since it enables early design verification and analysis. One of the most important aspects in system modeling and analysis is timing. However, it is very challenging to analyze and verify timing at the early design stages, as the design representation is quite abstract and trade-offs have to be made between the performance requirements defined in terms of system functionality and the cost of the feasible architecture that can implement the functionality. In this paper, we present Metronomy, a function-architecture co-simulation framework that integrates functional modeling from Ptolemy and architectural modeling from the MetroII environment via a mapping interface. Metronomy exploits contract theory for timing verification and design space exploration via co-simulation. Two case studies on an electrical power system and a paper-feed sub-system for a high speed printing press demonstrate the effectiveness of our approach.","","","","10.1145/2656075.2656093","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971840","Co-simulation;Cyber-Physical System;Timing","Computational modeling;Computer architecture;Contracts;Sensors;Solid modeling;TV;Timing","formal verification;software architecture;systems analysis","MetroII environment;Metronomy;Ptolemy;abstraction levels;cyber-physical systems;design space exploration;electrical power system;formal models;function-architecture cosimulation framework;paper-feed subsystem;printing press;system analysis;timing verification","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Saving energy without defying deadlines on mobile GPU-based heterogeneous systems","Maghazeh, A.; Bordoloi, U.D.; Horga, A.; Eles, P.; Zebo Peng","Dept. of Comput. Sci., Linkopings Univ., Linko&#x0308;pings, Sweden","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","With the advent of low-power programmable compute cores based on GPUs, GPU-equipped heterogeneous platforms are becoming common in a wide spectrum of industries including safety-critical domains like the automotive industry. While the suitability of GPUs for throughput oriented applications is well-accepted, their applicability for real-time applications remains an open issue. Moreover, in mobile/embedded systems, energy-efficient computing is a major concern and yet, there has been no systematic study on the energy savings that GPUs may potentially provide. In this paper, we propose an approach to utilize both the GPU and the CPU in a heterogeneous fashion to meet the deadlines of a real-time application while ensuring that we maximize the energy savings. We note that GPUs are inherently built to maximize the throughput and this poses a major challenge when deadlines must be satisfied. The problem becomes more acute when we consider the fact that GPUs are more energy efficient than CPUs and thus, a naive approach that is based on maximizing GPU utilization might easily lead to infeasible solutions from a deadline perspective.","","","","10.1145/2656075.2656097","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971824","","Convolution;Energy consumption;Graphics processing units;Mobile communication;Real-time systems;Schedules;Throughput","embedded systems;graphics processing units;low-power electronics","automotive industry;deadline perspective;embedded systems;energy saving;energy-efficient computing;low-power programmable compute cores;mobile GPU-based heterogeneous systems;real-time applications;safety-critical domains;throughput oriented applications","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Verification of balancing architectures for modular batteries","Lukasiewycz, M.; Steinhorst, S.; Narayanaswamy, S.","TUM CREATE, Singapore, Singapore","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Large battery packs consisting of a high number of cells are essential in electric vehicles as well as in smart grids as stationary energy buffers. In this context, active cell balancing techniques improve the lifetime and capacity of battery packs significantly by equalizing charge at runtime. Modern balancing circuits rely on switching schemes to transfer charge between cells via energy storage elements such as inductors or capacitors. Verifying correct functionality of complex architectures can become a non-trivial task where circuit and control have to be considered concurrently. For this purpose, we provide a framework for the verification of balancing architectures, using a methodology that takes advantage of graph search algorithms. While this paper focuses on inductor-based architectures, the proposed approach might also be extended to other storage elements such as capacitors or transformers. The experimental results based on several case studies give evidence that a manual verification becomes impractical and our framework is capable of either proving correctness or delivering a counter-example.","","","","10.1145/2656075.2656104","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971846","Architecture;Battery;Cell Balancing","Batteries;Capacitors;Charge transfer;Computer architecture;Inductors;MOSFET;Pulse width modulation","graph theory;inductors;search problems;secondary cells","balancing architecture verification;graph search algorithms;inductor-based architectures;modular batteries","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"A low cost acceleration method for hardware trojan detection based on fan-out cone analysis","Bin Zhou; Wei Zhang; Thambipillai, S.; Teo, J.K.J.","Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore, Singapore","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Fabless semiconductor industry and government agencies have raised serious concerns about tampering with inserting hardware Trojans in an integrated circuit supply chain in recent years. In this paper, a low hardware overhead acceleration method of the detection of HTs based on the insertion of 2-to-1 MUXs as test points is proposed. In the proposed method, the fact that one logical gate has a significant impact on the transition probability of the logical gates in its logical fan-out cone is utilized to optimize the number of the insertion MUXs. The nets which have smaller transition probability than the threshold value set by the user and minimal logical depth from the primary inputs are selected as the candidate nets. As for each candidate net, only its input net with smallest signal probability is required to be inserted the MUXs based test points until the minimal transition probability of the entire circuit is no smaller than the threshold value. Experiment results on ISCAS'89 benchmark circuits show that our proposed method can achieve remarkable improvement of transition probability with small overhead penalty.","","","","10.1145/2656075.2656077","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971844","Fan-out cone;Hardware Trojan;Low cost;Signal probability;Transition probability","Delays;Flip-flops;Hardware;Integrated circuits;Logic gates;Trojan horses;Vectors","integrated circuit testing;integrated logic circuits;invasive software;logic gates","MUX insertion;fan-out cone analysis;hardware Trojan detection;logical gates;low cost acceleration method;transition probability","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"A PCM translation layer for integrated memory and storage management","Bing-Jing Chang; Yuan-Hao Chang; Hung-Sheng Chang; Tei-Wei Kuo; Hsiang-Pang Li","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ. Taipei, Taipei, Taiwan","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Phase change memory (PCM) is known for its potentials as main memory and as storage. In contrast to the past work, this work presents a PCM translation layer that considers how the main memory is used by the operating system together with the usage patterns of storage by trading their performance and reliability. In particular, a joint management scheme is proposed to improve the capability of PCM as both main memory and storage so as to enhance the performance of the entire system. The endurance issue of PCM for main memory is resolved by utilizing the potentially large capacity of the PCM storage space with limited modifications to the existing operating system implementations. Moreover, three commands are proposed to help operating system engineers to take advantage of PCM as main memory and storage by reducing I/O overheads and speeding up both the initialization and termination of program executions. The experimental results show that the performance of PCM as both main memory and storage can be significantly improved with reasonable lifetime, while the system overhead is very limited under coarse-grained wear leveling.","","","","10.1145/2656075.2656078","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971822","","Hardware;Joints;Memory management;Operating systems;Performance evaluation;Phase change materials;Random access memory","operating systems (computers);phase change memories;program verification;storage management","I/O overheads;PCM storage space;PCM translation layer;coarse-grained wear leveling;integrated memory management;integrated storage management;joint management scheme;operating system;operating system implementations;phase change memory;program executions","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Timing analysis of erroneous systems","Assare, O.; Gupta, R.","Dept. of Comput. Sci. & Eng., Univ. of California, San Diego, La Jolla, CA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Erroneous systems allow timing errors to occur during execution, but use measures to ensure continued operation through changes in operating parameters (voltage and frequency), error correction at various levels of the system, or ensuring controlled occurrence of errors to perform approximate computing. In this paper, we are interested in characterization of error behavior at the level of instructions and programs. We propose Inter- and Intra-Program Variation as measures of error rate variability in different programs and among instructions of a program, respectively. We also characterize the error rate variation caused by the program input data and show that it is comparable to other sources of variability such as process variation. Finally, we present an analysis of the physical location of errors in hardware, identify regions in which most of the errors occur, and how different programs change the distribution of errors among these regions. In order to enable reliable timing analysis of large programs, we propose Clustered Timing Model (CTM), a high level timing model based on clustering functionally similar timing paths of the processor, and develop a CTM for LEON3, a representative in-order RISC processor. The accuracy of the model is verified using our variation-aware timing analysis framework with an average error of 3.9% (max. 6.7%) across a wide range of voltage-temperature corners.","","","","10.1145/2656075.2656101","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971823","delay faults;dynamic error estimation;erroneous systems;process variation;software error behavior;variability;variation-aware timing analysis","Analytical models;Clocks;Correlation;Delays;Registers;Software","error correction;pattern clustering;program debugging;program processors;timing","CTM;LEON3;RISC processor;approximate computing;clustered timing model;erroneous systems;error behavior characterization;error correction;error rate variability;high level timing model;interprogram variation;intraprogram variation;physical error location;processor timing paths;program instructions;program timing analysis;timing errors;variation-aware timing analysis framework","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Hypnos: An ultra-low power sleep mode with SRAM data retention for embedded microcontrollers!","Jayakumar, H.; Raha, A.; Raghunathan, V.","Purdue Univ., West Lafayette, IN, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","In heavily duty-cycled embedded systems, the energy consumed by the microcontroller in idle mode is often the bottleneck for battery lifetime. Existing solutions address this problem by placing the microcontroller in a low power (sleep) state when idle, and preserving application state either by retaining the data in-situ in SRAM, or by checkpointing it to FLASH. However, both these approaches have notable drawbacks. In-situ data retention requires the SRAM to remain powered in sleep mode, while checkpointing to FLASH involves significant energy and time overheads. This paper proposes a new ultra-low power sleep mode for micro-controllers that overcomes the limitations of both these ap- proaches. Our technique, HYPNOS, is based on the key observation that the on-chip SRAM in a microcontroller exhibits 100% data retention even at a much lower supply voltage (as much as 10x lower) than the typical operating voltage of the microcontroller. HYPNOS exploits this observation by performing extreme voltage scaling when the microcontroller is in sleep mode. We implement and evaluate HYPNOS for the TI MSP430G2452 microcontroller and show that the MCU draws only 26nA in the proposed sleep mode, which is 4× lower than any existing sleep mode that preserves SRAM contents. Further, we show that a complete wireless sensing system using HYPNOS only depletes battery capacity by 42.6nAh in an hour. By decreasing the average power consumption to such minuscule levels, HYPNOS takes a significant step forward in making perpetual systems a reality through the use of energy harvesting.","","","","10.1145/2656075.2656089","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971827","","Microcontrollers;Phasor measurement units;Power demand;Registers;SRAM cells;Switches","SRAM chips;checkpointing;embedded systems;microcontrollers;power aware computing;power consumption;storage management","Flash;HYPNOS;MCU;SRAM content preservation;SRAM data retention;TI MSP430G2452 microcontroller;battery capacity;battery lifetime;checkpointing;embedded microcontrollers;energy consumption;energy harvesting;energy overhead;extreme voltage scaling;heavily duty-cycled embedded system;microcontroller operating voltage;onchip SRAM;power consumption;time overhead;ultralow power sleep mode;wireless sensing system","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Leveraging microarchitectural side channel information to efficiently enhance program control flow integrity","Chen Liu; Chengmo Yang; Yuanqi Shen","Dept. of Electr. & Comput. Eng., Univ. of Delaware, Newark, DE, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","9","Stack buffer overflow is a serious security threat to program execution. A malicious attacker may overwrite the return address of a procedure to alter its control flow and hence change its functionality. While a number of hardware and/or software based protection schemes have been developed, these counter-measures introduce sizable overhead in performance and energy, thus limiting their applicability to embedded systems. To reduce such overhead, our goal is to develop a low-cost scheme to “filter out” potential stack buffer overflow attacks. Our observation is that attacks to control flow will trigger certain microarchitectural events, such as mis-predictions in the return address stack or misses in the instruction cache. We therefore propose a hardware-based scheme to monitor these events. Only upon detecting any suspicious behavior, a more precise but costly diagnosis scheme will be invoked to thoroughly check control flow integrity. Meanwhile, to further reduce the rate of false positives of the security filter, we propose three enhancements to the return address stack, instruction prefetch engine and instruction cache, respectively. The results show that these enhancements effectively reduce more than 95% of false positives with almost no false negatives introduced.","","","","10.1145/2656075.2656092","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971821","Instruction Cache;Return Address Stack;Security;Stack Buffer Overflow","Accuracy;Hardware;Monitoring;Prefetching;Radiation detectors;Runtime;Security","cache storage;security of data","check control flow integrity;embedded systems;false positives;hardware and/or software based protection schemes;hardware-based scheme;instruction cache;instruction prefetch engine;malicious attacker;microarchitectural event;microarchitectural side channel information;misprediction;program control flow integrity;program execution;return address stack;security filter;security threat;stack buffer overflow attack","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"System-level memory optimization for high-level synthesis of component-based SoCs","Pilato, C.; Mantovani, P.; Di Guglielmo, G.; Carloni, L.P.","Dept. of Comput. Sci., Columbia Univ., New York, NY, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","The design of specialized accelerators is essential to the success of many modern Systems-on-Chip. Electronic system-level design methodologies and high-level synthesis tools are critical for the efficient design and optimization of an accelerator. Still, these methodologies and tools offer only limited support for the optimization of the memory structures, which are often responsible for most of the area occupied by an accelerator. To address these limitations, we present a novel methodology to automatically derive the memory sub-systems of SoC accelerators. Our approach enables compositional design-space exploration and promotes design reuse of the accelerator specifications. We illustrate its effectiveness by presenting experimental results on the design of two accelerators for a high-performance embedded application.","","","","10.1145/2593069.2500071","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971834","High-Level Synthesis;Memory Optimization;System-on-Chip","Data structures;Memory management;Optimization;Organizations;Ports (Computers);Process control;System-on-chip","embedded systems;high level synthesis;memory architecture;optimisation;performance evaluation;system-on-chip","SoC accelerators;accelerator specifications;component-based SoCs;compositional design-space exploration;electronic system-level design methodologies;high-level synthesis tools;high-performance embedded application;memory structure optimization;memory subsystems;system-level memory optimization;systems-on-chip","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Automated firmware testing using firmware-hardware interaction patterns","Ahn, S.; Malik, S.","Princeton Univ., Princeton, NJ, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2014 International Conference on","20141204","2014","","","1","10","Firmware is low-level software which can directly access hardware and is often shipped with the hardware platform. This component of the system is increasing in scale and importance, and thus firmware validation is a critical part of system validation. Firmware validation relies on the interacting hardware components which are usually not available until the late design stages. This is generally addressed through co-simulating C/C++ based firmware code and HDL hardware models (including SystemC). However, this tends to be slow, and is further exacerbated by the large number of possible interleavings between the concurrent firmware and hardware threads. Typically, in the co-simulation, the scheduler, such as the SystemC scheduler, will only explore a single, or at best a small number of possible firmware-hardware interleavings and thus may miss critical bugs. In this paper we present an alternative approach to firmware validation that is based on automatically generating a test-set for the firmware with the goal of complete path coverage while considering its interactions with hardware and other firmware threads. It uses a service-function based Transaction Level Model (TLM) which has been used in the past for firmware-hardware codesign. The test generation is based on concolic testing which has been used successfully in software test generation. However, existing concolic testing tools are used for test-generation of sequential code, and cannot directly consider the interaction of other hardware/firmware threads with the target firmware thread during test generation. We address this limitation by exploiting specific interaction patterns between the firmware and hardware threads that can be analyzed from the TLM. We show how these patterns, along with the firmware and hardware threads are used to automatically generate a sequential program that is test-equivalent to the target firmware transaction and that can be used with a standard sequential program concolic test- generator. The tests generated can be (i) directly used for the firmware transaction and (ii) account for the multi-threaded interactions. These interaction patterns are practically relevant as they occur often in practice in real firmware benchmarks such as Linux device driver code, and its interacting QEMU emulated hardware code. Finally, we demonstrate the efficacy of our techniques for these benchmarks through a practical implementation that is automated and built on top of Frama-C, a static code analyzer, and KLEE, a concolic testing tool.","","","","10.1145/2656075.2656080","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6971841","","Benchmark testing;Computer bugs;Generators;Hardware;Microprogramming;Software","firmware;hardware-software codesign;multi-threading;program testing;program verification","C++ based firmware code;Frama-C;HDL hardware models;KLEE;Linux device driver code;QEMU emulated hardware code;SystemC scheduler;TLM;automated firmware testing;concolic testing tools;concurrent firmware;firmware benchmarks;firmware transaction;firmware validation;firmware-hardware codesign;firmware-hardware interaction patterns;firmware-hardware interleavings;hardware components;hardware-firmware thread interaction;low-level software;multithreaded interactions;sequential code test-generation;service-function based transaction level model;software test generation;standard sequential program concolic test generator;static code analyzer;system validation","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"[Title page]","","","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","1","13","The following topics are dealt with: embedded systems; application-specific algorithms and architectures; reconfigurable and real-time system; HW/SW co-design; high performance computing; optimising multiprocessor and NoC performance, QoS and reliability; power-aware design; MPSoC analysis and synthesis; memory and communication architecture; SystemC synthesis subset standard; compilation techniques for CGRAs; Network-on-Chip systems; accelerating system simulation; embedded software performance optimization; and multi-core systems.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751488","","","C language;application specific integrated circuits;embedded systems;hardware-software codesign;logic design;memory architecture;microprocessor chips;multiprocessing systems;network-on-chip;power aware computing;program compilers;reconfigurable architectures;software performance evaluation","CGRA;HW/SW co-design;MPSoC analysis;MPSoC synthesis;NoC performance;QoS;SystemC synthesis subset standard;accelerating system simulation;application-specific algorithms;application-specific architectures;communication architecture;compilation techniques;embedded software performance optimization;embedded systems;hardware/software codesign;high performance computing;memory architecture;multicore systems;network-on-chip systems;optimising multiprocessor;power-aware design;real-time system;reconfigurable system;reliability;system synthesis","","0","","","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Keynotes","","","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2013 International Conference on","20131111","2013","","","1","3","Provides an abstract for each of the keynote presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.","","","","10.1109/CODES-ISSS.2013.6658986","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6658986","","","","","","0","","","","","Sept. 29 2013-Oct. 4 2013","","IEEE","IEEE Conference Publications"
"Copyright page","","","Hardware/Software Codesign and System Synthesis, 2004. CODES + ISSS 2004. International Conference on","20041130","2004","","","ii","ii","Copyright and Reprint Permissions: Abstracting is permitted with credit to the source. Libraries may photocopy beyond the limits of US copyright law, for private use of patrons, those articles in this volume that carry a code at the bottom of the first page, provided that the per-copy fee indicated in the code is paid through the Copyright Clearance Center. The papers in this book comprise the proceedings of the meeting mentioned on the cover and title page. They reflect the authors' opinions and, in the interests of timely dissemination, are published as presented and without change. Their inclusion in this publication does not necessarily constitute endorsement by the editors or the Institute of Electrical and Electronics Engineers, Inc.","","1-58113-937-3","","10.1109/CODESS.2004.241143","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1360461","","","","","","0","","","","","10-10 Sept. 2004","","IEEE","IEEE Conference Publications"
"Tutorials","","","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2013 International Conference on","20131111","2013","","","1","8","Provides an abstract for each of the tutorial presentations and a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.","","","","10.1109/CODES-ISSS.2013.6658987","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6658987","","Computer architecture;Embedded systems;Hardware;Program processors;Reliability;Unified modeling language","","","","0","","11","","","Sept. 29 2013-Oct. 4 2013","","IEEE","IEEE Conference Publications"
"TPC","Donlin, A.","Xilinx"
"TPC","Jerraya, A.","CEATech"
"TPC","Jones, A.","University of Pittsburgh"
"TPC","Orailoglu, A.","University of California, San Diego"
"TPC","Gerstlauer, A.","University Of Texas, Austin"
"TPC","Pimentel, A.","University Of Amsterdam"
"TPC","Ross, A.","University Of Florida"
"TPC","Shrivastava, A.","Arizona State University"
"TPC","Jantsch, A.","Royal Institute of Technology, Stockholm"
"TPC","Hashimi, B.","University of Southampton"
"TPC","Meyer, B.","McGill University"
"TPC","Gebotys, C.","University Of Waterloo"
"TPC","Yang, C.","National Taiwan University"
"TPC","Haubelt, C.","University of Rostock"
"TPC","Atienza, D.","EPFL"
"TPC","Thomas, D.","Carnegie Mellon University"
"TPC","Sha, E.","University of Texas, Dallas"
"TPC","Bozorgzadeh, E.","University of California, Irvine"
"TPC","Macii, E.","Politecnico di Torino"
"TPC","Kock, E.","NXP Semiconductors"
"TPC","Ferrandi, F.","Politecnico di Milano"
"TPC","Kurdahi	, F.","University of California, Irvine"
"TPC","Fummi, F.","University of Verona"
"TPC","Hannig, F.","University of Erlangen-Nuremberg"
"TPC","Vahid, F.","University of California, Riverside"
"TPC","Nicolescu, G.","École Polytechnique de Montréal, Canada"
"TPC","Beltrame , G.","Polytechnique Montreal"
"TPC","Martin, G.","Cadence Design Systems"
"TPC","Pravadelli, G.","University of Verona"
"TPC","Stitt, G.","University of Florida"
"TPC","Schirner, G.","Northeastern University"
"TPC","Zeng, H.","McGill University"
"TPC","Matsutani, H.","Keio University"
"TPC","Tomiyama, H.","Ritsumeikan University"
"TPC","Oh, H.","Hanyang University"
"TPC","Madsen, J.","Technical University of Denmark"
"TPC","Xue, J.","City University of Hong Kong"
"TPC","Lee, J.","Indiana University"
"TPC","Xu, J.","Hong Kong University of Science and Technology"
"TPC","Henkel, J.","Karlsruhe Institute of Technology"
"TPC","Teich, J.","University of Erlangen"
"TPC","Wakabayashi, K.","NEC Corporation"
"TPC","Goossens, K.","Eindhoven University of Technology"
"TPC","Choi, K.","Seoul National University"
"TPC","Bauer, L.","Karlsruhe Institute of Technology"
"TPC","Benini, L.","University of Bologna"
"TPC","Lavagno, L.","Politecnico di Torino"
"TPC","Santambrogio, M.","Politecnico di Milano"
"TPC","Zwolinski, M.","University of Southampton"
"TPC","Radetzki, M.","University of Stuttgart"
"TPC","Poncino, M.","Politecnico di Torino"
"TPC","Pedram, M.","University of Southern California"
"TPC","Palesi, M.","University of Catania"
"TPC","Udrescu, M.","Universitatea Politehnica Timisoara"
"TPC","Chang, N.","Seoul National University"
"TPC","Dutt, N.","University of California, Irvine"
"TPC","Jha, N.","Princeton University"
"TPC","Bringmann, O.","University of Tuebingen / FZI"
"TPC","Hsiung, P.","National Chung Cheng University"
"TPC","Pande, P.","Washington State University"
"TPC","Bogdan, P.","University of Southern California"
"TPC","Marwedel, P.","Technical University of Dortmund"
"TPC","Eles, P.","Linkoping University"
"TPC","Mishra, P.","University of Florida"
"TPC","Raghavan, P.","IMEC"
"TPC","Panda, P.","Indian Institute of Technology Delhi, India."
"TPC","Marculescu, R.","Carnegie Mellon University"
"TPC","Marculescu, R.","Carnegie Mellon University, USA"
"TPC","Doemer, R.","University of California, Irvine"
"TPC","Bergamaschi, R.","Odysci"
"TPC","Dick, R.","University of Michigan, Ann Arbor"
"TPC","Hermida, R.","Universidad Complutense de Madrid"
"TPC","Lysecky, R.","University of Arizona"
"TPC","Garg, S.","University of Waterloo"
"TPC","Ha, S.","Seoul National University"
"TPC","Kim, S.","KAIST"
"TPC","Roy, S.","Freescale"
"TPC","Parameswaran, S.","University of New South Wales"
"TPC","Stefanov, T.","Leiden University"
"TPC","Ishihara, T.","Kyoto University"
"TPC","Givargis, T.","University of California, Irvine"
"TPC","Ogras, U.","Arizona State University"
"TPC","Bordoloi, U.","Linkoping University"
"TPC","Mueller, W.","University of Paderborn/C-LAB"
"TPC","Chen, Y.","University of Pittsburgh"
"TPC","Lin, Y.","National Tsing Hua University"
"TPC","Xie, Y.","Pennsylvania State University"
"TPC","Shao, Z.","The Hong Kong Polytechnic University"