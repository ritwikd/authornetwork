"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&matchBoolean%3Dtrue%26searchField%3DSearch_All%26queryText%3D%28%28Design%2C+Automation+.AND.+Test+in+Europe+Conference+.AND.+Exhibition+.LB.DATE.RB.%29+AND+2015%29",2015/06/23 14:59:16
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN","ISBN","EISBN","DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"On the automatic generation of SBST test programs for in-field test","Riefert, A.; Cantoro, R.; Sauer, M.; Reorda, M.S.; Becker, B.","Albert-Ludwigs-Univ. Freiburg, Freiburg, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1186","1191","Software-based self-test (SBST) techniques are used to test processors against permanent faults introduced by the manufacturing process (often as a complementary approach with respect to DfT) or to perform in-field test in safety-critical applications. A major obstacle to their adoption is the high cost for developing effective test programs, since there is still a lack of suitable EDA algorithms and tools able to automatically generate SBST test programs. An efficient ATPG algorithm can serve as the foundation for the automatic generation of SBST test programs. In this work we first highlight the additional constraints characterizing SBST test programs wrt functional ones, with special emphasis on their usage for infield test; then, we describe an ATPG framework targeting stuck-at faults based on Bounded Model Checking. The framework allows the user to flexibly specify the requirements of SBST test programs in the considered scenario. Finally, we demonstrate how a set of properly chosen requirements can be used to generate test programs matching these constraints. In our experiments we evaluate the framework with the miniMIPS microprocessor. The results show that the proposed method is the first able to automatically generate SBST test programs whose fault efficiency is superior to those produced with state-of-the-art manual approaches.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092567","","Automatic test pattern generation;Circuit faults;Memory management;Microprocessors;Model checking;Program processors;Registers","automatic test pattern generation;automatic test software;design for testability;program testing;software fault tolerance","ATPG algorithm;DfT;EDA algorithms;SBST test programs;automatic generation;bounded model checking;complementary approach;design for testability techniques;in-field test;manufacturing process;miniMIPS microprocessor;permanent faults;safety-critical applications;software-based self-test techniques;stuck-at faults","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"From device to system: Cross-layer design exploration of racetrack memory","Guangyu Sun; Chao Zhang; Hehe Li; Yue Zhang; Weiqi Zhang; Yizi Gu; Yinan Sun; Klein, J.-O.; Ravelosona, D.; Yongpan Liu; Weisheng Zhao; Huazhong Yang","CECA, Peking Univ., Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1018","1023","Recently, Racetrack Memory (RM) has attracted more and more attention of memory researchers because it has advantages of ultra-high storage density, fast access speed, and non-volatility. Prior research has demonstrated that RM has potential to replace SRAM for large capacity on-chip memory design. At the same time, it also addressed that the design space exploration of RM could be more complicated compared to traditional on-chip memory technologies for several reasons. First, a single RM cell introduces more device level design parameters. Second, considering these device-level design factors, the layout exploration of a RM array demonstrates trade-off among area, performance, and power consumption of RM circuit level design. Third, in the architecture level, the unique “shift” operation results in an extra dimension for design exploration. In this paper, we will review all these design issues in different layers and try to reveal the relationship among them. The experimental results demonstrate that cross-layer design exploration is necessary for racetrack memory. In addition, a system level case study of using RM in a sensor node is presented to demonstrate its advantages over SRAM or STT-RAM.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092539","","Computer architecture;Layout;Magnetic tunneling;Microprocessors;Nonvolatile memory;Random access memory;Saturation magnetization","integrated circuit design;random-access storage","RM array;RM circuit level design;SRAM;STT-RAM;cross-layer design exploration;design space exploration;device-level design factors;fast access speed;large capacity on-chip memory design;memory researchers;nonvolatility;racetrack memory;sensor node;shift operation;ultra-high storage density","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Comparative study of test generation methods for simulation accelerators","Kadry, W.; Krestyashyn, D.; Morgenshtein, A.; Nahir, A.; Sokhin, V.; Jin Sung Park; Sung-Boem Park; Wookyeong Jeong; Jae Cheol Son","IBM Res., Haifa, Israel","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","321","324","Hardware-accelerated simulation platforms are quickly becoming a major vehicle for the functional verification of modern systems and processors. Accelerator platforms provide functional verification with valuable simulation cycles. Yet, the high cost and limited bandwidth of accelerator platforms dictate a requirement for continuous utilization improvement. In this work, we perform a comparative analysis of two approaches of test generation for accelerator platforms. An exerciser tool is used as experimental vehicle for the study. An off-platform test generation methodology is implemented and is compared to on-platform test generation typically used in exercisers. We present experimental results from simulation of latest IBM POWER8 processor on Awan accelerator platform, as well as from simulation of an eight-core ARMv8-based design on Veloce emulation platform. Our results indicate that the utilization of accelerator platforms can be improved by up to ×7 ratio when using off-platform test generation. In addition, increase of up to 24% is observed in test coverage. Off-platform mode features significantly bigger image size, but maintains tolerable build and load times.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092407","","Acceleration;Computational modeling;Emulation;Generators;Life estimation;Program processors;Silicon","integrated circuit design;integrated circuit testing;microprocessor chips","Awan accelerator platform;IBM POWER8 processor;Veloce emulation platform;build times;comparative analysis;continuous utilization improvement;eight-core ARMv8-based design;exerciser tool;experimental vehicle;functional verification;hardware-accelerated simulation platforms;load times;microprocessor design;off-platform test generation methodology;on-platform test generation;simulation accelerators;valuable simulation cycles","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Device/circuit/architecture co-design of reliable STT-MRAM","Pajouhi, Z.; Xuanyao Fong; Roy, K.","Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1437","1442","Spin transfer torque magnetic random access memory (STT-MRAM), using magnetic tunnel junctions (MTJ) has garnered significant attention in the research community due to its immense potential for on-chip, high-density and non-volatile memory. However, process variations may significantly impact the achievable yield in STT-MRAM. To this end, several yield enhancement techniques that improve STT-MRAM failures at the bit-cell, and at the architecture level of design abstraction have been proposed in the literature. However, these techniques may lead to a suboptimal design because they do not consider the impact of design choices at every level of design abstraction. In this paper, we propose a unified device-circuit-architecture co-design framework to optimize and enhance the yield of STT-MRAM. We studied the interaction between device parameters (viz. energy barrier height) and bit-cell level parameters (viz. transistor width), together with different Error Correcting Codes (ECC) to optimize the robustness and energy efficiency of STT-MRAM cache. The advantages of our proposed approach to STT-MRAM design are explored at the 32nm technology node. We show that for a target yield of 500 Defects Per Million (DPM) for an example array with 64-bit word length, our proposed approach with realistic parameters can save up to 15% and 13% in cell area and total power consumption, respectively, in comparison with a design that does not use any array level yield enhancement technique.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092616","STT-MRAM","Arrays;Decoding;Error correction codes;Integrated circuit modeling;Magnetic tunneling;Thermal stability","MRAM devices;error correction codes","bit-cell level parameters;cell area;energy barrier height;energy efficiency;error correcting codes;magnetic tunnel junctions;power consumption;reliable STT-MRAM;robustness;size 32 nm;spin transfer torque magnetic random access memory;transistor width;unified device-circuit-architecture co-design framework;word length 64 bit","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Asymmetric underlapped FinFET based robust SRAM design at 7nm node","Goud, A.A.; Venkatesan, R.; Raghunathan, A.; Roy, K.","Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","659","664","Robust 6T SRAM design in 7nm technology node, at low supply voltage and rising leakage, requires ingenious design of FinFETs capable of providing reasonable I<sub>on</sub>/I<sub>off</sub> ratio and acceptable short channel effects even under new leakage mechanisms such as direct source to drain tunneling. In this work, we explore asymmetric underlapped FinFET design with the help of quantum mechanical device simulations considering both the bit-cell and cache design constraints. We show that our optimized FinFET achieves a significant improvement in on-current over conventional symmetrically underlapped FinFETs. Through circuit simulations using compact models, we demonstrate that when such asymmetric underlapped n-FinFETs are used as bit-line access transistors, read/write conflict can be mitigated with simultaneous reduction in 6T SRAM bit-cell leakage. Improvement in write noise margin as well as access time can also be achieved under iso-read stability condition. Based on these technology and bit-cell models, we have developed a CACTI-based simulator for evaluating asymmetric FinFET based SRAM cache at 7nm node. Using this device-circuit-system level framework and optimized asymmetric underlapped FinFETs, we demonstrate significant energy savings and performance improvements for an 8KB L1 cache and a 4MB last-level cache.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092471","6T SRAM;7nm;CACTI;FinFET;asymmetric underlap;cache;low leakage;noise margin improvement;scaled interconnect","Capacitance;FinFETs;Integrated circuit modeling;Logic gates;Mathematical model;Noise;Random access memory","MOSFET;SRAM chips;cache storage;electrical faults;integrated circuit design","CACTI based simulator;asymmetric FinFET based SRAM cache;asymmetric underlapped FinFET;bit cell design constraint;bit line access transistor;cache design constraint;last level cache;leakage mechanisms;memory size 4 MByte;robust SRAM design;short channel effect;size 7 nm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Exploiting loop-array dependencies to accelerate the design space exploration with high level synthesis","Nam Khanh Pham; Singh, A.K.; Kumar, A.; Mi Mi Aung Khin","Data Storage Inst., A*STAR, Singapore, Singapore","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","157","162","Recently, the requirement of shortened design cycles has led to rapid development of High Level Synthesis (HLS) tools that convert system level descriptions in a high level language into efficient hardware designs. Due to the high level of abstraction, HLS tools can easily provide multiple hardware designs from the same behavioral description. Therefore, they allow designers to explore various architectural options for different design objectives. However, such exploration has exponential complexity, making it practically impossible to explore the entire design space. The conventional approaches to reduce the design space exploration (DSE) complexity do not analyze the structure of the design space to limit the number of design points. To fill such a gap, we explore the structure of the design space by analyzing the dependencies between loops and arrays. We represent these dependencies as a graph that is used to reduce the dimensions of the design space. Moreover, we also examine the access pattern of the array and utilize it to find the efficient partition of arrays for each loop optimization parameter set. The experimental results show that our approach provides almost the same quality of result as the exhaustive DSE approach while significantly reducing the exploration time with an average of speed-up of 14x.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092375","","Algorithm design and analysis;Hardware;Memory management;Pareto optimization;Partitioning algorithms;Pipeline processing","circuit complexity;circuit optimisation;electronic design automation;high level languages;high level synthesis;integrated circuit design","DSE approach;DSE complexity;HLS tool;access pattern;design space exploration;hardware design;high level language;high level synthesis;loop array dependency;loop optimization parameter","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Axilog: Language support for approximate hardware design","Yazdanbakhsh, A.; Mahajan, D.; Thwaites, B.; Jongse Park; Nagendrakumar, A.; Sethuraman, S.; Ramkrishnan, K.; Ravindran, N.; Jariwala, R.; Rahimi, A.; Esmaeilzadeh, H.; Bazargan, K.","Georgia Inst. of Technol., Atlanta, GA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","812","817","Relaxing the traditional abstraction of “near-perfect” accuracy in hardware design can lead to significant gains in energy efficiency, area, and performance. To exploit this opportunity, there is a need for design abstractions that can systematically incorporate approximation in hardware design. We introduce Axilog, a set of language annotations, that provides the necessary syntax and semantics for approximate hardware design and reuse in Verilog. Axilog enables the designer to relax the accuracy requirements in certain parts of the design, while keeping the critical parts strictly precise. Axilog is coupled with a Relaxability Inference Analysis that automatically infers the relaxable gates and connections from the designer's annotations. The analysis provides formal safety guarantees that approximation will only affect the parts that the designer intended to approximate, referred to as relaxable elements. Finally, the paper describes a synthesis flow that approximates only the relaxable elements. Axilog enables applying approximation in the synthesis process while abstracting away the details of approximate synthesis from the designer. We evaluate Axilog, its analysis, and the synthesis flow using a diverse set of benchmark designs. The results show that the intuitive nature of the language extensions coupled with the automated analysis enables safe approximation of designs even with thousands of lines of code. Applying our approximate synthesis flow to these designs yields, on average, 54% energy savings and 1.9× area reduction with 10% output quality loss.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092497","","Approximation methods;Benchmark testing;Hardware;Logic gates;Semantics;Timing;Wires","hardware description languages;inference mechanisms","Axilog;Verilog;accuracy requirements;approximate hardware design;area reduction;automated analysis;benchmark designs;design abstractions;energy efficiency;energy savings;language annotations;language support;near-perfect accuracy;quality loss;relaxability inference analysis;semantics;syntax;synthesis flow","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Ultra-low-power ECG front-end design based on compressed sensing","Mamaghanian, H.; Vandergheynst, P.","Sch. of Eng., Ecole Polytech. Fed. de Lausanne (EPFL), Lausanne, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","671","676","Ultra-low-power design has been a challenging area for design of the sensor front-ends especially in the area of Wireless Body Sensor Nodes (WBSN), where a limited amount of power budget and hardware resources are available. Since introduction of Compressed Sensing, there has been a challenge to design CS-based low-power readout devices for different applications and among all for biomedical signals. Till now, different proposed realizations of the digital CS prove the suitability of using CS as an efficient low-power compression technique for compressible biomedical signals. However, these works mainly take advantages of only one aspect of the benefits of the CS. In this type of works, CS is usually used as a very low cost and easy to implement compression technique. This means that we should acquire the signal with traditional limitations on the bandwidth (BW) and later compresses it. However, the main power of the CS, which lies on the efficient data acquisition, remains untouched. Building on our previous work [1], where the suitability of the CS is proven for the compression of the ECG signals, and our investigation on ultra-low-power CS-based A2I devices [2], here in this paper we propose a fully redesigned complete CS-based “Analog-to-information” (A/I) front-end for ECG signals. Our results show that proposed hybrid design easily outperforms the traditional implementation of CS with more than 11 times fold reduction in power consumption compared to standard implementation of CS. Moreover our design shows a very promising performance specially in high compression ratio.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092473","","Analytical models;Automation;Compressed sensing;Electrocardiography;Power demand;Signal resolution;Signal to noise ratio","body sensor networks;compressed sensing;electrocardiography;medical signal processing","CS-based low-power readout device;ECG signal compression;analog-to-information front-end;compressed sensing;compressible biomedical signal;compression ratio;data acquisition;low-power compression technique;power consumption;ultralow-power CS-based A2I device;ultralow-power ECG front-end design;wireless body sensor node","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Energy-efficient cache design in emerging mobile platforms: The implications and optimizations","Kaige Yan; Xin Fu","Dept. of Electr. & Comput. Eng., Univ. of Houston, Houston, TX, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","375","380","Mobile devices are quickly becoming the most widely used processors in consumer devices. Since their major power supply is battery, the energy-efficient computing is highly desired. In this paper, we focus on the energy-efficient cache design in emerging mobile platforms. We observe that more than 40% of L2 cache accesses are OS kernel accesses in interactive smartphone applications. Such frequent kernel accesses cause serious interferences between the user and kernel blocks in the L2 cache, leading to the unnecessary block replacements and high L2 cache miss rate. We propose to partition the L2 cache into two separate segments which can only be accessed by the user code and kernel code, respectively. Meanwhile, the overall size of the two segments is shrunk, which greatly reduces the energy consumption by 15% while still maintains the similar cache miss rate. We further find completely different access behaviors between the two separated kernel and user segments in our novel L2 cache design, and explore the multi-retention STT-RAM based user and kernel segments to maximize the cache energy savings. The experimental results show that our techniques significantly reduce the cache energy consumption (e.g. 75%) with only 2% performance loss in emerging smartphones.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092417","","Benchmark testing;Energy consumption;Kernel;Mobile communication;Mobile handsets;Program processors;Random access memory","cache storage;circuit optimisation;interactive systems;mobile computing;operating system kernels;power aware computing;random-access storage;smart phones","L2 cache access;L2 cache design;OS kernel access;cache energy consumption reduction;cache energy saving maximization;energy efficient cache design;interactive smartphone applications;kernel code;kernel segments;mobile devices;multiretention STT-RAM based user;optimization;user code","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Power-aware online testing of manycore systems in the dark silicon era","Haghbayan, M.-H.; Rahmani, A.-M.; Fattah, M.; Liljeberg, P.; Plosila, J.; Navabi, Z.; Tenhunen, H.","Dept. of Inf. Technol., Univ. of Turku, Turku, Finland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","435","440","Online defect screening techniques to detect runtime faults are becoming a necessity in current and near future technologies. At the same time, due to aggressive technology scaling into the nanometer regime, power consumption is becoming a significant burden. Most of today's chips employ advanced power management features to monitor the power consumption and apply dynamic power budgeting (i.e., capping) accordingly to prevent over-heating of the chip. Given the notable power dissipation of existing testing methods, one needs to efficiently manage the power budget to cover test process of a many-core system in runtime. In this paper, we propose a power-aware online testing method for many-core systems benefiting from advanced power management capabilities. The proposed power-aware method uses non-intrusive online test scheduling strategy to functionally test the cores in their idle period. In addition, we propose a test-aware utilization-oriented runtime mapping technique that considers the utilization of cores and their test criticality in the mapping process. Our extensive experimental results reveal that the proposed power-aware online testing approach can efficiently utilize temporarily free resources and available power budget for the testing purposes, within less than 1% penalty on system throughput for the 16nm technology.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092429","Dark Silicon;Functional Testing;Many-Core Systems;Online Testing;Power Capping","Power demand;Power system dynamics;Runtime;Silicon;System performance;Testing;Upper bound","multiprocessing systems;power aware computing;testing","dark silicon era;functional test;manycore systems;nonintrusive online test scheduling strategy;power management capabilities;power-aware online testing;test-aware utilization-oriented runtime mapping technique","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Designing inexact systems efficiently using elimination heuristics","Venkataraman, S.; Kumar, A.; Schlachter, J.; Enz, C.","Dept. of Electr. & Comput. Eng., Nat. Univ. of Singapore, Singapore, Singapore","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","758","763","There are a wide variety of applications that are able to tolerate small errors in the values of the outputs, provided they are within the application-specific thresholds. For such applications, there have been many efforts to study the tradeoff involved in the accuracy of the output and the energy/area requirement. However, most of the efforts have been at the level of individual components. In this article, we present a design flow to study the inexactness at the level of system and provide heuristics to quickly explore the design-space under given inexactness and area/energy constraints. The approach is applied to various digital signal processing filters and an ECG application of QRS detection. In both cases, orders of magnitude speed-ups are obtained in the design-flow process. Area savings of 21.61% and power savings of 22.79% were observed for a low-pass filter having a relative error of just 8E-5%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092488","","Adders;Algorithm design and analysis;Delays;Digital signal processing;Electrocardiography;Estimation;Signal processing algorithms","low-pass filters","ECG application;QRS detection;application-specific thresholds;area-energy constraints;design flow;design-flow process;digital signal processing filters;elimination heuristics;energy-area requirement;inexact systems design;low-pass filter;magnitude speed-ups","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Temperature-aware software-based self-testing for delay faults","Ying Zhang; Zebo Peng; Jianhui Jiang; Huawei Li; Fujita, M.","Sch. of Software Eng., Tongji Univ., Shanghai, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","423","428","Delay defects under high temperature have been one of the most critical factors to affect the reliability of computer systems, and the current test methods don't address this problem properly. In this paper, a temperature-aware software-based self-testing (SBST) technique is proposed to self-heat the processors within a high temperature range and effectively test delay faults under high temperature. First, it automatically generates high-quality test programs through automatic test instruction generation (ATIG), and avoids over-testing caused by nonfunctional patterns. Second, it exploits two effective powerintensive program transformations to self-heat up the processors internally. Third, it applies a greedy algorithm to search the optimized schedule of the test templates in order to generate the test program while making sure that the temperature of the processor under test is within the specified range. Experimental results show that the generated program is successful to guarantee delay test within the given temperature range, and achieves high test performance with functional patterns.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092427","","Circuit faults;Delays;Power dissipation;Program processors;Schedules;Temperature distribution","automatic test pattern generation;fault diagnosis;greedy algorithms;reliability","ATIG;SBST technique;automatic test instruction generation;computer systems;delay faults;greedy algorithm;high-quality test program;power-intensive program transformation;reliability;temperature-aware software-based self-testing","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"DP-fill: A dynamic programming approach to X-filling for minimizing peak test power in scan tests","","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","836","841","At-speed testing is crucial to catch small delay defects that occur during the manufacture of high performance digital chips. Launch-Off-Capture (LOC) and Launch-Off-Shift (LOS) are two prevalently used schemes for this purpose. LOS scheme achieves higher fault coverage while consuming lesser test time over LOC scheme, but dissipates higher power during the capture phase of the at-speed test. Excessive IR-drop during capture phase on the power grid causes false delay failures leading to significant yield reduction that is unwarranted. As reported in literature, an intelligent filling of don't care bits (X-filling) in test cubes has yielded significant power reduction. Given that the tests output by automatic test pattern generation (ATPG) tools for big circuits have large number of don't care bits, the X-filling technique is very effective for them. Assuming that the design for testability (DFT) scheme preserves the state of the combinational logic between capture phases of successive patterns, this paper maps the problem of optimal X-filling for peak power minimization during LOS scheme to a variant of interval coloring problem and proposes a dynamic programming (DP) algorithm for the same along with a theoretical proof for its optimality. To the best of our knowledge, this is the first ever reported X-filling algorithm that is optimal. The proposed algorithm when experimented on ITC99 benchmarks produced peak power savings of up to 34% over the best known low power X-filling algorithm for LOS testing. Interestingly, it is observed that the power savings increase with the size of the circuit.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092501","Digital Systems Testing;Dynamic Programming;Peak Test Power;X-filling","Benchmark testing;Color;Computer architecture;Delays;Dynamic programming;Heuristic algorithms;Minimization","automatic test pattern generation;combinational circuits;dynamic programming;integrated circuit testing;microprocessor chips","ATPG tools;DFT scheme;DP algorithm;DP-fill;ITC99 benchmarks;LOC scheme;LOS scheme;LOS testing;at-speed testing;automatic test pattern generation tools;big circuits;combinational logic;design for testability scheme;don`t care bits;dynamic programming algorithm;dynamic programming approach;excessive IR-drop;false delay failures;high performance digital chips;interval coloring problem;launch-off-capture scheme;launch-off-shift scheme;optimal X-filling technique;peak test power minimization;power grid;power reduction;scan tests","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"(AS)<sup>2</sup>: Accelerator synthesis using algorithmic skeletons for rapid design space exploration","Fernando, S.; Wijtvliet, M.; Nugteren, C.; Kumar, A.; Corporaal, H.","Dept. of Electr. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","305","308","Hardware accelerators in heterogeneous multiprocessor system-on-chips are becoming popular as a means of meeting performance and energy efficiency requirements of modern embedded systems. Current design methods for accelerator synthesis, such as High-Level Synthesis, are not fully automated. Therefore, time consuming manual iterations are required to explore efficient accelerator alternatives: the programmer is still required to think in terms of the underlying architecture. In this paper, we present (AS)<sup>2</sup>: a design flow for Accelerator Synthesis using Algorithmic Skeletons. Skeletonization separates the structure of a parallel computation from an algorithms' functionality, enabling efficient implementations without requiring the programmer to have hardware knowledge. We define three such skeletons (for three image processing kernels) enabling FPGA specific parallelization techniques and optimizations. As a case study, we present a design space exploration of these skeletons and show how multiple design points with area-performance trade-offs for the accelerators can be efficiently and rapidly synthesized. We show that (AS)<sup>2</sup> is a promising direction for accelerator synthesis as it generates a pareto front of 8 design points in under half an hour for each of the three image processing kernels.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092403","","Algorithm design and analysis;Arrays;Field programmable gate arrays;Kernel;Libraries;Manuals;Skeleton","Pareto optimisation;embedded systems;image processing;multiprocessing systems;system-on-chip","FPGA specific parallelization techniques;Pareto front;accelerator synthesis;algorithmic skeletons;design flow;energy efficiency requirements;hardware accelerators;heterogeneous multiprocessor system-on-chips;high level synthesis;image processing kernels;modern embedded systems;parallel computation;rapid design space exploration;skeletonization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Panel: The future of electronics, semiconductors, and design in Europe","Casale-Rossi, Marco; De Micheli, Giovanni; Bagherli, Jalal; Collette, Thierry; Domic, Antun; Symanzik, Horst; Yassaie, Sir Hossein","Synopsys, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1726","1728","For more than a decade, Europe has been the wireless continent; today, wireless has almost completely shifted to the U.S. and Asia. This shift has had a profound impact on the electronic, semiconductor, and design ecosystem: long-time leaders have disappeared, or have abandoned the wireless business/market. Europe needs to re-invent itself once again. Is there a future for electronics, and IC design and manufacturing in Europe? If so, what are the applications, and the technologies that will bring Europe back to the top of the world leadership? This panel session, moderated by EPFL Professor Giovanni De Micheli, will gather executives from the semiconductor, IP, and R&D sectors to discuss the prospects of our industry in Europe.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092669","","Consumer electronics;Ecosystems;Europe;IP networks;Industries;Wireless communication;Wireless sensor networks","","","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Variation-aware, reliability-emphasized design and optimization of RRAM using SPICE model","Li, H.; Jiang, Z.; Huang, P.; Wu, Y.; Chen, H.-Y.; Gao, B.; Liu, X.Y.; Kang, J.F.; Wong, H.-S.P.","Dept. of Electr. Eng. & Stanford SystemX Alliance, Stanford Univ., Stanford, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1425","1430","Resistive switching random access memory (RRAM) is a leading candidate for next-generation nonvolatile and storage-class memories and monolithic integration of logic with memory interleaved in multiple layers. To meet the increasing need for device-circuit-system co-design and optimization for applications from digital memory systems to brain-inspired computing systems, a SPICE model of RRAM that can reproduce essential device physics in a circuit simulation environment is required. In this work, we develop an RRAM SPICE model that can capture all the essential device characteristics such as stochastic switching behaviors, multi-level cell, switching voltage variations, and resistance distributions. The model is verified and calibrated by a variety of electrical measurements on ~10 nm RRAMs. The model is applied to explore a wide range of applications including: 1) variation-aware design; 2) reliability-emphasized design; 3) speed-power assessment; 4) array architecture optimization; and 5) neuromorphic computing. This experimentally verified design tool not only enables system design that utilizes the complete suite of RRAM device features, but also provides solutions for system optimization that capitalize on device/circuit interaction.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092614","SPICE model;design tool;emerging memory;reliability;resistive switching memory;variability","Arrays;Computational modeling;Integrated circuit modeling;Resistance;SPICE;Switches","SPICE;integrated circuit reliability;resistive RAM","RRAM device features;SPICE model;array architecture optimization;brain-inspired computing systems;circuit interaction;circuit simulation environment;device interaction;device-circuit-system codesign;digital memory systems;electrical measurements;monolithic integration;multilevel cell;neuromorphic computing;next-generation nonvolatile memories;reliability-emphasized design;resistance distributions;resistive switching random access memory;stochastic switching behaviors;storage-class memories;switching voltage variations;variation-aware assessment","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A methodology for automated design of embedded bit-flips detectors in post-silicon validation","Taatizadeh, P.; Nicolici, N.","Dept. of Electr. & Comput. Eng., McMaster Univ., Hamilton, ON, Canada","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","73","78","Post-silicon validation is concerned with detecting design errors that escape to silicon prototypes and need to be fixed before committing to high-volume manufacturing. Electrical errors are particularly difficult to catch during the pre-silicon phase because of the insufficient accuracy of device models, which is often traded-off against simulation time. This challenge is further aggravated by the rising number of voltage domains, especially if subtle errors are excited in unique electrical states. Since these electrically-induced subtle errors most commonly manifest in the logic domain as bit-flips, to the best of our knowledge there are no systematic methods to design embedded hardware monitors for generic logic blocks that can detect bit-flips with low detection latency. Toward this goal, we propose a methodology that relies on design assertions that are ranked based on their potential to detect bit-flips and subsequently mapped into user-constrained embedded hardware monitors with the aim to increase bit-flip coverage estimate.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092361","","Clocks;Hardware;Integrated circuit modeling;Monitoring;Prototypes;Silicon;Wires","error detection;logic design;quality assurance","bit-flip coverage estimate;design assertions;design errors;device models;electrical errors;electrically-induced subtle errors;generic logic blocks;high-volume manufacturing;logic domain;post-silicon validation;pre-silicon phase;silicon prototypes;unique electrical states;user-constrained embedded hardware monitors;voltage domains","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Silicon proof of the intelligent analog IP design flow for flexible automotive components","Reich, T.; Prautsch, H.D.B.; Eichler, U.; Buhl, R.","Design Autom. Div., Fraunhofer Inst. for Integrated Circuits, Dresden, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","403","404","In this brief paper we present the successful silicon validation of the Intelligent Analog IP (IIP) design flow applied to the design of a SMART sensor IC for automotive requirements. Using a library of reconfigurable and robust analog IP we fast create parameterized cells up to high complexity levels including the corresponding layouts. This allows us (1) to overcome time-consuming handcrafted analog re-design cycles, (2) to include the effects of layout parasitics into the optimization loop, and thus (3) to fast achieve different specifications even for multiple technologies. We show that the IIP design flow leads to a strong improvement of design efficiency, silicon performance, and yield.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092422","Design Flow;Intelligent IP;Optimization;Post-Layout;Reuse;Yield","IP networks;Integrated circuits;Layout;Libraries;Optimization;Silicon;Topology","analogue circuits;automotive electronics;circuit optimisation;elemental semiconductors;integrated circuit design;intelligent sensors;silicon","IIP design flow;Si;flexible automotive components;intelligent analog IP design flow;layout parasitics;parameterized cells;silicon proof;smart sensor IC;time-consuming handcrafted analog redesign cycles","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Combining adaptive alternate test and multi-site","Leger, G.","Centro Nac. de Microelectron., Univ. de Sevilla, Sevilla, Spain","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1389","1394","Testing analog, mixed-signal and RF circuits represents one of the main cost components for complex SoCs. Multisite Testing is widely accepted as a straightforward technique to reduce the effective test time. This paper shows that an adaptive Alternate Test approach can be compatible with a multisite strategy. The proposed solution consists in ordering offline the signatures acquisition sequence and training incremental regression models for each new feature. These models can be used to diagnose the circuit as good, provided that the estimate of the performance is larger than the specification plus a guard-band related to the model error. If all the sites are diagnosed as good, the test program can be halted before completion. This decision is taken on-line and makes this scheme adaptive. We provide an analytical study of the expected test time reduction and of the test escape penalty that is incurred. Results obtained from post-layout MonteCarlo simulations of an LNA demonstrate the validity of the approach and show that significant test time improvements can be obtained, even for large number of sites, whenever the manufacturing yield is sufficiently high.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092608","","Adaptation models;Data models;Gain;Integrated circuit modeling;Measurement;Testing;Training","Monte Carlo methods;analogue integrated circuits;integrated circuit testing;low noise amplifiers;mixed analogue-digital integrated circuits;radiofrequency integrated circuits;regression analysis;system-on-chip","LNA;RF circuits;SoC;adaptive alternate test;analog circuits;incremental regression models;low noise amplifier;mixed-signal circuits;multisite strategy;multisite testing;post-layout Monte Carlo simulations;signatures acquisition sequence;system-on-chip;test escape penalty;test program;test time reduction","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Towards systematic design of 3D pNML layouts","Perricone, R.; Yining Zhu; Sanders, K.M.; Hu, X.S.; Niemier, M.","Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1539","1542","Nanomagnetic logic (NML) is a “beyond-CMOS” technology that uses bistable magnets to store, process, and move binary information. Compared to CMOS, NML has several advantages such as non-volatility, lower power consumption, and radiation hardness. Recently, NML devices with perpendicular magnetic anisotropy (pNML) have been experimentally demonstrated to perform logic operations in three dimensions. 3D pNML layouts provide additional benefits such as simplified signal routing and greater integration density. However, designing functional 3D pNML circuits can be challenging as one must consider the effects of fringing magnetic fields in three dimensions. Furthermore, the current process of designing 3D pNML layouts is little more than a trial-and-error-based approach, which is infeasible for larger, more complex designs. In this paper, we propose a systematic approach to designing 3D pNML layouts. Our design process leverages a machine learning-inspired prediction approach that examines the effects of varying individual device parameters (e.g., length, width, etc.) and predicts functional configurations.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092633","","Algorithm design and analysis;Clocks;Layout;Perpendicular magnetic anisotropy;Prediction algorithms;Three-dimensional displays","integrated logic circuits;learning (artificial intelligence);logic design;magnetic fields;magnetic logic;nanoelectronics;network routing;perpendicular magnetic anisotropy;power consumption;radiation hardening (electronics);three-dimensional integrated circuits","3D pNML circuits;3D pNML layouts;NML devices;beyond-CMOS technology;bistable magnets;fringing magnetic fields;integration density;logic operations;machine learning-inspired prediction approach;nanomagnetic logic;perpendicular magnetic anisotropy;power consumption;radiation hardness;signal routing","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Minimizing the number of process corner simulations during design verification","Shoniker, M.; Cockburn, B.F.; Jie Han; Pedrycz, W.","Univ. of Alberta, Edmonton, AB, Canada","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","289","292","Integrated circuit designs need to be verified in simulation over a large number of process corners that represent the expected range of transistor properties, supply voltages, and die temperatures. Each process corner can require substantial simulation time. Unfortunately, the required number of corners has been growing rapidly in the latest semiconductor technologies. We consider the problem of minimizing the required number of process corner simulations by iteratively learning a model of the output functions in order to confidently estimate key maximum and/or minimum properties of those functions. Depending on the output function, the required number of corner simulations can be reduced by factors of up to 95%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092399","Adaptive algorithms;Gaussian processes;circuit simulation;design automation;function approximation;robustness;unsupervised learning","Automation;Decision support systems;Europe;Integrated circuit modeling;Semiconductor process modeling;Transistors;Uncertainty","circuit simulation;electronic design automation;integrated circuit design;transistor circuits","Integrated circuit designs;design verification;die temperatures;output functions;process corner simulations;semiconductor technologies;supply voltages;transistor properties","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Exploring the impact of functional test programs re-used for power-aware testing","Touati, A.; Bosio, A.; Dilillo, L.; Girard, P.; Virazel, A.; Bernardi, P.; Reorda, M.S.","LIRMM, Univ. de Montpellier 2, Montpellier, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1277","1280","High power consumption during at-speed delay fault testing may lead to yield loss and premature aging. On the other hand, reducing too much test power might lead to test escape and reliability problems. Thus, to avoid these issues, test power has to map the power consumed during functional mode. Existing works target the generation of functional test programs able to maximize the power consumption in functional mode of microprocessor cores. The obtained power consumption will be used as threshold to tune the power consumed during testing. This paper investigates the impact of re-using such functional test programs for testing purposes. We propose to apply them by exploiting existing DfT architecture to maximize the delay fault coverage. Then, we combine them with the classical at-speed LOC and LOS delay fault testing schemes to further increase the fault coverage. Results show that it is possible to achieve a global test solution able to maximize the delay fault coverage while respecting the functional power budget.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092588","ATPG;Functional and Structural test;Power Aware Test;microprocessor test","Circuit faults;Clocks;Delays;Flip-flops;Microprocessors;Power demand;Testing","integrated circuit testing;microprocessor chips;power aware computing;power engineering computing","at-speed delay fault testing;functional power budget;functional test programs;high power consumption;microprocessor cores;power-aware testing;premature aging;yield loss","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"LVS check for photonic integrated circuits — Curvilinear feature extraction and validation","Ruping Cao; Billoudet, J.; Ferguson, J.; Couder, L.; Cayo, J.; Arriordaz, A.; O'Connor, I.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1253","1256","This work is motivated by the demand of an electronic design automation (EDA) approach for the emerging ecosystem of the photonic integrated circuit (PIC) technology. A reliable physical verification flow cannot be achieved without the adaption of the traditional EDA tools to the photonic design verification needs. We analyze how layout versus schematic (LVS) checking is performed differently for photonic designs, and propose an LVS flow that addresses the particular need of curvilinear feature validation (curved path length and bend curvature extraction). We show that it is possible to reuse and extend the current LVS tools to perform such critical but non-traditional checks, which ensures a more reliable photonic layout implementation in term of functionality and circuit yield. Going forward, we propose possible future studies that can further improve the flows.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092582","","Feature extraction;Integrated optics;Layout;Optical devices;Optical waveguides;Silicon photonics","electronic design automation;feature extraction;integrated circuit layout;integrated optics","EDA tools;LVS checking;LVS flow;LVS tools;PIC technology;bend curvature extraction;curved path length;curvilinear feature extraction;curvilinear feature validation;electronic design automation;layout versus schematic checking;photonic design verification;photonic integrated circuit technology;physical verification flow","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Reducing energy consumption in microcontroller-based platforms with low design margin co-processors","Gomez, A.; Pinto, C.; Bartolini, A.; Rossi, D.; Benini, L.; Fatemi, H.; de Gyvez, J.P.","Comput. Eng. & Networks Lab., ETH Zurich, Zurich, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","269","272","Advanced energy minimization techniques (i.e. DVFS, Thermal Management, etc) and their high-level HW/SW requirements are well established in high-throughput multi-core systems. These techniques would have an intolerable overhead in low-cost, performance-constrained microcontroller units (MCU's). These devices can further reduce power by operating at a lower voltage, at the cost of increased sensitivity to PVT variation and increased design margins. In this paper, we propose an runtime environment for next-generation dual-core MCU platforms. These platforms complement a single-core with a low area overhead, reduced design margin shadow-processor. The runtime decreases the overall energy consumption by exploiting design corner heterogeneity between the two cores, rather than increasing the throughput. This allows the platform's power envelope to be dynamically adjusted to application-specific requirements. Our simulations show that, depending on the ratio of core to platform energy, total energy savings can be up to 20%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092394","","Energy consumption;Microcontrollers;Multicore processing;Optical wavelength conversion;Parallel processing;Resource management","coprocessors;energy consumption;microcontrollers;multiprocessing systems","advanced energy minimization technique;energy consumption reduction;high-level HW-SW requirements;high-throughput multicore system;low design margin coprocessors;microcontroller-based platforms;next-generation dual-core MCU platforms;performance-constrained microcontroller units","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A tool for the assisted design of charge redistribution SAR ADCs","Brenna, S.; Bonetti, A.; Bonfanti, A.; Lacaita, A.L.","DEIB, Politec. di Milano, Milan, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1265","1268","The optimal design of SAR ADCs requires the accurate estimate of nonlinearity and parasitic effects in the feedback charge-redistribution DAC. Since the effects of both mismatch and stray capacitances depend on the specific array topology, complex calculations, custom modeling and heavy simulations in common circuit design environments are often required. This paper presents a MATLAB-based numerical tool (CSAtool) to assist the design of the charge redistribution DACs adopted in SAR ADCs. The tool performs both parametric and statistical simulations taking into account capacitive mismatch and parasitic capacitances thus computing both differential and integral nonlinearity (DNL, INL). SNDR and ENoB degradation due to static non-linear effects is also estimated. An excellent agreement is obtained with the results of circuit simulators (e.g. Cadence Spectre) featuring up to 10<sup>4</sup> shorter simulation time, allowing a large number statistical simulations which would be otherwise impracticable. Measurements on two fabricated SAR ADCs confirm that the proposed tool can be used as a valid instrument to assist the design of a charge redistribution SAR ADC and predict its static and dynamic metrics.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092585","Analog-to-digital conversion;assisted design;charge redistribution successive approximation registers ADC;numerical tools","Arrays;Capacitance;Capacitors;Computational modeling;Integrated circuit modeling;Numerical models;Topology","analogue-digital conversion;circuit simulation;digital-analogue conversion;mathematics computing;statistical analysis","CSAtool;ENoB degradation;MATLAB-based numerical tool;SNDR;analog-to-digital converters;array topology;capacitive mismatch;charge redistribution SAR ADC assisted design;circuit design environments;circuit simulator;complex calculations;custom modeling;differential nonlinearity;digital-to-analog converter;dynamic metrics;feedback charge-redistribution DAC;heavy simulations;integral nonlinearity;parametric simulation;parasitic capacitances;parasitic effects;static metrics;static nonlinear effect;statistical simulation;stray capacitances;successive approximation register","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Feedback-bus oscillation ring: A general architecture for delay characterization and test of interconnects","Shi-Yu Huang; Meng-Ting Tsai; Kun-Han Hans Tsai; Wu-Tung Cheng","Electr. Eng. Dept., Nat. Tsing Hua Univ., Hsinchu, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","924","927","In this paper we propose a flexible delay characterization and test architecture, called Feedback-Bus Oscillation Ring (FB-OR), for die-to-die interconnects in a 3D IC. As compared to previous works, it is unique in its ability to streamline the characterization/test operations for a set of arbitrary interconnects with multiple pins sprawling multiple dies. During the Design-for-Testability stage, one common feedback-bus (connected to all dies in the IC under characterization/test) is inserted. Through this feedback-bus, an oscillation ring can be formed dynamically and the Variable-Output-Threshold (VOT) technique can be applied to characterize the delay of one interconnect segment at a time. Experimental results indicate that this method is not only flexible and scalable, but requiring only a small area overhead.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092520","","Circuit faults;Delays;Integrated circuit interconnections;Inverters;Oscillators;Testing;Through-silicon vias","design for testability;feedback oscillators;integrated circuit interconnections;three-dimensional integrated circuits","3D IC;FB-OR;VOT technique;arbitrary interconnects;design-for-testability stage;die-to-die interconnects;feedback-bus oscillation ring;flexible delay characterization;test architecture;variable-output-threshold technique","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Fast deployment of alternate analog test using Bayesian model fusion","Liaperdos, J.; Stratigopoulos, H.-G.; Abdallah, L.; Tsiatouhas, Y.; Arapoyanni, A.; Xin Li","Dept. of Comput. Eng., Technol. Educ. Inst. of Peloponnese, Sparta, Greece","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1030","1035","In this paper, we address the problem of limited training sets for learning the regression functions in alternate analog test. Typically, a large volume of real data needs to be collected from different wafers and lots over a long period of time to be able to train the regression functions with accuracy across the whole design space and apply alternate test with high confidence. To avoid this delay and achieve a fast deployment of alternate test, we propose to use the Bayesian model fusion technique that leverages prior knowledge from simulation data and fuses this information with data from few real circuits to draw accurate regression functions across the whole design space. The technique is demonstrated for an alternate test designed for RF low noise amplifiers.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092541","","Accuracy;Data models;Integrated circuit modeling;Predictive models;Production;Standards;Training","analogue integrated circuits;low noise amplifiers;radiofrequency amplifiers;regression analysis","Bayesian model fusion technique;RF low noise amplifiers;alternate analog test;regression functions;simulation data","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"New testing procedure for finding insertion sites of stealthy Hardware Trojans","Dupuis, S.; Ba, P.-S.; Flottes, M.-L.; Di Natale, G.; Rouzeyre, B.","LIRMM, Univ. Montpellier II, Montpellier, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","776","781","Hardware Trojans (HTs) are malicious alterations to a circuit. These modifications can be inserted either during the design phase or during the fabrication process. Due to the diversity of Hardware Trojans, detecting and/or locating them are challenging tasks. Numerous approaches have been proposed to address this problem. Methods based on logic testing consist in trying to activate potential HTs and detect erroneous outputs during test. However, HTs are stealthy in nature i.e. mostly inactive unless they are triggered by a very rare condition. The activation of a HT is therefore a major challenge. In this paper, we propose a new testing procedure dedicated to identifying where a possible HT may be easily inserted and generating the test patterns that are able to excite these sites. The selection of the sites is based on the assumption that the HT (i) is triggered by signals with low controllability, (ii) combines them using gates in close proximity in the circuit's layout, and (iii) without introducing new gates in critical paths.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092491","","Automatic test pattern generation;Benchmark testing;Controllability;Delays;Layout;Logic gates;Payloads","integrated circuit layout;integrated circuit testing;invasive software;logic testing;trigger circuits","circuit layout;logic testing;malicious alterations;stealthy hardware Trojan insertion site;testing procedure;triggering","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A novel modeling attack resistant PUF design based on non-linear voltage transfer characteristics","Vijayakumar, A.; Kundu, S.","Dept. of Electr. & Comput. Eng., Univ. of Massachusetts, Amherst, MA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","653","658","Physical Unclonable Function (PUF) circuits are used for chip authentication. PUF designs rely on manufacturing process variations to produce unique response to input challenges. It has been shown that many PUF designs are vulnerable to machine learning (ML) attacks, where a model can be built to predict PUF response to any input after only a few observations. In this work, we propose a ML attack resistant PUF design based on a circuit block to implement a non-linear voltage transfer function. The proposed circuit is simple, exhibits high uniqueness and randomness. Further improvements are proposed to enhance PUF reliability. The proposed circuit was simulated in a 45nm technology process and the results indicate a significant improvement in ML attack resistance in comparison to traditional PUFs. Results on uniqueness and reliability are also presented.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092470","Physical unclonable function;modeling attack;security","Authentication;Delays;Integrated circuit modeling;Integrated circuit reliability;Resistance;Transistors","integrated circuit design;integrated circuit manufacture;learning (artificial intelligence)","ML attack resistance;ML attack resistant PUF design;PUF circuits;chip authentication;circuit block;machine learning attacks;manufacturing process variations;nonlinear voltage transfer function;physical unclonable function circuits","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Efficient soft error vulnerability estimation of complex designs","Mirkhani, S.; Mitra, S.; Chen-Yong Cher; Abraham, J.","Univ. of Texas at Austin, Austin, TX, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","103","108","Analyzing design vulnerability for soft errors has become a challenging process in large systems with a large number of memory elements. Error injection in a complex system with a sufficiently large sample of error candidates for reasonable accuracy takes a large amount of time. In this paper we describe RAVEN, a statistical method to estimate the outcomes of a system in the presence of soft errors injected into flip-flops, as well as the vulnerability for each memory element. This method takes advantage of fast local simulations for each error injection, and calculates the probabilities for the system outcomes for every possible soft error in a period of time. Experimental results, on an out-of-order processor with SPECINT2000 workloads, show that RAVEN is an order of magnitude faster compared with traditional error injection while maintaining accuracy.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092366","","Automation;Clocks;Estimation;Hardware design languages;Mathematical model;Probability;Resilience","error statistics;flip-flops;probability;radiation hardening (electronics)","RAVEN;SPECINT2000 workloads;design vulnerability;error candidates;error injection;fast local simulations;flip-flops;memory elements;soft errors;statistical method","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Embedded HW/SW platform for on-the-fly testing of true random number generators","Yang, B.; Rozic, V.; Mentens, N.; Dehaene, W.; Verbauwhede, I.","ESAT/COSIC & iMinds, KU Leuven, Leuven, Belgium","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","345","350","We present a HW/SW platform for on-the-fly detection of failures and weaknesses in entropy sources. By splitting the operations between hardware and software, we achieve sufficient flexibility to control the level of significance of the tests. This approach also enables sharing resources between different tests thereby reducing the area and power. Statistical tests were selected from the NIST test suite. We propose several versions of hardware co-processors for monitoring random bit sequences, ranging from 52 slices (5 tests) to 552 slices (9 tests) on Spartan-6 FPGA. We are the first to provide implementations of the Serial test and the Approximate entropy test for on-the-fly monitoring.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092412","","Entropy;Generators;Hardware;NIST;Radiation detectors;Software;Testing","coprocessors;entropy;field programmable gate arrays;hardware-software codesign;random number generation","MIST test suite;Spartan-6 FPGA;approximate entropy test;embedded HW-SW platform;entropy sources;hardware coprocessors;on-the-fly failures detection;on-the-fly monitoring;on-the-fly testing;random bit sequences;serial test;true random number generators","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Automated feature localization for dynamically generated SystemC designs","Stoppe, J.; Wille, R.; Drechsler, R.","Cyber-Phys. Syst., DFKI GmbH, Bremen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","277","280","Due to the large complexity of today's circuits and systems, all components e.g. in a System on Chip (SoC) cannot be designed from scratch anymore. As a consequence, designers frequently work on components which they did not create themselves and, hence, design understanding becomes a crucial issue. Approaches for feature localization help by pinpointing to distinguished characteristics of a design. However, existing approaches for feature localization mainly focused on the Register Transfer Level; existing solutions for the Electronic System Level (using languages such as SystemC) have severe limits. In this work, we propose an approach for advanced feature localization in SystemC designs. By this, we overcome major limitations of previously proposed solutions, in particular the missing support for dynamically generated designs, while keeping the proposed solution as non-intrusive as possible. The benefits of our approach are confirmed by means of a case study.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092396","","Automation;Europe;Programming;Receivers;Switches;System-on-chip;Weaving","C++ language;aspect-oriented programming;system-on-chip","SoC;SystemC design;aspect-oriented programming;automated feature localization;electronic system level;register transfer level;system-on-chip","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A general design of stochastic circuit and its synthesis","Zheng Zhao; Weikang Qian","Univ. of Michigan-Shanghai Jiao Tong Univ. Joint Inst., Shanghai Jiao Tong Univ., Shanghai, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1467","1472","Stochastic computing (SC) is an unconventional paradigm to realize arithmetic computation, where real values are encoded as stochastic bit streams. Compared with conventional computation on binary radix encoding, SC can perform arithmetic computation with very simple circuits. It also has strong tolerance to soft errors. In this paper, we introduce a general design of combinational circuit for stochastic computing, together with its analysis. We further show a synthesis method that can implement arbitrary arithmetic functions with the proposed design. The experimental results demonstrated that compared with the previous methods, our approach produces a circuit with much smaller area and delay.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092621","","Automation;Boolean functions;Combinational circuits;Delays;Design automation;Polynomials;Transforms","combinational circuits;digital arithmetic;logic design","SC;arbitrary arithmetic functions;arithmetic computation;binary radix encoding;combinational circuit;general stochastic circuit design;soft errors;stochastic bit streams;stochastic computing;synthesis method","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"FLINT: Layout-oriented FPGA-based methodology for fault tolerant ASIC design","Nowosielski, R.; Gerlach, L.; Bieband, S.; Paya-Vaya, G.; Blume, H.","Inst. of Microelectron. Syst., Leibniz Univ. Hannover, Hannover, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","297","300","Research of efficient fault tolerance techniques for digital systems requires insight into the fault propagation mechanism inside the ASIC design. Radiation, high temperature, or charge sharing effects in ultra-deep submicron technologies influence fault generation and propagation dependent on die location. The proposed methodology links efficient fault injection to fault propagation in the floorplan view of a standard cell ASIC. This is achieved by instrumentation of the gate netlist after place&route, emulation in an FPGA system and experiment control via interactive user interface. Further, automated fault injection campaigns allow exhaustive fault tolerance evaluations taking single faults as well as adjacent cell faults into account. The proposed methodology can be used to identify vulnerable cell nodes in the design and allow the classification of placement strategies of fault tolerant ASIC designs.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092401","","Application specific integrated circuits;Circuit faults;Computer architecture;Fault tolerance;Fault tolerant systems;Instruments;Logic gates","application specific integrated circuits;circuit layout;fault simulation;fault tolerance;field programmable gate arrays","FLINT;digital systems;fault generation;fault injection tool;fault propagation mechanism;fault tolerance techniques;fault tolerant ASIC design;floorplan view;layout-oriented FPGA;ultradeep submicron technologies","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A method for the estimation of defect detection probability of analog/RF defect-oriented tests","Liaperdos, J.; Arapoyanni, A.; Tsiatouhas, Y.","Dept. of Comput. Eng., Technol. Educ. Inst. of Peloponnese, Sparta, Greece","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1395","1400","A method to realistically estimate the defect detection probability achieved by defect-oriented analog/RF integrated circuit tests at the circuit design level is presented in this paper. The proposed method also provides insight to the efficiency of the various available defect-oriented testing techniques, thus allowing the selection of the most suitable for a specific circuit. The effect of structural defects in the presence of process variations and device mismatches is taken into account, by the exploitation of the defect probability distributions and the statistical models of the used technology. Although the proposed methodology is generally applicable to the entire class of analog circuits, its application to simple RF circuits which consist of a few elements seems to be more practical, due to the affordable computational cost implied by circuits with shorter defect dictionaries. In order to obtain results without a reliability compromise, the number of required statistical simulation runs is reduced through regression. The application of the proposed method on a typical RF mixer, designed in a 0.18μm CMOS technology, is also presented.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092609","","Computational modeling;Dictionaries;Mixers;Probability;Radio frequency;Resistance;US Department of Transportation","CMOS analogue integrated circuits;electronic engineering computing;integrated circuit design;integrated circuit testing;mixers (circuits);radiofrequency integrated circuits;statistical distributions","CMOS technology;RF mixer;circuit design level;defect detection probability estimation;defect oriented analog-RF integrated circuit test;defect probability distribution;process variation;size 0.18 mum;statistical model;statistical simulation;structural defect effect","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Design method for multiplier-less two-variable numeric function approximation","Rust, J.; Paul, S.","Inst. of Electrodynamics & Microelectron., Univ. of Bremen, Bremen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","948","953","In this paper a novel method for hardware-based realization of two-variable numeric functions is introduced. The main idea is based on the extension of the well-known piecewise linear approximation technique, which is often used for the calculation of one-variable elementary functions. A nonuniform and plane segmentation scheme enables quick segment access at runtime; the use of multiplier-less linear equations causes high performance in terms of throughput. As both the extraction of approximation-related parameters and its mapping to corresponding hardware elements is automated, the design time is also reduced to a minimum. For evaluation, several approximations with varying constraints are generated and compared on the algorithmic level to one another as well as to actual references. In conjunction with the results of logical and physical CMOS synthesis, our work turns out to be highly efficient in terms of throughput, memory requirements and energy consumption.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092525","multiplier-less;numeric function approximation;two-variable","Approximation algorithms;Function approximation;Hardware;Linear approximation;Piecewise linear approximation;Signal processing","digital arithmetic;function approximation;piecewise linear techniques","multiplier-less linear equations;multiplier-less two-variable numeric function approximation;nonuniform plane segmentation scheme;piecewise linear approximation technique;segment access","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Fault diagnosis in designs with extreme low pin test data compressors","Kundu, S.; Bhattacharya, P.; Kapur, R.","Synopsys India Pvt. Ltd., Bangalore, India","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1285","1288","Diagnosis plays an important role to ramp up yield during IC manufacturing process. Limited observability due to test response compaction negatively affects diagnosis procedure. With modern compressors - targeting very high test data compression, diagnosis becomes even more complicated. In this paper, a complete diagnosis methodology focussing on a novel mapping algorithm has been described. The mapping algorithm maps failures from compressor pins to scan cells with great accuracy (even in presence of X-bits in the responses), so that, scan diagnosis can be used to find out the actual defects. Experimental results on industrial designs showed that the proposed method almost match scan based fault diagnosis results.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092590","","Algorithm design and analysis;Circuit faults;Compaction;Compressors;Convolution;Fault diagnosis;Synthetic aperture sonar","boundary scan testing;compressors;data compression;integrated circuit yield;logic testing","data compression;data compressors;integrated circuit manufacture;integrated circuit yield;scan based fault diagnosis;scan diagnosis","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Design flow and run-time management for compressed FPGA configurations","Huriaux, C.; Courtay, A.; Sentieys, O.","Univ. of Rennes 1, Lannion, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1551","1554","The aim of partially and dynamically reconfigurable hardware is to provide an increased flexibility through the load of multiple applications on the same reconfigurable fabric at the same time. However, a configuration bit-stream loaded at runtime should be created offline for each task of the application. Moreover, modern applications use a lot of specialized hardware blocks to perform complex operations, which tends to cancel the “single bit-stream for a single application” paradigm, as the logic content for different locations of the reconfigurable fabric may be different. In this paper we propose a design flow for generating compressed configuration bit-streams abstracted from their final position on the logic fabric. Those configurations will then be decoded and finalized in real-time and at run-time by a dedicated reconfiguration controller to be placed at a given physical location. Our experiments show that densely routed applications gain the most with a compression factor of more than 2× using the finest cluster size, but coarser coding can be implemented to achieve a compression factor up to 10×.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092636","Bit-Stream compression;FPGA","Encoding;Fabrics;Field programmable gate arrays;Hardware;Routing;Switches;Video recording","field programmable gate arrays;logic design","compressed FPGA configurations;configuration bit-stream;dedicated reconfiguration controller;design flow;logic content;logic fabric;reconfigurable fabric;reconfigurable hardware;run-time management;single application paradigm;single bit-stream;specialized hardware blocks","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A comprehensive study of Monolithic 3D cell on cell design using commercial 2D tool","Billoint, O.; Sarhan, H.; Rayane, I.; Vinet, M.; Batude, P.; Fenouillet-Beranger, C.; Rozeau, O.; Cibrario, G.; Deprat, F.; Fustier, A.; Michallet, J.-E.; Faynot, O.; Turkyilmaz, O.; Christmann, J.-F.; Thuries, S.; Clermidy, F.","Univ. Grenoble Alpes, Grenoble, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1192","1196","In this paper we present a methodology allowing an emulated-3D two tiers physical implementation of any design using 2D commercial tools. Place and Route is achieved through similar steps as required by 2D designs: pre clock tree synthesis (including placement), clock tree synthesis and routing; to which we added a folding step in order to emulate the 3D placement. Routing of both tiers in parallel using inter-tier metal layers is made possible by modifying input files of the tools. Our study covers power supply network on both tiers, forbidden inter-tier via on active placement and inter-tier back end flavors in order to refine quality of results. Benchmark results on two tiers 3D Monolithic integration have been done on several IPs (microcontroller, reconfigurable FFT and LDPC) using as reference ST 28nm FDSOI technology and show the correlation between cell density, routing congestion, wire length, operating frequency and power consumption. To our knowledge, this paper is the first one to evaluate monolithic 3D physical implementation using full 3D Back End description and taking into account power supply distribution on both tiers.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092568","","Clocks;Copper;Routing;Standards;Three-dimensional displays;Tungsten","integrated circuit design;integrated circuit interconnections;network routing;silicon-on-insulator;three-dimensional integrated circuits","2D designs;3D back end description;3D monolithic integration;3D placement;LDPC;ST FDSOI technology;cell density;cell design;clock tree synthesis;commercial 2D tool;emulated-3D two tiers physical implementation;intertier metal layers;microcontroller;monolithic 3D cell;monolithic 3D physical implementation;power consumption;power supply distribution;power supply network;reconfigurable FFT;routing congestion;size 28 nm;wire length","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A fast spatial variation modeling algorithm for efficient test cost reduction of analog/RF circuits","Goncalves, H.; Xin Li; Correia, M.; Tavares, V.; Carulli, J.; Butler, K.","Carnegie Mellon Univ., Pittsburgh, PA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1042","1047","In this paper, we adopt a novel numerical algorithm, referred to as dual augmented Lagrangian method (DALM), for efficient test cost reduction based on spatial variation modeling. The key idea of DALM is to derive the dual formulation of the L<sub>1</sub>-regularized least-squares problem posed by Virtual Probe (VP), which can be efficiently solved with substantially lower computational cost than its primal formulation. In addition, a number of unique properties associated with discrete cosine transform (DCT) are exploited to further reduce the computational cost of DALM. Our experimental results of an industrial RF transceiver demonstrate that the proposed DALM solver achieves up to 38× runtime speed-up over the conventional interior-point solver without sacrificing any performance on escape rate and yield loss for test applications.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092543","","Algorithm design and analysis;Computational efficiency;Discrete cosine transforms;Optimization;Radio frequency;Runtime;Semiconductor device modeling","analogue circuits;discrete cosine transforms;least squares approximations;radio transceivers;radiofrequency integrated circuits","DALM;DCT;L1-regularized least-squares problem;RF circuits;RF transceiver;analog circuits;discrete cosine transform;dual augmented Lagrangian method;interior-point solver;numerical algorithm;spatial variation modeling algorithm;test cost reduction;virtual probe","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Technology-design co-optimization of resistive cross-point array for accelerating learning algorithms on chip","Pai-Yu Chen; Kadetotad, D.; Zihan Xu; Mohanty, A.; Binbin Lin; Jieping Ye; Vrudhula, S.; Jae-sun Seo; Yu Cao; Shimeng Yu","Arizona State Univ., Tempe, AZ, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","854","859","Technology-design co-optimization methodologies of the resistive cross-point array are proposed for implementing the machine learning algorithms on a chip. A novel read and write scheme is designed to accelerate the training process, which realizes fully parallel operations of the weighted sum and the weight update. Furthermore, technology and design parameters of the resistive cross-point array are co-optimized to enhance the learning accuracy, latency and energy consumption, etc. In contrast to the conventional memory design, a set of reverse scaling rules is proposed on the resistive cross-point array to achieve high learning accuracy. These include 1) larger wire width to reduce the IR drop on interconnects thereby increasing the learning accuracy; 2) use of multiple cells for each weight element to alleviate the impact of the device variations, at an affordable expense of area, energy and latency. The optimized resistive cross-point array with peripheral circuitry is implemented at the 65 nm node. Its performance is benchmarked for handwritten digit recognition on the MNIST database using gradient-based sparse coding. Compared to state-of-the-art software approach running on CPU, it achieves >10<sup>3</sup> speed-up and >10<sup>6</sup> energy efficiency improvement, enabling real-time image feature extraction and learning.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092504","cross-point array;machine learning;neuromorphic computing;resistive memory;synaptic device","Accuracy;Arrays;Encoding;Machine learning algorithms;Resistance;Wires","feature extraction;handwritten character recognition;learning (artificial intelligence)","MNIST database;energy consumption;gradient-based sparse coding;handwritten digit recognition;latency;machine learning algorithms;memory design;optimized resistive cross-point array;peripheral circuitry;real-time image feature extraction;reverse scaling rules;technology-design cooptimization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Thermal aware design method for VCSEL-based on-chip optical interconnect","Hui Li; Fourmigue, A.; Le Beux, S.; Letartre, X.; O'Connor, I.; Nicolescu, G.","Lyon Inst. of Nanotechnol., Ecole Centrale de Lyon, Ecully, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1120","1125","Optical Network-on-Chip (ONoC) is an emerging technology considered as one of the key solutions for future generation on-chip interconnects. However, silicon photonic devices in ONoC are highly sensitive to temperature variation, which leads to a lower efficiency of Vertical-Cavity Surface-Emitting Lasers (VCSELs), a resonant wavelength shift of Microring Resonators (MR), and results in a lower Signal to Noise Ratio (SNR). In this paper, we propose a methodology enabling thermal-aware design for optical interconnects relying on CMOS-compatible VCSEL. Thermal simulations allow designing ONoC interfaces with low gradient temperature and analytical models allow evaluating the SNR.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092556","ONoC;design methodology;thermal simulation","Heating;Optical interconnections;Optical sensors;Optical waveguides;Signal to noise ratio;Vertical cavity surface emitting lasers;Waveguide lasers","CMOS integrated circuits;integrated circuit interconnections;integrated optoelectronics;laser cavity resonators;laser noise;network-on-chip;optical interconnections;semiconductor lasers;surface emitting lasers","CMOS-compatible VCSEL;SNR;VCSEL-based on-chip optical interconnect;microring resonators;optical network-on-chip;resonant wavelength shift;signal-to-noise ratio;silicon photonic devices;thermal aware design method;thermal simulations;vertical-cavity surface-emitting lasers","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Designer-level verification — An industrial experience story","Bergman, S.; Bobok, G.; Kowalski, W.; Koyfman, S.; Moran, S.; Nevo, Z.; Orni, A.; Paruthi, V.; Roesner, W.; Shurek, G.; Vuyyuru, V.","IBM Corp., USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","410","411","Designer-level verification (DLV) is now widely accepted as a necessary practice in the hardware industry. More than ever, logic designers are held responsible for the initial validation of modules they develop, before these are released to systematic verification. DLV requires specific tools and methods adapted for designers, who are not full-time verification experts. We present user experience stories and usage statistics, describing how DLV has been practiced in our company, using a dedicated tool developed for this purpose. A typical pattern that emerges is of designers devoting short, fragmented time periods to DLV work, interleaved with other logic development tasks. We observe that the deployed DLV tool supports this mode of work, since it is simple and intuitive. This demonstrates that a suitable tool can help DLV become an integral part of a logic design project.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092424","","Companies;Delays;Hardware;Industries;Registers;Systematics;Testing","logic design;statistical analysis","DLV;designer-level verification;full-time verification experts;hardware industry;industrial experience story;logic design project;logic development tasks;module validation;systematic verification;usage statistics;user experience stories","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Giant spin hall effect (GSHE) logic design for low power application","Yaojun Zhang; Bonan Yan; Wenqing Wu; Hai Li; Yiran Chen","Dept. of Electr. & Comput. Eng., Univ. of Pittsburgh, Pittsburgh, PA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1000","1005","Conventional CMOS transistors will reach its power wall, a huge leakage power consumption limits the performance growth when technology scales down, especially beyond 45nm technology nodes. Spin based devices are one of the alternative computing technologies that aims to replace the current MOS based circuits by taking the advantage of their attractive characteristics, including non-volatility, high integration density and small cell area. The development of technologies such as spin-transfer torque random access memory (STT-RAM) and spin torque majority gate logic has become a story of great success. However, most of these technologies faces problems like, small operation margin, poor fan-out ability, etc. As the latest spin technology, Giant Spin Hall Effect (GSHE) Magnetic Tunneling Junction (MTJ) demonstrates a much better operation speed, switching probability and resistance margin. By leveraging the benefit of greater power efficiency and area density, GSHE MTJ elements become a suitable candidate for spintronic logic gates. Compare with traditional MOS transistors based logic gates, GSHE MTJ based logic can operate as a non-volatile memory and requires a much smaller number of elements to perform same logical operations (i.e., `AND', `OR', `NAND' or `NOR' gate.). And compare with other spin based logics, GSHE MTJ based logic also provides an better performance, excellent CMOS process compatibility and great fan-out ability.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092536","","Adders;CMOS integrated circuits;Logic gates;Resistance;Strips;Switches;Writing","CMOS memory circuits;logic design;logic gates;low-power electronics;magnetic tunnelling;power consumption;probability;random-access storage;spin Hall effect;switching circuits","CMOS process compatibility;CMOS transistors;GSHE MTJ based logic;GSHE MTJ elements;GSHE logic design;GSHE magnetic tunneling junction;MOS based circuits;MOS transistors based logic gates;NAND gate;NOR gate;STT-RAM;area density;computing technologies;giant spin Hall effect logic design;integration density;leakage power consumption;low power application;nonvolatile memory;power efficiency;resistance margin;spin based devices;spin based logics;spin torque majority gate logic;spin-transfer torque random access memory;spintronic logic gates;switching probability","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Exploration and design of embedded systems including neural algorithms","Philippe, J.-M.; Carbon, A.; Brousse, O.; Paindavoine, M.","Embedded Comput. Lab., CEA, Gif-sur-Yvette, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","986","991","The current trend in embedded systems is to make them surrounding the users, providing services thanks to a knowledge of their environment. These self-awareness and context-awareness properties are provided by numerous sensors, from different types. Using the provided information causes at least two problems: the fusion of data from different sources, and the noise induced by sensors which are closer from the processing unit than ever. Additionally, the needed applications that use these information are based on different recognition processings, sometimes not easy to formalize with conventional algorithms. Processing chains using neural-based algorithms are promising approaches for solving these kinds of issues. Unfortunately, embedding bio-inspired algorithms in an embedded system is not so easy since there is no exploration environment for this specific task. Moreover, neural networks often need pre- or postprocessing of data for optimal operation. In fact, there is a balance to find between pre-processing and neural network processing: for example, adding more filtering to clean or to transform data (like convolution filters or FFT) enables to have smaller neural networks, leading to less number of neurons, less learning time and finally more efficient applications. This paper presents early results of a collaboration towards the design of such an exploration environment coming from a joint laboratory between an SME and a Research Institute. The main object coming from the current collaboration is the coupling of a rich exploration environnement of embedded systems (including multi/manycore) with a neural network exploration tool. The combination of the two enables us to have feedbacks concerning both algorithm efficiency and performances and other non-functional metrics regarding the target system for driving the co-design cycle of industrial embedded systems.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092533","","Artificial neural networks;Biological neural networks;Embedded systems;Neurons;Program processors;Sensors;Timing","embedded systems;neural nets;sensor fusion;ubiquitous computing","FFT;bio-inspired algorithm;context-awareness property;convolution filters;embedded system;industrial embedded system;neural network exploration tool;neural-based algorithm;self-awareness property","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Feature selection for Alternate Test using wrappers: Application to an RF LNA case study","Barragan, M.J.; Leger, G.","TIMA, Grenoble, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1229","1232","Testing analog, mixed-signal and RF circuits represents the main cost component for testing complex SoCs. A promising solution to alleviate this cost is the Alternate Test strategy. Alternate test is an indirect test approach that replaces costly specification measurements by simpler signatures. Machine learning techniques are then used to map signatures and performances. One key point that still remains as an open problem is the conception of adequate simple measurement candidates. This work presents efficient algorithms for selecting information rich signatures.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092576","","Correlation;Envelope detectors;Integrated circuits;Principal component analysis;Radio frequency;Testing;Training","feature selection;integrated circuit testing;low noise amplifiers;radiofrequency amplifiers;system-on-chip","RF LNA;alternate test strategy;complex SoC testing;costly specification measurements;feature selection;indirect test approach;information rich signatures;machine learning techniques;simple measurement candidates;wrappers","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Reducing trace size in multimedia applications endurance tests","Tchagou, S.V.E.; Termier, A.; Mehaut, J.-F.; Videau, B.; Santana, M.; Ren Quiniou","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","984","985","Proper testing of applications over embedded systems such as set-top boxes requires endurance tests, i.e. running applications for extended periods of times, typically several days. In order to understand bugs or poor performances, execution traces have to be analyzed, however current trace analysis methods are not designed to handle several days of execution traces due to the huge quantity of data generated. Our proposal, designed for regular applications such as multimedia decoding/encoding, is to monitor execution by analyzing trace on the fly in order to record trace only in time periods where a suspicious activity is detected. Our experiments show a significant reduction in the trace size compared to recording the whole trace.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092532","","Computer bugs;Decoding;Electronic mail;Hardware;Monitoring;Multimedia communication;Streaming media","embedded systems;multimedia systems;program diagnostics;program testing;system monitoring","embedded system;execution monitoring;execution trace analysis;multimedia applications endurance test;trace size reduction","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Quick error detection tests with fast runtimes for effective post-silicon validation and debug","Lin, D.; Eswaran, S.; Kumar, S.; Rentschler, E.; Mitra, S.","Dept. of EE, Stanford Univ., Stanford, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1168","1173","Long error detection latency, the time elapsed from the occurrence of an error caused by a bug to its manifestation as an observable failure, severely limits the effectiveness of existing post-silicon validation and debug techniques. Traditional post-silicon validation tests can incur very long error detection latencies of millions or even billions of clock cycles. An earlier technique called Quick Error Detection (QED) shortens error detection latencies to only few hundred (or thousand) clock cycles. However, software-only QED (i.e., QED implemented entirely in software) can result in significantly increased post-silicon validation test runtimes. We present a new technique called Fast QED that overcomes this drawback of software-only QED, while preserving the error detection latency and bug coverage benefits of software-only QED. Simulation results using an OpenSPARC T2-like multi-core SoC and bugs abstracted from multiple commercial multi-core SoCs demonstrate: 1. Fast QED achieves 4 orders of magnitude improvement in test runtime as compared to software-only QED, with only 0.4% increase in chip area; 2. Fast QED improves error detection latencies by up to 5 orders of magnitude compared to non-QED tests, and also achieves improved error detection latencies compared to software-only QED; and, 3. Fast QED improves bug coverage by up to 2-fold compared to non-QED tests (similar to software-only QED).","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092564","Debug;Post-Silicon Validation;Quick Error Detection","Arrays;Cache memory;Clocks;Computer bugs;Memory architecture;Runtime;System-on-chip","elemental semiconductors;error detection;integrated circuit testing;logic testing;silicon;system-on-chip","OpenSPARC T2-like multi-core SoC;Si;debug;error detection latencies;post-silicon validation tests;quick error detection tests;software-only QED","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Automatic extraction of micro-architectural models of communication fabrics from register transfer level designs","Joosten, S.J.C.; Schmaltz, J.","Eindhoven Univ. of Technol., Eindhoven, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1413","1418","Multi-core processors and Systems-on-Chips are composed of a large number of processing and memory elements interconnected by complex communication fabrics. These fabrics are large systems made of many queues and distributed control logic. Recent studies have demonstrated that high levels models of these networks are either tractable for verification or can provide key invariants to improve hardware model checkers. Formally verifying Register Transfer Level (RTL) designs of these networks is an important challenge, yet still open. This paper bridges the gap between high level models and RTL designs. We propose an algorithm that from a Verilog description automatically produces its corresponding micro-architectural model. We prove that the extracted model is transfer equivalent to the original RTL circuit. We illustrate our approach on a typical example of communication fabrics: a scoreboard with credit-flow control.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092612","","Fabrics;Hardware design languages;Integrated circuit modeling;Mathematical model;Ports (Computers);Registers;Switches","formal verification;hardware description languages;high level synthesis;integrated circuit design;logic design;multiprocessing systems;system-on-chip","RTL circuit design;Verilog;automatic microarchitectural model extraction;complex communication fabrics;distributed control logic;formal verification;hardware model checker;high level model;memory element;multicore processor;processing element;register transfer level design;systems-on-chip","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Efficiency-driven design time optimization of a hybrid energy storage system with networked charge transfer interconnect","Qing Xie; Younghyun Kim; Donkyu Baek; Yanzhi Wang; Pedram, M.; Naehyuck Chang","Univ. of Southern California, Los Angeles, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1607","1610","This paper targets at the state-of-art hybrid energy storage systems (HESSs) with a networked charge transfer interconnect and solves a node placement problem in the HESS, where a node refers to a storage bank, a power source, or a load device, with its distributed power converter. In particular, the node placement problem is formulated as how to place the nodes in a HESS such that the optimal total charge transfer efficiency is achieved, with accurate modelings of all kinds of different components in the HESS. The methodology of FPGA placement problem is adopted to solve the node placement in HESS by properly defining a cost function that strongly relates the charge transfer efficiency to the node placement, properties of HESS components, as well as applications of the HESS. An algorithm that combines a quadratic programming method to generate an initial placement and a simulated annealing method to converge to the optimal placement result is presented in this paper. Experimental results demonstrate the efficacy of the placement algorithm and improvements in the charge transfer efficiency for various problem setups and scales.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092650","hybrid energy storage system;networked charge transfer interconnect;placement","Automation;Europe","charge exchange;energy storage;field programmable gate arrays;hybrid power systems;load distribution;power convertors;power system interconnection;quadratic programming;simulated annealing","FPGA placement problem;HESS efficiency driven design time optimization;cost function;distributed power converter;field programmable gate arrays;load device;networked charge transfer interconnect;node placement problem;power source;quadratic programming method;simulated annealing method;state-of-art hybrid energy storage system;storage bank","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"The human intranet — Where swarms and humans meet","Rabaey, J.M.","EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","637","640","A Human Intranet is envisioned as an open scalable platform that seamlessly integrates an ever-increasing number of sensor, actuation, computation, storage, communication and energy nodes located on, in, or around the human body acting in symbiosis with the functions provided by the body itself. This may fundamentally alter the ways humans operate, and interact with the physical world around them. It all starts with concepts that find their roots in the Internet of Things (IoT) and swarm technologies.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092467","Body-Area networks;Human-Machine interfaces;IoT;Swarms","Biology;Communication system security;Glass;Security;Smart phones;Wireless communication;Wireless sensor networks","Internet of Things;human computer interaction;intranets","Internet of Things;IoT;human intranet;open scalable platform;swarm technologies","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"DyReCTape: A dynamically reconfigurable cache using domain wall memory tapes","Ranjan, A.; Ramasubramanian, S.G.; Venkatesan, R.; Pai, V.; Roy, K.; Raghunathan, A.","Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","181","186","Spintronic memories offer superior density, non-volatility and ultra-low standby power compared to CMOS memories, and have consequently attracted great interest in the design of on-chip caches. Domain Wall Memory (DWM) is a spintronic memory technology with unparalleled density arising from a tape-like structure. However, such a structure involves serialized access to the bits stored in each bit-cell, resulting in increased access latency, and thereby degrading performance. Prior efforts address this challenge either by limiting the number of bits per tape, in effect sacrificing the density benefits of DWM, or through cache management policies that can only partly alleviate the shift overhead. We observe that there exists significant heterogeneity in sensitivity to cache capacity and access latency across different applications, and across distinct phases of an application. We also make the key observation that DWM tapes offer a natural mechanism to tradeoff density for access latency by limiting the number of domains of each tape that are actively used to store cache data. Based on this insight, we propose DyReCTape, a dynamically reconfigurable cache that packs maximum bits per tape and leverages the intrinsic capability of DWMs to modulate the active bits per tape with minimal overhead. DyReCTape uses a history-based reconfiguration policy that tracks the number of shift operations incurred and miss rate to appropriately tailor the capacity and access latency of the DWM cache. We further propose two performance optimizations to DyReCTape: (i) a lazy migration policy to mitigate the overheads of reconfiguration, and (ii) re-use of the portion of the cache that is unused (due to reconfiguration) as a victim cache to reduce the number of offchip accesses. We evaluate DyReCTape using applications from the PARSEC and SPLASH benchmark suites. Our experiments demonstrate that DyReCTape achieves 19.8% performance improvement over an iso-area SRAM cache and 11.7% perform- nce improvement (due to a 3.4X reduction in the number of shifts) over a state-of-the-art DWM cache.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092379","Cache Design;Domain Wall Memory;Racetrack Memory;Reconfigurable Caches;Spintronics","Arrays;Benchmark testing;Degradation;Optimization;Performance evaluation;Random access memory","cache storage;integrated circuit design;storage management chips","DWM tapes;DyReCTape;domain wall memory tapes;dynamically reconfigurable cache;history-based reconfiguration policy;iso-area SRAM cache;on-chip cache design;spintronic memory technology","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Operational fault detection and monitoring of a memristor-based LUT","Kumar, T.N.; Almurib, H.A.F.; Lombardi, F.","Dept. of Electr. & Electron. Eng., Univ. of Nottingham, Semenyih, Malaysia","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","429","434","This paper presents a method for operational testing of a memristor-based memory look-up table (LUT). In the proposed method, the deterioration of the memristors (as storage elements of a LUT) is modeled based on the reduction of the resistance range as observed in fabricated devices and recently reported in the technical literature. A quiescent current technique is used for testing the memristors when deterioration results in a change of state, thus leading to an erroneous (faulty) operation. An equivalent circuit model of the operational deterioration for a memristor-based LUT is presented. In addition to modeling and testing, the proposed method can be utilized also for continuous monitoring of the LUT in the presence of memristor deterioration in the LUT. The proposed method is assessed using LTSPICE; extensive simulation results are presented with respect to different operational features, such as LUT dimension and range of resistance. These results show that the proposed test method is scalable with LUT dimension and highly efficient for testing and monitoring a LUT in the presence of deteriorating multiple memristors.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092428","Memristor;deterioration;monitoring;quiescent current;testing","Circuit faults;Current measurement;Electrical resistance measurement;Memristors;Resistance;Table lookup;Testing","SPICE;equivalent circuits;fault diagnosis;memristors;table lookup","LTSPICE;change of state;device fabrication;equivalent circuit model;memristor operational deterioration;memristor-based LUT dimension;memristor-based memory lookup table;operational fault detection;operational fault monitoring;operational testing;quiescent current technique;resistance range reduction;technical literature","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Impact of process-variations in STTRAM and adaptive boosting for robustness","Motaman, S.; Ghosh, S.; Rathi, N.","Comput. Sci. & Eng., Univ. of South Florida, Tampa, FL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1431","1436","Spin-Torque Transfer Random Access Memory (STTRAM) is a promising technology for high density on-chip cache due to low standby power. Additionally, it offers fast access time, good endurance and retention. However, it suffers from poor write latency and write power. Additionally we observe that process variation can result in large spread in write and read latency variations. The performance of conventionally designed STTRAM cache can degrade as much as 10% due to process variations. We propose a novel and adaptive write current boosting to address this issue. The bits experiencing worst-case write latency are fixed through write current boosting. Simulations show 80% power improvement compared to boosting all bit-cells and 13% performance improvement compared to worst case latency due to process variation over a wide range of PARSEC benchmarks.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092615","Process variation;STTRAM;Variation tolerant design;write current boosting;write power","Benchmark testing;Boosting;Curve fitting;Magnetic tunneling;Mathematical model;Monte Carlo methods;Random access memory","SRAM chips;cache storage;learning (artificial intelligence)","PARSEC benchmarks;STTRAM cache;access time;adaptive write current boosting;bit-cells;high density on-chip cache;low standby power;process-variation impact;spin-torque transfer random access memory;write latency;write power","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A scan partitioning algorithm for reducing capture power of delay-fault LBIST","Nan Li; Dubrova, E.; Carlsson, G.","R. Inst. of Technol., Stockholm, Sweden","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","842","847","It is well-known that high power consumption in test mode can cause problems such as overheating and IR-drop which have negative effect on circuit reliability and yield. The problem is particularly hard in the case of at-speed delay-fault testing where it cannot be mitigated by lowering the clock frequency. The difficulty increases even further if pseudo-random rather than ATPG patterns are used for testing. ATPG patterns can be chosen selectively, as well as re-ordered and specified in a power-friendly manner. Pseudo-random test patterns are much harder to control. In this paper, we present a scan partitioning algorithm for reducing capture power targeting delay-fault LBIST. The algorithm uses a novel weighted S-graph model in which the weights are determined by signal probability analysis. Our experimental results show that, on average, the presented method reduces average capture power by 50% and peak capture power by 39% with less than 2% loss in the transition fault coverage.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092502","","Automatic test pattern generation;Built-in self-test;Circuit faults;Logic gates;Partitioning algorithms;Power demand","automatic test pattern generation;built-in self test;circuit reliability;fault simulation;graph theory;logic testing;probability","ATPG patterns;IR-drop;S-graph model;at-speed delay-fault testing;automatic test pattern generator;capture power targeting delay-fault LBIST;circuit reliability;clock frequency;logic built in self test;overheating;power-friendly manner;pseudorandom test patterns;scan partitioning algorithm;signal probability analysis","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A score-based classification method for identifying Hardware-Trojans at gate-level netlists","Oya, M.; Youhua Shi; Yanagisawa, M.; Togawa, N.","Dept. of Comput. Sci. & Commun. Eng., Waseda Univ., Tokyo, Japan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","465","470","Recently, digital ICs are often designed by outside vendors to reduce design costs in semiconductor industry, which may introduce severe risks that malicious attackers implement Hardware Trojans (HTs) on them. Since IC design phase generates only a single design result, an RT-level or gate-level netlist for example, we cannot assume an HT-free netlist or a Golden netlist and then it is too difficult to identify whether a generated netlist is HT-free or HT-inserted. In this paper, we propose a score-based classification method for identifying HT-free or HT-inserted gate-level netlists without using a Golden netlist. Our proposed method does not directly detect HTs themselves in a gate-level netlist but a net included in HTs, which is called Trojan net, instead. Firstly, we observe Trojan nets from several HT-inserted benchmarks and extract several their features. Secondly, we give scores to extracted Trojan net features and sum up them for each net in benchmarks. Then we can find out a score threshold to classify HT-free and HT-inserted netlists. Based on these scores, we can successfully classify HT-free and HT-inserted netlists in all the Trust-HUB gate-level benchmarks. Experimental results demonstrate that our method successfully identify all the HT-inserted gate-level benchmarks to be “HT-inserted” and all the HT-free gate-level benchmarks to be “HT-free” in approximately three hours for each benchmark.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092434","classification;gate-level netlist;golden-IC free;hardware Trojans;identification","Adders;Benchmark testing;Feature extraction;Integrated circuits;Logic gates;Logic testing;Trojan horses","benchmark testing;feature extraction;integrated circuit design;invasive software;pattern classification;semiconductor industry","Golden netlist;HT-free gate-level benchmarks;HT-free netlist;HT-inserted gate-level benchmarks;HT-inserted netlist;IC design phase;RT-level netlist;Trojan net feature extraction;Trust-HUB gate-level benchmarks;digital ICs;gate-level netlist;hardware-trojan identification;malicious attackers;score-based classification method;semiconductor industry","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A coupling area reduction technique applying ODC shifting","Yi Diao; Tak-Kei Lam; Xing Wei; Yu-Liang Wu","Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Hong Kong, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1461","1466","Circuit size reduction is a basic problem in today's integrated circuit (IC) design. Besides yielding a smaller area, reducing circuit size can also provide advantages in many operations throughout the design flow, including technology mapping, verification and place-and-route. In recent years, some node based logic synthesis algorithms have been proposed for this purpose. Node Addition and Removal (NAR) and Observability Don't Cares (ODCs) based node merging were found to be quite effective in reducing the number of nodes in a netlist. However, both methods do not address the effect of re-distributing ODCs and the results are virtually fixed after one iteration run. We study the implications of redistributing ODCs and propose a node-based and wire-based coupling synthesis scheme that can effectively And better solutions with the application of ODC shifting operations. Experimental results show that this approach can produce area reductions nearly double of the pure node-based algorithms.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092620","Area Reduction;Logic synthesis;Node merging;Rewiring","Automation;Decision support systems;Europe;Hafnium","integrated circuit design","NAR;ODC shifting;area reduction technique;circuit size reduction;design flow;integrated circuit design;logic synthesis algorithms;netlist;node addition and removal;node merging were;node-based coupling synthesis scheme;observability don't cares;pure node-based algorithms;technology mapping;wire-based coupling synthesis scheme","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Timing verification for adaptive integrated circuits","Kumar, R.; Bing Li; Yiren Shen; Schlichtmann, U.; Jiang Hu","Dept. of Electr. & Comput. Eng., Texas A&M Univ., College Station, TX, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1587","1590","An adaptive circuit can perform built-in self-detection of timing variations and accordingly adjust itself to avoid timing violations. Compared with conventional over-design approach, adaptive circuit design is conceptually advantageous in terms of power-efficiency. Although the advantage has been witnessed in numerous previous works including test chips, adaptive design is far from being widely used in practice. A key reason is the lack of corresponding timing verification support. We develop new timing analysis techniques to fill this void. A main challenge is the large runtime complexity due to numerous adaptivity configurations. We propose several pruning and reduction techniques and apply them in conjunction with statistical static timing analysis (SSTA). The proposed method is validated on benchmark circuits including the recent ISPD'13 suite, which has circuit as large as 150K gates. The results show that our method can achieve orders of magnitude speedup over Monte Carlo simulation with about the same accuracy. It is also several times faster than an exhaustive application of SSTA.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092645","","Benchmark testing;Central Processing Unit;Circuit synthesis;Logic gates;Monte Carlo methods;Sensors;Timing","benchmark testing;integrated circuit design;statistical analysis;timing","SSTA;adaptive circuit design;adaptivity configurations;benchmark circuits;built-in self-detection;large runtime complexity;statistical static timing analysis;timing analysis techniques;timing variations;timing verification support","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Algorithmic Principles<sup>1</sup>","Arumugam, Guru Prakash; Augustine, John; Upfal, Eli; Parishkrati; Srikanthan, Prashanth; Palem, Krishna; Bhargava, Ayush; Yenugula, Sreelatha","Department of Computer Science and Engineering, Indian Institute of Technology Madras, Chennai, India","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","752","757","It is increasingly accepted that energy savings can be achieved by trading the accuracy of a computing system for energy gains — quite often significantly. This approach is referred to as inexact or approximate computing. Given that a significant portion of the energy in a modern general purpose processor is spent on moving data to and from storage, and that increasingly data movement contributes significantly to activity during the execution of applications, it is important to be able to develop techniques and methodologies for inexact computing in this context. To accomplish this to its fullest level, it is important to start with algorithmic specifications and alter their intrinsic design to take advantage of inexactness. This calls for a new approach to inexact memory aware algorithm design (IMAD) or co-design. In this paper, we provide the theoretical foundations which include novel models as well as technical results in the form of upper and lower bounds for IMAD in the context of universally understood and canonical problems: variations of sorting, and string matching. Surprisingly, IMAD allowed us to design entirely error-free algorithms while achieving energy gain factors of 1.5 and 5 in the context of sorting and string matching when compared to their traditional (textbook) algorithms. IMAD is also amenable to theoretical analysis and we present several asymptotic bounds on energy gains.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092487","","Algorithm design and analysis;Arrays;Computational modeling;Delays;Energy consumption;Energy states;Sorting","","","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"SAPPHIRE: An always-on context-aware computer vision system for portable devices","Venkataramani, S.; Bahl, V.; Xian-Sheng Hua; Jie Liu; Jin Li; Phillipose, M.; Priyantha, B.; Shoaib, M.","Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1491","1496","Being aware of objects in the ambient provides a new dimension of context awareness. Towards this goal, we present a system that exploits powerful computer vision algorithms in the cloud by collecting data through always-on cameras on portable devices. To reduce communication-energy costs, our system allows client devices to continually analyze streams of video and distill out frames that contain objects of interest. Through a dedicated image-classification engine SAPPHIRE, we show that if an object is found in 5% of all frames, we end up selecting 30% of them to be able to detect the object 90% of the time: 70% data reduction on the client device at a cost of ≤ 60 mW of power (45 nm ASIC). By doing so, we demonstrate system-level energy reductions of ≥ 2×. Thanks to multiple levels of pipelining and parallel vector-reduction stages, SAPPHIRE consumes only 3.0 mJ/frame and 38 pJ/OP - estimated to be lower by 11.4× than a 45 nm GPU - and a slightly higher level of peak performance (29 vs. 20 GFLOPS). Further, compared to a parallelized sofware implementation on a mobile CPU, it provides a processing speed up of up to 235× (1.81 s vs. 7.7 ms/frame), which is necessary to meet the real-time processing needs of an always-on context-aware system.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092625","Always on;computer vision;energy efficiency;hardware acceleration;object recognition;portable devices","Algorithm design and analysis;Cameras;Computational modeling;Engines;Pipeline processing;Software algorithms","application specific integrated circuits;computer vision;image classification;ubiquitous computing","ASIC;SAPPHIRE;always-on context-aware computer vision system;communication-energy cost reduction;data reduction;image-classification engine;mobile CPU;parallel vector-reduction stage;pipelining stage;portable devices","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"PWL: A progressive wear leveling to minimize data migration overheads for NAND flash devices","Fu-Hsin Chen; Ming-Chang Yang; Yuan-Hao Chang; Tei-Wei Kuo","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ., Taipei, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1209","1212","As the endurance of flash memory keeps deteriorating, exploiting wear leveling techniques to improve the lifetime/endurance of flash memory has become a critical issue in the design of flash storage devices. In contrast to existing wear-leveling techniques that aggressively distributes the erases to all flash blocks by a fixed threshold, we propose a progressive wear leveling design to perform wear leveling in a ""progressive"" way to prevent any block from being worn out prematurely, and thereby to ultimately minimize the performance overheads caused by the unnecessary data migration. The results reveal that, instead of sacrificing the device lifetime, performing wear leveling in such a progressive way can not only minimize the performance overheads but even have potentials to extend the device lifespan.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092571","","Automation;Decision support systems;Europe;File systems","NAND circuits;flash memories","NAND flash devices;PWL;data migration overhead minimization;fixed threshold;flash memory;performance overheads;progressive wear leveling design;wear-leveling techniques","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Automated rectification methodologies to functional state-space unreachability","Berryhill, R.; Veneris, A.","ECE Dept., Univ. of Toronto, Toronto, ON, Canada","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1401","1406","In the modern design cycle, significant manual resources are dedicated to fix a design when verification shows that a state is not reachable. Today there is little automation to aid an engineer in understanding why a state is not reachable and how to correct it. This paper presents a novel methodology that automates this task. In detail, a process that involves intertwined steps of state approximation, reachability analysis and traditional debugging is developed to identify design locations where fixes can be applied so the target state becomes reachable. An initial formulation identifies such error locations that, when corrected, can make the target state reachable directly from the existing reachable set of states. This is later extended for the cases where more than one state transition is required to reach an unreachable state from the existing reachable set. Empirical results on industrial level designs show a performance which is an order of magnitude faster than the state-of-the-art confirming the practicality of the proposed automated methodology.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092610","","Accuracy;Algorithm design and analysis;Approximation algorithms;Approximation methods;Debugging;Reachability analysis;Silicon","computability;electronic design automation;reachability analysis;state-space methods","SAT-based automated debugging;automated rectification methodologies;functional state-space unreachability;reachability analysis;reachable set;state approximation;state transition","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Exploiting dynamic timing margins in microprocessors for frequency-over-scaling with instruction-based clock adjustment","Constantin, J.; Lai Wang; Karakonstantis, G.; Chattopadhyay, A.; Burg, A.","Telecommun. Circuits Lab., EPFL, Lausanne, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","381","386","Static timing analysis provides the basis for setting the clock period of a microprocessor core, based on its worst-case critical path. However, depending on the design, this critical path is not always excited and therefore dynamic timing margins exist that can theoretically be exploited for the benefit of better speed or lower power consumption (through voltage scaling). This paper introduces predictive instruction-based dynamic clock adjustment as a technique to trim dynamic timing margins in pipelined microprocessors. To this end, we exploit the different timing requirements for individual instructions during the dynamically varying program execution flow without the need for complex circuit-level measures to detect and correct timing violations. We provide a design flow to extract the dynamic timing information for the design using post-layout dynamic timing analysis and we integrate the results into a custom cycle-accurate simulator. This simulator allows annotation of individual instructions with their impact on timing (in each pipeline stage) and rapidly derives the overall code execution time for complex benchmarks. The design methodology is illustrated at the microarchitecture level, demonstrating the performance and power gains possible on a 6-stage OpenRISC in-order general purpose processor core in a 28nm CMOS technology. We show that employing instruction-dependent dynamic clock adjustment leads on average to an increase in operating speed by 38% or to a reduction in power consumption by 24%, compared to traditional synchronous clocking, which at all times has to respect the worst-case timing identified through static timing analysis.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092418","","Benchmark testing;Clocks;Delays;Microarchitecture;Optimization;Pipelines","CMOS digital integrated circuits;benchmark testing;clocks;instruction sets;microprocessor chips;pipeline processing;power aware computing;reduced instruction set computing;synchronisation;timing","6-stage OpenRISC in-order general purpose processor core;CMOS technology;complex circuit-level measures;custom cycle-accurate simulator;dynamic timing margins;dynamically varying program execution flow;frequency-over-scaling;instruction-based clock adjustment;instruction-dependent dynamic clock adjustment;microprocessor core;pipelined microprocessors;post-layout dynamic timing analysis;power consumption;predictive instruction-based dynamic clock adjustment;size 28 nm;static timing analysis;synchronous clocking;voltage scaling;worst-case critical path","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"GTFUZZ: A novel algorithm for robust dynamic power optimization via gate sizing with fuzzy games","Casagrande, T.; Ranganathan, N.","Dept. of Comput. Sci. & Eng., Univ. of South Florida, Tampa, FL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","677","682","As CMOS technology continues to scale, the effects of variation inject a greater proportion of error and uncertainty into the design process. Ultra-deep submicron circuits require accurate modeling of gate delay in order to meet challenging timing constraints. With the lack of statistical data, designers are faced with a arduous task to optimize a circuit which is greatly affected by variability due to the mechanical and chemical manufacturing process. Discrete gate sizing is a complex problem which requires (1) accurate models that take into account random parametric variation and (2) a fair allocation of resources to maximize the solution in the delay-energy space. The GTFUZZ algorithm is presented which handles both of these tasks. Fuzzy games are used to model the problem of gate sizing as a resource allocation problem. In fuzzy games, delay is considered a fuzzy goal with fuzzy parameters to capture the imprecision of gate delay early in the design phase when empirical data is absent. Dynamic power is normalized as a fuzzy goal without varying coefficients. The fuzzy goals also provide a flexible platform for multimetric optimization. The robust GTFUZZ (Fuzzy Game Theory) algorithm is compared against fuzzy linear programming (FLP) and deterministic worst-case FLP (DWCFLP) algorithms. Benchmark circuits are first synthesized, placed, routed, and optimized for performance using the Synopsys University 32/28nm standard cell library and technology files. Operating at the optimized clock frequency, results show an average power reduction of about 20% versus DWCFLP and 9% against variation-aware gate sizing with FLP. Timing and timing yield are verified by both Synopsys PrimeTime and Monte Carlo simulations of the most critical paths using HSPICE.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092474","","Algorithm design and analysis;Delays;Games;Integrated circuit modeling;Logic gates;Optimization","circuit optimisation;fuzzy set theory;game theory;integrated circuit design;low-power electronics","CMOS technology;GTFUZZ algorithm;Ultradeep submicron circuit;circuit variability;discrete gate sizing;fair resource allocation;fuzzy game theory algorithm;fuzzy games;fuzzy goal;fuzzy parameter;gate delay;most critical path;optimized clock frequency;random parametric variation;robust dynamic power optimization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Volume-oriented sample preparation for reactant minimization on flow-based microfluidic biochips with multi-segment mixers","Chi-Mei Huang; Chia-Hung Liu; Juinn-Dar Huang","Dept. of Electron. Eng. & Inst. of Electron., Nat. Chiao Tung Univ., Hsinchu, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1114","1119","Sample preparation is one of essential processes in most biochemical reactions. In this process, raw reactants are diluted to achieve given target concentrations. So far, most of existing sample preparation techniques only consider mixing of two source solutions under the (1:1) mixing model. In this paper, we propose the first sample preparation algorithm VOSPA that not only blends several (≥ 2) solutions in a dilution operation but also allows various mixing models on flow-based microfluidic biochips with multi-segment mixers. VOSPA is a volume-oriented sample preparation algorithm that enables segment-based intermediate solution reuse for better reactant minimization. Experimental results show that VOSPA can lower the reactant consumption and operation count by 72% and 59% as compared to the baseline bit-scanning method if an 8-segment mixer is used. Moreover, VOSPA outperforms an optimal algorithm, which merely allows the use of (1:1) mixing model; the reactant usage and operation count can be further reduced by 37% and 76%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092555","Biochip;dilution;flow-based microfluidic biochip;mixing model;reactant minimization;sample preparation","Automation;Biological system modeling;Microfluidics;Minimization;Mixers;Optimized production technology;Valves","bioMEMS;biochemistry;lab-on-a-chip;microfluidics","8-segment mixer;baseline bit-scanning method;biochemical reaction;flow-based microfluidic biochip;multisegment mixers;operation count;raw reactant;reactant consumption;reactant minimization;segment-based intermediate solution reuse;volume-oriented sample preparation algorithm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Leakage power reduction for deeply-scaled FinFET circuits operating in multiple voltage regimes using fine-grained gate-length biasing technique","Ji Li; Qing Xie; Yanzhi Wang; Nazarian, S.; Pedram, M.","Dept. of Electr. Eng., Univ. of Southern California, Los Angeles, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1579","1582","With the aggressive downscaling of the process technologies and importance of battery-powered systems, reducing leakage power consumption has become one of the most crucial design challenges for IC designers. This paper presents a device-circuit cross-layer framework to utilize fine-grained gate-length biased FinFETs for circuit leakage power reduction in the near- and super-threshold operation regimes. The impacts of Gate-Length Biasing (GLB) on circuit speed and leakage power are first studied using one of the most advanced technology nodes - a 7nm FinFET technology. Then multiple standard cell libraries using different leakage reduction techniques, such as GLB and Dual-V<sub>T</sub>, are built in multiple operating regimes at this technology node. It is demonstrated that, compared to Dual-V<sub>T</sub>, GLB is a more suitable technique for the advanced 7nm FinFET technology due to its capability of delivering a finer-grained trade-off between the leakage power and circuit speed, not to mention the lower manufacturing cost. The circuit synthesis results of a variety of ISCAS benchmark circuits using the presented GLB 7nm FinFET cell libraries show up to 70% leakage improvement with zero degradation in circuit speed in the near- and super-threshold regimes, respectively, compared to the standard 7nm FinFET cell library.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092643","","Automation;Benchmark testing;Decision support systems;Europe;FinFETs;Libraries;Standards","CMOS integrated circuits;MOSFET;electrical faults;integrated circuit design;low-power electronics","FinFET technology;deeply scaled FinFET circuit;device-circuit cross-layer framework;fine grained gate length biased FinFET;fine grained gate length biasing technique;integrated circuit design;leakage power reduction;multiple voltage FinFET circuit;size 7 nm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"SCANDALee: A side-ChANnel-based DisAssembLer using local electromagnetic emanations","Strobel, D.; Bache, F.; Oswald, D.; Schellenberg, F.; Paar, C.","Horst-Gortz Inst. for IT Security, Ruhr Univ. Bochum, Bochum, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","139","144","Side-channel analysis has become a well-established topic in the scientific community and industry over the last one and a half decade. Somewhat surprisingly, the vast majority of work on side-channel analysis has been restricted to the “use case” of attacking cryptographic implementations through the recovery of keys. In this contribution, we show how side-channel analysis can be used for extracting code from embedded systems based on a CPU's electromagnetic emanation. There are many applications within and outside the security community where this is desirable. In cryptography, it can, e.g., be used for recovering proprietary ciphers and security protocols. Another broad application field is general security and reverse engineering, e.g., for detecting IP violations of firmware or for debugging embedded systems when there is no debug interface or it is proprietary. A core feature of our approach is that we take localized electromagnetic measurements that are spatially distributed over the IC being analyzed. Given these multiple inputs, we model code extraction as a classification problem that we solve with supervised learning algorithms. We apply a variant of linear discriminant analysis to distinguish between the multiple classes. In contrast to previous approaches, which reported instruction recognition rates between 40-70%, our approach detects more than 95% of all instructions for test code, and close to 90% for real-world code. The methods are thus very relevant for use in practice. Our method performs dynamic code recognition, which has both advantages (only the program parts that are actually executed are observed) but also limitations (rare code executions are difficult to observe).","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092372","","Algorithm design and analysis;Clocks;Feature extraction;Position measurement;Probes;Reverse engineering;Security","cryptographic protocols;firmware;learning (artificial intelligence);program debugging;reverse engineering","SCANDALee;classification problem;cryptography;dynamic code recognition;embedded system debugging;firmware IP violation detection;general security;linear discriminant analysis;local electromagnetic emanations;localized electromagnetic measurements;proprietary ciphers;reverse engineering;security protocols;side-channel analysis;side-channel-based disassembler;supervised learning algorithm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"NFRs early estimation through software metrics","Vieira, A.; Faustini, P.; Carro, L.; Cota, E.","PPGC - Inf. Inst., Fed. Univ. of Rio Grande do Sul (UFRGS), Porto Alegre, Brazil","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","329","332","We propose the use of regression analysis to generate accurate predictive models for physical metrics using design metrics as input. We validate our approach with 40+ implementations of three systems in two development scenarios: system evolution and first design. Results show maximum prediction errors of 1.66% during system evolution. In a first design scenario, the average error is 15% with the maximum error still below 20% for all physical metrics. This approach provides a fast and accurate strategy to boost embedded software productivity and quality, by estimating Non-Functional Requirements (NFRs) during the first design stages.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092409","Embedded Systems;Performance Estimation;Regression Analysis;Software Metrics","Automation;Decision support systems;Embedded systems;Estimation;Europe;Regression analysis;Software metrics","regression analysis;software metrics;software quality","NFR early estimation;design metrics;embedded software productivity;embedded software quality;maximum prediction errors;nonfunctional requirements;physical metrics;predictive models;regression analysis;software metrics","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"VARSHA: Variation and reliability-aware application scheduling with adaptive parallelism in the dark-silicon era","Kapadia, N.; Pasricha, S.","Dept. of Electr. & Comput. Eng., Colorado State Univ., Fort Collins, CO, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1060","1065","With deeper technology scaling accompanied by a worsening power-wall, an increasing proportion of chip area on a chip multiprocessor (CMP) is expected to be occupied by dark-silicon. At the same time, design challenges due to process variations and soft-errors in integrated circuits are projected to become even more severe. In this work, we propose a novel framework that leverages the knowledge of variations on the chip to perform runtime application mapping and dynamic voltage scaling to optimize system performance and energy, while satisfying dark-silicon power-constraints of the chip as well as application-specific performance and reliability constraints. Our experimental results show average savings of 35%-80% in application service-times and 13%-15% in energy consumption, compared to the state-of-the-art.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092546","","Automation;Delays;Europe;Parallel processing;Reliability engineering;Voltage control","parallel processing;power aware computing;reliability;scheduling","VARSHA;adaptive parallelism;application service-times;dark-silicon power constraints;dynamic voltage scaling;energy consumption;runtime application mapping;variation and reliability-aware application scheduling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Subpage programming for extending the lifetime of NAND flash memory","Jung-Hoon Kim; Sang-Hoon Kim; Jin-Soo Kim","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","555","560","During the past decade, the density of NAND flash memory has been increased in many folds. The increase has been driven by storing multiple bits in a cell and scaling down the fabrication process. Such advance in manufacturing technology, however, has been significantly impaired the reliability of flash memory so that it becomes one of the major concerns in use of flash memory. Moreover, as flash memory writes data in the unit of flash page, the trend of the increase in page size worsens the reliability by amplifying a small update to a full flash page programming. In this paper, we propose a new programming method to improve the flash endurance cycle, especially when a small amount of data are written repeatedly. The proposed method, so called “subpage programming”, partitions a page into smaller subpages. A small amount of data can be programmed to one of the subpages while the other subpages are inhibited from the programming by leveraging the mechanisms of flash cell programming. Thus, the number of flash cells that undergo programming is minimized. We evaluated the effect of the proposed subpage programming on real NAND flash memory chips from three different manufacturers. Our evaluation results show that subpage programming improves the flash endurance cycle by up to 258%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092449","","Arrays;Ash;Benchmark testing;Logic gates;Programming;Reliability;Substrates","NAND circuits;flash memories;reliability","NAND flash memory chips;flash cell programming;flash endurance cycle;subpage programming","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Detection of illegitimate access to JTAG via statistical learning in chip","Xuanle Ren; Grade Tavares, V.; Blanton, R.D.","Dept. of Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","109","114","IEEE 1149.1, commonly known as the joint test action group (JTAG), is the standard for the test access port and the boundary-scan architecture. The JTAG is primarily utilized at the time of the integrated circuit (IC) manufacture but also in the field, giving access to internal sub-systems of the IC, or for failure analysis and debugging. Because the JTAG needs to be left intact and operational for use, it inevitably provides a “backdoor” that can be exploited to undermine the security of the chip. Potential attackers can then use the JTAG to dump critical data or reverse engineer IP cores, for example. Since an attacker will use the JTAG differently from a legitimate user, it is possible to detect the difference using machine-learning algorithms. A JTAG protection scheme, SLIC-J, is proposed to monitor user behavior and detect illegitimate accesses to the JTAG. Specifically, JTAG access is characterized using a set of specifically-defined features, and then an on-chip classifier is used to predict whether the user is legitimate or not. To validate the effectiveness of the approach, both legitimate and illegitimate JTAG accesses are simulated using the OpenSPARC T2 benchmark. The results show that the detection accuracy is 99.2%, and the escape rate is 0.8%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092367","","Accuracy;Debugging;Decision trees;Feature extraction;System-on-chip;Table lookup;Testing","IEEE standards;circuit analysis computing;integrated circuit testing;learning (artificial intelligence);pattern classification;security","IEEE 1149.1;JTAG protection scheme;OpenSPARC T2 benchmark;SLIC-J;illegitimate access detection;joint test action group;on-chip classifier;statistical learning","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"SubHunter: A high-performance and scalable sub-circuit recognition method with Prüfer-encoding","Hong-Yan Su; Chih-Hao Hsu; Yih-Lang Li","Inst. of Comput. Sci. & Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1583","1586","Sub-circuit recognition (SR) is a problem of recognizing sub-circuits within a given circuit and is a fundamental component in simulation, verification and testing of computer-aided design. The SR problem can be formulated as subgraph isomorphism problem. Performance of previous works is not scalable as the complexities of modern designs increase. In this paper we propose a novel Prüfer-encoding based SR algorithm that performs scalable and high-performance sub-circuit matching. Several techniques including tree structure partition, tree cutting and circuit graph encoding are proposed herein to decompose the SR problem into several small sub-sequence matching problems. A pre-filtering strategy is applied before matching to remove the sub-circuits that are not likely to be matched. A fast branch and bound approach is developed to identify all the sub-circuits within the given circuit. Experimental results show that SubHunter can achieve better performance than SubGemini and detect all the sub-circuits as well. As the circuit size increases, we can also achieve near linear runtime growth that outperforms the exponential growth for SubGemini, showing the scalability of the proposed algorithm.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092644","Prüfer encoding;Sub-circuit recognition;graph isomorphism","Algorithm design and analysis;Cascading style sheets;Encoding;Partitioning algorithms;Random access memory;Runtime;Vegetation","CAD;encoding;graph theory;integrated circuit design;isomorphism;network synthesis","Prüfer-encoding;SubGemini;SubHunter;circuit graph encoding;computer-aided design;prefiltering strategy;subcircuit matching;subcircuit recognition method;subgraph isomorphism problem;subsequence matching problems;tree cutting;tree structure partition","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A cyber-physical systems approach to personalized medicine: Challenges and opportunities for NoC-based multicore platforms","Bogdan, P.","Dept. of Electr. Eng., Univ. of Southern California, Los Angeles, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","253","258","This paper describes a few fundamental challenges concerning the design of Network-on-Chip (NoC) based multicores as the backbone of cyber-physical systems (CPS) for personalized medicine. One fundamental challenge in designing such CPS architectures is the need for a unifying mathematical description of the dynamical interactions between bio-physiological processes and cyber states. Another fundamental challenge is to build a rigorous mathematical optimization framework that allows the CPS to adapt to varying workloads and demands. To enable large-scale parallelism, we need a rigorous understanding of the CPS workloads that can guide the design and optimization of wired and wireless NoCs. We advocate for the development of goal-oriented self-organization algorithms that seek to both optimize specific design cost functions and maximize information about future system state. It is necessary to identify basic local rules of interaction not only for solving large scale optimization problems in a distributed fashion, but also for inducing an overall degree of autonomy and intelligence in the CPS architecture.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092391","Cyber-physical systems;adaptive autonomous systems;goal-oriented self-organization;highly-variable workloads;multicore platforms;networks-on-chip;non-stationary fractal behavior;personalized medicine;real-time performance guarantees;scalability","Artificial intelligence;Automation;Channel hot electron injection;DH-HEMTs;Europe","medical computing;multiprocessing systems;network-on-chip;optimisation","CPS architectures;NoC-based multicore platforms;cyber-physical systems approach;goal-oriented self-organization algorithm;large-scale parallelism;mathematical optimization framework;network-on-chip based multicores;personalized medicine","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"E-pipeline: Elastic hardware/software pipelines on a many-core fabric","Xi Zhang; Javaid, H.; Shafique, M.; Peddersen, J.; Henkel, J.; Parameswaran, S.","Sch. of Comput. Sci. & Eng., Univ. of New South Wales, Sydney, NSW, Australia","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","363","368","On-chip many-core systems are expected to be in common use in the future. A set of homogeneous processors in a many-core system can be used to implement multiple pipelines which execute simultaneously. Pipelines of processors use varying numbers of cores when their workloads vary at run time. In this paper, we show how such a system executing multiple pipelines with varying workloads can be implemented. We further show how the system can switch cores within a pipeline (intra-elasticity) and between pipelines (inter-elasticity). The method is named E-pipeline, and is implemented and evaluated in a commercial tool suite. Compared to reference design methods with clock gating, E-pipeline achieves the same power savings, maintains the throughput to meet throughput constraints and reduces core usage by an average of 37.7%. The adaptation overhead for switching cores is approximately 2μs.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092415","","Benchmark testing;Clocks;Cloning;Hardware;Pipelines;Software;Throughput","microprocessor chips;multiprocessing systems;pipeline processing","e-pipeline;elastic hardware pipelines;many-core fabric;multiple pipelines;software pipelines","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"De-elastisation: From asynchronous dataflows to synchronous circuits","Mamaghani, M.J.; Garside, J.; Edwards, D.","Sch. of Comput. Sci., Univ. of Manchester, Manchester, UK","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","273","276","Asynchronous VLSI programming provides a flexible abstract formalism for concurrent systems but the is an issue for industrial adoption. The asynchronous design paradigm provides `elasticity' enabling the system to tolerate delays in communication and computation but can impose a prohibitive communication overhead when applied at a fine-grained level. This paper proposes `De-elastisation' in a CAD flow for asynchronous dataflow networks to improve the circuits' performance and area. To preserve the architectural advantages of asynchronous design (e.g. short cycles), circuits are classified into blocking and non-blocking loops which the De-elastisation scheme relies upon. The technique is incorporated in the Teak CAD flow. Experimental results on substantial case studies show significant performance and area improvements. This work shows 3× improvement for the first category of circuits, suitable for iterative realisations and DSP-like architectures and 4× for the second category which are suitable for concurrent realisations.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092395","","Asynchronous circuits;Clocks;Design automation;Elasticity;Program processors;Synchronization","VLSI;asynchronous circuits;concurrency control;digital signal processing chips;logic CAD;sequential circuits","CAD flow;DSP-like architecture;asynchronous VLSI programming;asynchronous dataflow network;asynchronous design;blocking loop;circuit performance improvement;concurrent system realisation;de-elastisation scheme;flexible abstract formalism;iterative realisation;nonblocking loop;synchronous circuits","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"On the premises and prospects of timing speculation","Rong Ye; Feng Yuan; Jie Zhang; Qiang Xu","Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Shatin, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","605","608","Timing speculation (TS), being able to detect and correct circuit timing errors at runtime, is a promising alternative solution to mitigate the ever-increasing variation effects in nanometer circuits. The potential energy-efficiency improvement, however, is limited by the circuit “timing wall”, a critical operating point caused by conventional circuit optimization techniques (e.g., gate sizing). With a given circuit netlist, we study the bound of the potential benefits provided by TS techniques in this work, which facilitate designers to decide whether it worths the effort to implement a timing-speculative circuit. Experimental results on benchmark circuits demonstrate the effectiveness of the proposed methodology.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092459","","Benchmark testing;Energy consumption;Error probability;Logic gates;Optimization;Threshold voltage;Timing","circuit optimisation;integrated circuit design;low-power electronics;nanoelectronics;power aware computing;timing circuits","TS technique;circuit optimization technique;circuit timing error correction;circuit timing error detection;circuit timing wall;energy efficiency improvement;nanometer circuit;runtime;timing speculation;timing speculative circuit;variation effect mitigation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Efficient attacks on robust ring oscillator PUF with enhanced challenge-response set","Phuong Ha Nguyen; Sahoo, D.P.; Chakraborty, R.S.; Mukhopadhyay, D.","SEAL, Indian Inst. of Technol. Kharagpur, Kharagpur, India","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","641","646","Physically Unclonable Function (PUF) circuits are an important class of hardware security primitives that promise a paradigm shift in applied cryptography. Ring Oscillator PUF (ROPUF) is an important PUF variant, but it suffers from hardware overhead limitations, which in turn restricts the size of its challenge space. To overcome this fundamental shortcoming, improved ROPUF variants based on the subset selection concept have been proposed, which significantly “expand” the challenge space of a ROPUF at acceptable hardware overhead. In this paper, we develop cryptanalytic attacks on a previously proposed low-overhead and robust ROPUF variant. The proposed attacks are practical as they have quadratic time and data complexities in the worst case. We demonstrate the effectiveness of the proposed attack by successfully attacking a public domain dataset acquired from FPGA implementations.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092468","Cryptanalysis;hardware-intrinsic security;physically unclonable function (PUF);ring oscillator PUF (ROPUF)","Algorithm design and analysis;Complexity theory;Cryptography;Hardware;Prediction algorithms;Ring oscillators","copy protection;cryptography;field programmable gate arrays;oscillators","FPGA;PUF circuits;ROPUF;challenge-response set;cryptanalytic attacks;cryptography;data complexities;hardware security primitives;physically unclonable function circuits;public domain dataset;quadratic time;ring oscillator PUF","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A calibration based thermal modeling technique for complex multicore systems","Rai, D.; Thiele, L.","Comput. Eng. & Networks Lab., ETH Zurich, Zurich, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1138","1143","A calibration based method to construct fast and accurate thermal models of the state-of-the-art multicore systems is presented. Such models are usually required during Design Space Exploration (DSE) exercises to evaluate various task-to-core mapping, associated scheduling and processor speed-scaling options for their overall impact on the system temperature. Current approaches require modeling the thermal characteristics of the target processor using numerical simulators, which assume accurate information about several critical parameters (e.g., the processor floorplan). Such parameters are not readily available, forcing the system designers to use time and cost intensive, and possibly error-prone techniques such as using heat maps for reverse-engineering such parameters. Additionally, advanced power and temperature management algorithms commonly found in the state-of-the-art processors must also be accurately modeled. This paper proposes a calibration based method for constructing the complete system thermal model of a target processor without requiring any hard-to-get information such as the detailed processor floorplan or system power traces. Taking an example of a sufficiently complex Intel Xeon 8-core processor, we show that our approach yields an accurate thermal model, which is also lightweight both in terms of memory and compute requirements to be practically feasible for DSE over current processors.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092559","","Accuracy;Algorithm design and analysis;Autoregressive processes;Calibration;Computational modeling;Temperature sensors","calibration;large-scale systems;multiprocessing systems;thermal analysis","DSE;Intel Xeon 8-core processor;calibration based thermal modeling technique;complex multicore systems;design space exploration","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Knowledge-intensive, causal reasoning for analog circuit topology synthesis in emergent and innovative applications","Fanshu Jiao; Montano, S.; Doboli, A.","Dept. of Electr. & Comput. Eng., State Univ. of New York at Stony Brook, Stony Brook, NY, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1144","1149","Analog circuit topology design has been difficult to automate. Topology synthesis involves searching an open-ended, widely extensible, and strongly discontinuous solution space. Existing algorithms cannot generate topologies beyond a constrained set of structures, or experience difficulties in evolving performance-effective yet minimal circuits. This paper proposes a new topology synthesis method that implements a design knowledge-intensive reasoning process to create novel circuit structures with all their features justified by the problem requirements. Two synthesis experiments demonstrate the capability of the method to generate circuits beyond the capabilities of existing topology synthesis algorithms.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092560","","Algorithm design and analysis;Circuit topology;Cognition;Feedforward neural networks;Knowledge representation;Performance evaluation;Topology","analogue circuits;network synthesis;network topology","analog circuit topology design;analog circuit topology synthesis;circuit structures;knowledge-intensive causal reasoning;knowledge-intensive reasoning process;topology synthesis algorithms;topology synthesis method","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"TAPP: Temperature-aware application mapping for NoC-based many-core processors","Di Zhu; Lizhong Chen; Pinkston, T.M.; Pedram, M.","Ming Hsieh Dept. of Electr. Eng., Univ. of Southern California, Los Angeles, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1241","1244","Application mapping with its ability to spread out high-power components can potentially be a good approach to mitigate the looming issue of hotspots in many-core processors. However, very few works have explored effective ways of making tradeoff between temperature and network latency. Moreover, on-chip routers, which are of high power density and may lead to hotspots, are not considered in these works. In this paper, we propose TAPP (Temperature-Aware Partitioning and Placement), an efficient application mapping algorithm to reduce on-chip hotspots while sacrificing little network performance. This algorithm “spreads” high-power cores and routers across the chip by performing hierarchical bi-partitioning of the cores and concurrently conducting placement of the cores onto tiles, and achieves high efficiency and superior scalability. Simulation results show that the proposed algorithm reduces the temperature by up to 6.80°C with minimal latency increase compared to the latency-oriented mapping solution.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092579","","Algorithm design and analysis;Benchmark testing;Computer architecture;Heuristic algorithms;Partitioning algorithms;Power demand;System-on-chip","multiprocessing systems;network routing;network-on-chip","NoC-based many-core processor;TAPP;hierarchical bipartitioning;high-power component;latency-oriented mapping solution;network latency;on-chip hotspot reduction;on-chip router;power density;temperature-aware application mapping;temperature-aware partitioning and placement","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Clock domain crossing aware sequential clock gating","Jianfeng Liu; Mi-Suk Hong; Kyungtae Do; Jung Yun Choi; Jaehong Park; Kumar, M.; Kumar, M.; Tripathi, N.; Ranjan, A.","S. LSI, Samsung Electron. Co. Ltd., Hwaseong, South Korea","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1","6","Power has become the overriding concern for most modern electronic applications today. To reduce clock power, which is a significant portion of the dynamic power consumed by a design, sequential clock gating is increasingly getting used over and above combinational clock gating. With the shrinking device sizes and increasingly complex designs, data is frequently transferred from one clock domain to the other. The sequential clock gating optimizations can use signals from across sequential boundaries and thus, can introduce new clock domain crossing (CDC) violations which can cause catastrophic functional issues in the fabricated chip. Hence, it has become very important that sequential clock gating optimizations be CDC aware. In this paper, we present an algorithm to handle CDC violations as part of the objective function for sequential clock gating optimizations. With the proposed algorithm, we have obtained an average of 22% sequential power savings - this is within 3% of the power savings obtained by the CDC unaware sequential clock gating. In comparison, the state-of-the-art two-pass solution is leading to an almost complete loss of power savings.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092349","Clock Domain Crossing;Observability;Power Analysis;Power Optimization;Sequential Analysis;Sequential Clock Gating;Sequential Optimization;Stability","Algorithm design and analysis;Clocks;Logic gates;Observability;Optimization;Registers;Synchronization","clocks;combinational circuits;integrated circuit manufacture;logic design","clock domain crossing;clock power;combinational clock gating;electronics;fabricated chip;sequential clock gating","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Formal probabilistic analysis of distributed dynamic thermal management","Iqtedar, S.; Hasan, O.; Shafique, M.; Henkel, J.","Sch. of EE & CS, Nat. Univ. of Sci. & Technol., Islamabad, Pakistan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1221","1224","The prevalence of Dynamic Thermal Management (DTM) schemes coupled with demands for high reliability motivate the rigorous verification and testing of these schemes before deployment. Conventionally, these schemes are analyzed using either simulations or by running on real systems. But these traditional analysis techniques cannot exhaustively validate the distributed DTM schemes and thus compromise on the accuracy of the analysis results. Moreover, the randomness due to task assignments, task completion times and re-mappings, is often ignored in the analysis of distributed DTM schemes. We propose to overcome both of these limitations by using probabilistic model checking, which is a formal method for modeling and verifying concurrent systems with randomized behaviors. The paper presents a case study on the formal verification of a state-of-the-art distributed DTM scheme using the PRISM model checker.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092574","","Algorithm design and analysis;Analytical models;Mathematical model;Model checking;Probabilistic logic;Stability analysis;Temperature distribution","probability;thermal management (packaging)","PRISM model checker;dynamic thermal management;formal verification;probabilistic analysis;probabilistic model checking;task assignments;task completion times","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A low energy 2D adaptive median filter hardware","Kalali, E.; Hamzaoglu, I.","Fac. of Eng. & Natural Sci., Sabanci Univ., Istanbul, Turkey","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","725","729","The two-dimensional (2D) spatial median filter is the most commonly used filter for image denoising. Since it is a non-linear sorting based filter, it has high computational complexity. Therefore, in this paper, we propose a novel low complexity 2D adaptive median filter algorithm. The proposed algorithm reduces the computational complexity of 2D median filter by exploiting the pixel correlations in the input image, and it produces higher quality filtered images than 2D median filter. We also designed and implemented a low energy 2D adaptive median filter hardware implementing the proposed 2D adaptive median filter algorithm. The proposed hardware is verified to work correctly on a Xilinx Zynq 7000 FPGA board. It can process 105 full HD (1920×1080) images per second in the worst case on a Xilinx Virtex 6 FPGA, and it has more than 80% less energy consumption than original 2D median filter hardware on the same FPGA.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092482","FPGA;Median filter;hardware implementation;low energy","Adaptive filters;Algorithm design and analysis;Field programmable gate arrays;Filtering algorithms;Hardware;Maximum likelihood detection;Nonlinear filters","adaptive filters;computational complexity;field programmable gate arrays;image denoising;image filtering;image resolution;median filters","105 full RD image;2D spatial median filter;Xilinx Zynq 7000 FPGA board;computational complexity;energy consumption;image denoising;low complexity 2D adaptive median filter algorithm;low energy 2D adaptive median filter hardware;nonlinear sorting based filter;pixel correlations;two-dimensional spatial median filter","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Formal analysis of the startup delay of SOME/IP service discovery","Seyler, J.R.; Streichert, T.; Glass, M.; Navet, N.; Teich, J.","Mercedes-Benz Cars Dev., Daimler AG, Sindelfingen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","49","54","An automotive network needs to start up within the millisecond range. This includes the physical startup, the software boot time, and the configuration of the network. The introduction of Ethernet into the automotive industry expanded the design space drastically and is increasing the complexity of configuring every element in the network. To add more flexibility to automotive Ethernet networks, the concept of Service Discovery was migrated from consumer electronics to AUTOSAR within the SOME/IP middleware. A network is not fully functional until every client has found its service. Consequently, this time interval adds to the startup time of a network. This work presents a formal analysis model to calculate the waiting time of every client to receive the first offer from its service. The model is able to determine the worst case of a given parameter set. Based on this, a method for calculating the total startup time of a system is derived. The model is implemented in a free-to-use octave program and validated by comparing the analytical results to a timing-accurate simulation and an experimental setup. In every case the worst-case assumption holds true - the gap between the maximum of the simulation and the presented method is less than 1.3%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092357","","Automation;Bismuth;Europe","IP networks;automotive engineering;computational complexity;consumer electronics;local area networks;middleware;service-oriented architecture","AUTOSAR;SOME-IP middleware;automotive Ethernet network;automotive industry;automotive network;consumer electronics;formal analysis model;free-to-use octave program;service discovery;software boot time;startup delay;timing accurate simulation;worst case configuration time calculation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"User-specific skin temperature-aware DVFS for smartphones","Egilmez, B.; Memik, G.; Ogrenci-Memik, S.; Ergin, O.","Dept. of Electr. Eng. & Comput. Sci., Northwestern Univ., Evanston, IL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1217","1220","Skin temperature of mobile devices intimately affects the user experience. Power management schemes built into smartphones can lead to quickly crossing a user's threshold of tolerable skin temperature. Furthermore, there is a significant variation among users in terms of their sensitivity. Hence, controlling the skin temperature as part of the device's power management scheme is paramount. To achieve this, we first present a method for estimating skin and screen temperature at run-time using a combination of available on-device thermal sensors and performance indicators. In an Android-based smartphone, we achieve 99.05% and 99.14% accuracy in estimations of back cover and screen temperatures, respectively. Leveraging this run-time predictor, we develop User-specific Skin Temperature-Aware (USTA) DVFS mechanism to control the skin temperature. Performance of USTA is tested both with benchmarks and user tests comparing USTA to the standard Android governor. The results show that more users prefer to use USTA as opposed to the default DVFS mechanism.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092573","Thermal modeling;mobile device;skin temperature","Benchmark testing;Error analysis;Predictive models;Skin;Smart phones;Temperature measurement;Temperature sensors","smart phones","Android-based smartphone;on-device thermal sensors;performance indicators;screen temperature;user-specific skin temperature-aware DVFS","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Systematic application of ISO 26262 on a SEooC: Support by applying a systematic reuse approach","Ruiz, A.; Melzi, A.; Kelly, T.","Div., ICT-Eur. Software Inst., Derio, Spain","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","393","396","The automotive domain is undergoing significant transformation. The fully electric vehicle is playing a role in updating the electronic systems on the car. Systems such as electric parking are emerging. The entrance of ISO 26262 [1] functional safety standard has impacted automotive design and assurance practice. ISO 26262 includes the concept of a Safety Element out of Context (SEooC). However, it lacks a systematic process regarding the implementation of the SEooC concept. In this paper we present our experience of the application of the SEooC concept from ISO 26262 to an electric parking system. We describe a systematic approach that takes into account the needs for a safe reuse of system elements into the whole vehicle context.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092420","ISO 26262;SEooC;composition;reuse;safety","Automation;Hazards;ISO standards;Systematics;Vehicles","ISO standards;automobiles;automotive electronics;electric vehicles;safety systems","ISO 26262;SEooC concept;assurance practice;automotive domain design;car;electric parking system;electric vehicle;electronic systems;functional safety standard;safety element out of context;system element safe reuse;systematic process application","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Synergistic use of multiple on-chip networks for ultra-low latency and scalable distributed routing reconfiguration","Balboni, M.; Flich, J.; Bertozzi, D.","ENDIF - MPSoC Res. Group, Univ. of Ferrara, Ferrara, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","806","811","Extending the principle of partially good die allowance to manycore processors, and testing them over time to detect the onset of permanent faults, are only feasible through proper support in the on-chip interconnection network. In fact, this implies the ability to reconfigure the routing algorithm at runtime to reflect changes in network topologies. Current literature cannot avoid a large hardware and/or software overhead when tackling this challenge. This paper exploits the existence of multiple physical networks in industry-relevant manycore processors in a synergistic way, for the sake of fast and scalable distributed reconfiguration of the routing function at runtime.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092496","","Optimization;Ports (Computers);Routing;Runtime;Switches;System recovery;Testing","network routing;network-on-chip","NoC;die allowance;hardware overhead;industry-relevant manycore processors;multiple on-chip networks;multiple physical networks;network-on-chip;on-chip interconnection network;permanent faults;scalable distributed routing reconfiguration;software overhead;synergistic use;ultra-low latency","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Distributed reinforcement learning for power limited many-core system performance optimization","Zhuo Chen; Marculescu, D.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1521","1526","As power density emerges as the main constraint for many-core systems, controlling power consumption under the Thermal Design Power (TDP) while maximizing the performance becomes increasingly critical. To dynamically save power, Dynamic Voltage Frequency Scaling (DVFS) techniques have proved to be effective and are widely available commercially. In this paper, we present an On-line Distributed Reinforcement Learning (OD-RL) based DVFS control algorithm for many-core system performance improvement under power constraints. At the finer grain, a per-core Reinforcement Learning (RL) method is used to learn the optimal control policy of the Voltage/Frequency (VF) levels in a system model-free manner. At the coarser grain, an efficient global power budget reallocation algorithm is used to maximize the overall performance. The experiments show that compared to the state-of-the-art algorithms: 1) OD-RL produces up to 98% less budget overshoot, 2) up to 44.3x better throughput per over-the-budget energy and up to 23% higher energy efficiency, and 3) two orders of magnitude speedup over state-of-the-art techniques for systems with hundreds of cores.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092630","","Algorithm design and analysis;Complexity theory;Learning (artificial intelligence);Multicore processing;Power demand;Scalability;Throughput","electronic engineering computing;learning (artificial intelligence);multiprocessing systems;optimal control;performance evaluation;power aware computing;resource allocation","DVFS techniques;OD-RL based DVFS control algorithm;TDP;distributed reinforcement learning;dynamic voltage frequency scaling techniques;energy efficiency;global power budget reallocation algorithm;many-core system performance improvement;online distributed reinforcement learning based DVFS control algorithm;optimal control policy;per-core reinforcement learning method;power consumption;power limited many-core system performance optimization;thermal design power","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Spiking neural network with RRAM: Can we use it for real-world application?","Tianqi Tang; Lixue Xia; Boxun Li; Rong Luo; Yiran Chen; Yu Wang; Huazhong Yang","Dept. of E.E., Tsinghua Univ., Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","860","865","The spiking neural network (SNN) provides a promising solution to drastically promote the performance and efficiency of computing systems. Previous work of SNN mainly focus on increasing the scalability and level of realism in a neural simulation, while few of them support practical cognitive applications with acceptable performance. At the same time, based on the traditional CMOS technology, the efficiency of SNN systems is also unsatisfactory. In this work, we explore different training algorithms of SNN for real-world applications, and demonstrate that the Neural Sampling method is much more effective than Spiking Time Dependent Plasticity (STDP) and Remote Supervision Method (ReSuMe). We also propose an energy efficient implementation of SNN with the emerging metal-oxide resistive random access memory (RRAM) devices, which includes an RRAM crossbar array works as network synapses, an analog design of the spike neuron, and an input encoding scheme. A parameter mapping algorithm is also introduced to configure the RRAM-based SNN. Simulation results illustrate that the system achieves 91.2% accuracy on the MNIST dataset with an ultra-low power consumption of 3.5mW. Moreover, the RRAM-based SNN system demonstrates great robustness to 20% process variation with less than 1% accuracy decrease, and can tolerate 20% signal fluctuation with about 2% accuracy loss. These results reveal that the RRAM-based SNN will be quite easy to be physically realized.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092505","","Accuracy;Algorithm design and analysis;Arrays;Biological neural networks;Neurons;Training","learning (artificial intelligence);neural nets;performance evaluation;random-access storage","CMOS technology;RRAM crossbar array;RRAM-based SNN system;SNN training algorithms;analog spike neuron design;computing system efficiency;computing system performance;input encoding scheme;metal-oxide resistive random access memory devices;network synapses;neural sampling method;parameter mapping algorithm;process variation;signal fluctuation;spiking neural network","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Bordersearch: An adaptive identification of failure regions","Dobler, M.; Harrant, M.; Rafaila, M.; Pelz, G.; Rosenstiel, W.; Bogdan, M.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1036","1041","The reliability and safety of modern analog devices, e.g. in automotives, aircraft or consumer electronics, is influenced by many input parameters like supply voltage, ambient temperature or load resistances. In certain regions of this large parameter space, the device exhibits degraded performance or it fails completely. The validation of such a device has to find the regions of the input parameter space in which the device misbehaves. However, with several parameters, it is a complex task to determine these regions, especially if parameters interact. In this paper, we present the Bordersearch algorithm, which combines adaptive testing with a machine learning classifier to efficiently determine the border between passing and failing regions in the parameter space. Furthermore, this method enables sophisticated post-processing analysis, e.g. better visualizations and automatic ranking of the parameters according to their influence. This algorithm scales well to a high-dimensional parameter space and is robust against outliers and fuzzy borders. We show the effectiveness of this method on an automotive electromechanical system with eleven input parameters.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092542","","Accuracy;Aerospace electronics;Monte Carlo methods;Support vector machines;Testing;Training;Visualization","automotive electrics;automotive engineering;electrical engineering computing;failure analysis;fuzzy set theory;learning (artificial intelligence);pattern classification;reliability","Bordersearch algorithm;adaptive failure region identification;adaptive testing;analog device reliability;analog device safety;automatic parameter ranking;automotive electromechanical system;failing regions;high-dimensional parameter space;input parameter space;machine learning classifier;passing regions;sophisticated post-processing analysis","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Semiautomatic implementation of a bioinspired reliable analog task distribution architecture for multiple analog cores","von Rosen, J.; Meissner, M.; Hedrich, L.","Dept. of Comput. Sci., Univ. of Frankfurt/Main, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","912","915","In this paper we present a silicon implementation of a bioinspired analog task distribution system for enabling reliable analog multi-core systems. The increase in reliability is achieved by a dependable task distribution architecture using a hormone based mechanism. The specifications are generated by a feasibility analysis of the algebraic description of the architecture. Starting from the specifications, an automated analog synthesis framework is used to fasten the time-consuming design of the needed analog amplifiers. The complete system with the designed amplifiers has been layouted and fabricated. We present measurements of two different architectures of task distribution system on silicon showing the full functionality of the system and the design methodology.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092517","","Adders;Analog circuits;Automation;Biochemistry;Reliability engineering;Semiconductor device measurement","algebra;analogue integrated circuits;integrated circuit reliability","algebraic description;automated analog synthesis framework;bioinspired analog task distribution system;bioinspired reliable analog task distribution;feasibility analysis;multiple analog cores;reliable analog multicore systems;semiautomatic implementation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A thermal stress-aware algorithm for power and temperature management of MPSoCs","Kamal, M.; Iranfar, A.; Afzali-Kusha, A.; Pedram, M.","Sch. of Electr. & Comput. Eng., Univ. of Tehran, Tehran, Iran","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","954","959","In this work, we propose a thermal stress-aware algorithm for the management of the power and temperature in MPSoCs. The algorithm, which uses a heuristic approach, controls the power consumption, maximum temperature, thermal cycles, and temporal/spatial thermal gradients of MPSoCs. At the top level, the decision on turning the cores on and off is made based on the constraints of peak temperature, maximum spatial thermal gradient, and power consumption. At the next tier, the optimal frequencies (and supply voltages) of the ON cores, formulated in a convex optimization problem, are determined again based on satisfying the constraints of the maximum total power consumption, peak temperature, thermal cycles, and also temporal thermal gradient. The technique may be applied to both the heterogeneous and homogenous MPSoCs. The efficacy of the proposed approach in reducing the thermal cycles as well as temporal thermal gradient is evaluated by comparing its results with a similar previous power and temperature management approach. The evaluation which is performed on 8-core processors under Splash2 benchmarks, demonstrates the ability of the suggested technique in limiting a considerable reduction in the thermal stress parameters.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092526","","Automation;Benchmark testing;Decision support systems;Europe","benchmark testing;integrated circuit testing;microprocessor chips;multiprocessing systems;power consumption;system-on-chip","MPSoC;Splash2 benchmarks;convex optimization;maximum spatial thermal gradient;peak temperature;power consumption;power management;temperature management;temporal/spatial thermal gradients;thermal stress-aware algorithm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Platform-aware dynamic configuration support for efficient text processing on heterogeneous system","Mi Sun Park; Tickoo, O.; Narayanan, V.; Irwin, M.J.; Iyer, R.","Pennsylvania State Univ., University Park, PA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1503","1508","Significant efforts have been made in accelerating computer vision and machine learning algorithms by utilizing parallel processors such as multi-core CPUs and GPUs. Although the suitability of GPU is well-known for computer graphics and image processing applications which require massively parallel floating-point computations, recent research movement towards general purpose computing on-GPU (GPGPU) makes it possible to take advantage of parallel processors to accelerate text processing applications as well. However, how to fully leverage different types of parallel processor architectures to obtain optimal performance (especially with text) without making specific efforts to each platform still remains a great challenge. We applied performance and accuracy enhancements to Naive Bayes algorithm to develop a practically sound implementation of text classification. A platform-aware dynamic configuration support automation flow is also proposed to support the seamless execution of our work across platforms. Experiments on various (integrated graphics, dedicated multiple GPUs) platforms demonstrate that our proposed approach improves both accuracy and performance of text classification.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092627","","Accuracy;Automation;Feedback loop;Graphics processing units;Kernel;Performance evaluation;Training","Bayes methods;pattern classification;text analysis;word processing","heterogeneous system;naive Bayes algorithm;platform-aware dynamic configuration support automation flow;text classification;text processing","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Bytecode-to-C ahead-of-time compilation for Android Dalvik Virtual Machine","Hyeong-Seok Oh; Ji Hwan Yeo; Soo-Mook Moon","Dept. of Electr. & Comput. Eng., Seoul Nat. Univ., Seoul, South Korea","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1048","1053","Android employs Java for programming its apps which is executed by its own virtual machine called the Dalvik VM (DVM). One problem of the DVM is its performance. Its just-in-time compiler (JITC) cannot generate high-performance code due to its trace-based compilation with short traces and modest optimizations, compared to JVM's method-based compilation with ample optimziations. This paper proposes a bytecode-to-C ahead-of-time compilation (AOTC) for the DVM to accelerate pre-installed apps. We translated the bytecode of some of the hot methods used by these apps to C code, which is then compiled together with the DVM source code. AOTC-generated code works with the existing Android zygote mechanism, with corrects garbage collection and exception handling. Due to off-line, method-based compilation using existing compiler with full optimizations and Java-specific optimizations, AOTC can generate quality code while obviating runtime compilation overhead. For benchmarks, AOTC can improve the performance by 10% to 500%. When we compare this result with the recently-introduced ART, which also performs ahead-of-time compilation, our AOTC performs better.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092544","","Androids;Automation;Cryptography;Decision support systems;Europe;Humanoid robots;Registers","Java;operating systems (computers);program compilers;software performance evaluation;virtual machines","AOTC generated code;Android zygote mechanism;C code;DVM;DVM source code;Dalvik VM;JITC;JVM method;Java;Java specific optimizations;ahead-of-time compilation;android Dalvik virtual machine;bytecode translation;bytecode-to-C ahead-of-time compilation;exception handling;garbage collection;high performance code;just-in-time compiler","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Verifying synchronous reactive systems using lazy abstraction","Madhukar, K.; Srivas, M.; Wachter, B.; Kroening, D.; Metta, R.","Tata Res. Dev. & Design Center, Pune, India","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1571","1574","Embedded software systems are frequently modeled as a set of synchronous reactive processes. The transitions performed by the processes are given as sequential, atomic code blocks. Most existing verifiers flatten such programs into a global transition system, to be able to apply off-the-shelf verification methods. However, this monolithic approach fails to exploit the lock-step execution of the processes, severely limiting scalability. We present a novel formal verification technique that analyses synchronous concurrency explicitly rather than encoding it. We present a variant of Lazy Abstraction with Interpolants (LAwI), a technique successfully used in software verification, and tailor it to synchronous reactive concurrency. We exploit the synchronous communication structure by fixing an execution schedule, circumventing the exponential blow-up of state space caused by simulating synchronous behaviour by means of interleavings. The technique is implemented in Sympara, a verification tool for synchronous reactive systems. To evaluate the effectiveness of our technique, we compare Sympara with Bounded Model Checking and k-induction, and a LAWI-based verifier for multi-threaded (asynchronous) software. On several realistic examples Sympara outperforms the other tools by an order of magnitude.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092641","","Algorithm design and analysis;Concurrent computing;Model checking;Schedules;Software;Software algorithms;Subspace constraints","data structures;multi-threading;program verification","LAwI;Sympara;asynchronous software;atomic code blocks;bounded model checking;embedded software system;formal verification technique;global transition system;k-induction;lazy abstraction;monolithic approach;multithreaded software;off-the-shelf verification method;software verification;synchronous reactive concurrency;synchronous reactive system verification","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Computing approximately, and efficiently","Venkataramani, S.; Chakradhar, S.T.; Roy, K.; Raghunathan, A.","Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","748","751","Recent years have witnessed significant interest in the area of approximate computing. Much of this interest stems from the quest for new sources of computing efficiency in the face of diminishing benefits from technology scaling. We argue that trends in computing workloads will greatly increase the opportunities for approximate computing, describe the vision and key principles that have guided our work in this area, and outline a range of approximate computing techniques that we have developed at all layers of the computing stack, spanning circuits, architecture, and software.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092486","","Algorithm design and analysis;Approximation algorithms;Approximation methods;Computer architecture;Hardware;Resilience;Software","inference mechanisms;power aware computing","approximate computing techniques;computing efficiency;computing stack;computing workloads;spanning circuits;technology scaling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Fast and precise cache performance estimation for out-of-order execution","Douma, R.J.; Altmeyer, S.; Pimentel, A.D.","Comput. Syst. Archit. Group, Univ. of Amsterdam, Amsterdam, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1132","1137","Design space exploration (DSE) is a key ingredient of system-level design, enabling designers to quickly prune the set of possible designs and determine, e.g., the number of the processing cores, the mapping of application tasks to cores, and the core configuration such as the cache organization. High-level performance estimation is a principle component of any systemlevel DSE: it has to be fast and sufficiently precise. Modern out-of-order architectures with caches pose a significant problem to this performance estimation process, as no simple one-to-one mapping of the number of cache misses and resulting cycle time exists. We present a high-level cache performance-estimation framework for out-of-order processors. Evaluation shows that our prediction method is on average 15 times faster than cycle-accurate simulation, while our estimates only show an average error of below 3.5%, reduce the pessimism of a naive highlevel performance estimation by around 66%, and still maintain a high fidelity. Our approach thus enables quick yet accurate performance estimation and extends the applicability of systemlevel DSE to out-of-order processors with caches.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092558","","Benchmark testing;Computer architecture;Estimation;Histograms;Mathematical model;Out of order","cache storage;performance evaluation;precision engineering;principal component analysis","application task mapping;cache misses;cache organization;design space exploration;high-level cache performance-estimation framework;naive high-level performance estimation process;one-to-one mapping;out-of-order execution;processing cores;system-level DSE;system-level design","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Tactile prosthetics in WiseSkin","Farserotu, J.; Decotignie, J.-D.; Baborowski, J.; Volpe, P.-N.; Quiros, C.R.; Kopta, V.; Enz, C.; Lacour, S.; Michaud, H.; Martuzzi, R.; Koch, V.; Huang, H.; Li, T.; Antfolk, C.","Integrated & Wireless Syst., CSEM, Neuchatel, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1695","1697","The use of prosthetic hands is limited in part by the lack of sensory feedback to the wearer. In order to provide sensory feedback, an adequate number of sensors must be integrated with the prosthesis. The WiseSkin project targets the use of artificial skin embedding ultra-low power wireless sensor nodes. This presentation provides an overview of the WiseSkin project and the current status of the developments.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092665","MEMS;artificial skin;prosthetics;sensory feedback;tactility sensors;ultra low power;wireless","Automation;Decision support systems;Europe","prosthetics;tactile sensors;wireless sensor networks","WiseSkin;artificial skin;prosthetic hands;sensory feedback;tactile prosthetics;ultra-low power wireless sensor nodes","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A defect-aware reconfigurable cache architecture for low-Vccmin DVFS-enabled systems","Mavropoulos, M.; Keramidas, G.; Nikolos, D.","Dept. of Comput. Eng. & Inf., Univ. of Patras, Patras, Greece","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","417","422","As process technology continues to shrink, a large number of bitcells in on-chip caches is expected to be faulty. The number of defective cells varies from die-to-die, wafer-to-wafer, and in the field of application depends on the run-time operating conditions (e.g., supply voltage and frequency). Those trends necessitate i) to study fault-tolerant (FT) cache mechanisms in a wide spectrum of fault-probabilities and ii) to devise appropriate FT techniques that must be able to adapt their FT capacity to the volume of defective locations of the target faulty caches. It is well known that keeping the cache capacity, block size and the volume of defective cells constant, the average number of misses, due to faulty cells, decreases as the associativity of the cache increases. To this end, we propose DARCA, a Defect-Aware Reconfigurable Cache Architecture, which is equipped with the ability of dynamically varying its associativity according to the volume of defective cells. To keep the hardware overhead very small, as the associativity of the cache is multiplied by a power of two, its block size is divided by the same number. Since almost all contempprefetch-assisted cachesorary processors use prefetching, we also applied DARCA to prefetch-assisted caches. By performing cycle-accurate simulations for the SPEC2006 benchmarks assuming a wide range of fault-probabilities, we show that DARCA compares favorably against several known FT cache mechanisms with respect to the performance loss caused by defective cells.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092426","","Arrays;Bars;Benchmark testing;Europe;Organizations;Prefetching;Redundancy","cache storage;digital simulation;fault tolerance;power aware computing;probability;reconfigurable architectures","DARCA;FT cache mechanism;SPEC2006 benchmark;bitcells;cache associativity;contemporary processors;cycle-accurate simulations;defect-aware reconfigurable cache architecture;defective cells;fault-probabilities;fault-tolerant cache mechanism;low-V<sub>ccmin</sub> DVFS-enabled systems;on-chip cache;prefetch-assisted caches;run-time operating conditions","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Reuse distance analysis for locality optimization in loop-dominated applications","Lezos, C.; Dimitroulakos, G.; Masselos, K.","Dept. of Inf. & Telecommun., Univ. of Peloponnese, Tripoli, Greece","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1237","1240","This paper discusses MemAddIn, a compiler assisted dynamic code analysis tool that analyzes C code and exposes critical parts for memory related optimizations on embedded systems that can heavily affect systems performance, power and cost. The tool includes enhanced features for data reuse distance analysis and source code transformation recommendations for temporal locality optimization. Several of data reuse distance measurement algorithms have been implemented leading to different trade-offs between accuracy and profiling execution time. The proposed tool can be easily and seamlessly integrated into different software development environments offering a unified environment for application development and optimization. The novelties of our work over a similar optimization tool are also discussed. MemAddIn has been applied for the dynamic computation of data reuse distance for a number of different applications. Experimental results prove the effectiveness of the tool through the analysis and optimization of a realistic image processing application.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092578","Data reuse distance analysis;locality optimization;memory hierarchy optimization","Algorithm design and analysis;Arrays;Distance measurement;Histograms;Optimization;Random access memory","embedded systems;image processing;optimisation;program compilers;program diagnostics;software reusability;source code (software)","C code;MemAddIn;compiler assisted dynamic code analysis tool;data reuse distance analysis;data reuse distance measurement algorithms;embedded systems;locality optimization;loop-dominated applications;memory related optimizations;optimization;profiling execution time;realistic image processing application;software development environments;source code transformation recommendations;temporal locality optimization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Effective verification of low-level software with nested interrupts","Kroening, D.; Lihao Liang; Melham, T.; Schrammel, P.; Tautschnig, M.","Univ. of Oxford, Oxford, UK","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","229","234","Interrupt-driven software is difficult to test and debug, especially when interrupts can be nested and subject to priorities. Interrupts can arrive at arbitrary times, leading to an explosion in the number of cases to be considered. We present a new formal approach to verifying interrupt-driven software based on symbolic execution. The approach leverages recent advances in the encoding of the execution traces of interacting, concurrent threads. We assess the performance of our method on benchmarks drawn from embedded systems code and device drivers, and experimentally compare it to conventional formal approaches that use source-to-source transformations. Our experimental results show that our method significantly outperforms conventional techniques. To the best of our knowledge, our technique is the first to demonstrate effective formal verification of low-level embedded software with nested interrupts.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092387","","Benchmark testing;Encoding;Instruction sets;Instruments;Radio frequency;Semantics","embedded systems;formal verification;interrupts;symbol manipulation","device drivers;effective low-level software verification;embedded systems code;formal approach;formal verification;interrupt-driven software;low-level embedded software;nested interrupts;source-to-source transformations;symbolic execution","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Delay analysis of structural real-time workload","Nan Guan; Yue Tang; Yang Wang; Wang Yi","Northeastern Univ., Shenyang, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","223","228","In many complex embedded systems, real-time workload is generated conforming certain structural constraints. In this paper we study how to analyze the delay of real-time workloads of which the generation pattern can be modeled by task graph models. We first show that directly combining path abstraction technique (PAT) in real-time scheduling theory and real-time calculus (RTC) can provide safe delay bounds, but the results are typically over-pessimistic. Then we propose new algorithms to efficiently and precisely solve the delay analysis problem. Experiments with randomly generated task systems are conducted to evaluate the performance of the proposed methods.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092386","","Algorithm design and analysis;Analytical models;Automation;Delays;Radio frequency;Real-time systems;Time complexity","delays;embedded systems;graph theory;scheduling","PAT;RTC;complex embedded systems;delay analysis problem;path abstraction technique;real-time calculus;real-time scheduling theory;safe delay bounds;structural constraints;structural real-time workload;task graph models","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Introduction to hardware Trojan detection methods","Francq, J.; Frick, F.","Airbus Defence & Space - CyberSecurity, Elancourt, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","770","775","Hardware Trojans (HTs) are identified as an emerging threat for the integrity of Integrated Circuits (ICs) and their applications. Attackers attempt to maliciously manipulate the functionality of ICs by inserting HTs, potentially causing disastrous effects (Denial of Service, sensitive information leakage, etc.). Over the last 10 years, various methods have been proposed in literature to circumvent HTs. This article introduces the general context of HTs and summarizes the recent advances in HT detection from a French funded research project named HOMERE. Some of these results will be detailed in the related special session.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092490","","Application specific integrated circuits;Field programmable gate arrays;Hardware;Logic testing;Production;Trojan horses","integrated circuits;invasive software","HOMERE project;HT detection;hardware Trojan detection methods;integrated circuits","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Transparent acceleration of program execution using reconfigurable hardware","Paulino, N.; Ferreira, J.C.; Bispo, J.; Cardoso, J.M.P.","INESC TEC & Fac. of Eng., Univ. of Porto, Porto, Portugal","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1066","1071","The acceleration of applications, running on a general purpose processor (GPP), by mapping parts of their execution to reconfigurable hardware is an approach which does not involve program's source code and still ensures program portability over different target reconfigurable fabrics. However, the problem is very challenging, as suitable sequences of GPP instructions need to be translated/mapped to hardware, possibly at runtime. Thus, all mapping steps, from compiler analysis and optimizations to hardware generation, need to be both efficient and fast. This paper introduces some of the most representative approaches for binary acceleration using reconfigurable hardware, and presents our binary acceleration approach and the latest results. Our approach extends a GPP with a Reconfigurable Processing Unit (RPU), both sharing the data memory. Repeating sequences of GPP instructions are migrated to an RPU composed of functional units and interconnect resources, and able to exploit instruction-level parallelism, e.g., via loop pipelining. Although we envision a fully dynamic system, currently the RPU resources are selected and organized offline using execution trace information. We present implementation prototypes of the system on a Spartan-6 FPGA with a MicroBlaze as GPP and the very encouraging results achieved with a number of benchmarks.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092547","","Acceleration;Benchmark testing;Computer architecture;Hardware;Registers;Runtime;Software","field programmable gate arrays;multiprocessing systems;program compilers;source code (software);supervisory programs","GPP;MicroBlaze;RPU;Spartan-6 FPGA;binary acceleration approach;compiler analysis;general purpose processor;hardware generation;program execution;program source code;reconfigurable hardware;reconfigurable processing unit;transparent acceleration","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Over-approximating loops to prove properties using bounded model checking","Darke, P.; Chimdyalwar, B.; Venkatesh, R.; Shrotri, U.; Metta, R.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1407","1412","Bounded Model Checkers (BMCs) are widely used to detect violations of program properties up to a bounded execution length of the program. However when it comes to proving the properties, BMCs are unable to provide a sound result for programs with loops of large or unknown bounds. To address this limitation, we developed a new loop over-approximation technique LA. LA replaces a given loop in a program with an abstract loop having a smaller known bound by combining the techniques of output abstraction and a novel abstract acceleration, suitably augmented with a new application of induction. The resulting transformed program can then be fed to any bounded model checker to provide a sound proof of the desired properties. We call this approach, of LA followed by BMC, as LABMC. We evaluated the effectiveness of LABMC on some of the SV-COMP14 loop benchmarks, each with a property encoded into it. Well known BMCs failed to prove most of these properties due to loops of large, infinite or unknown bounds while LABMC obtained promising results. We also performed experiments on a real world automotive application on which the well known BMCs were able to prove only one of the 186 array accesses to be within array bounds. LABMC was able to successfully prove 131 of those array accesses to be within array bounds.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092611","","Acceleration;Arrays;Automation;Automotive applications;Benchmark testing;Europe;Model checking","program control structures;program verification","BMCs;LABMC;SV-COMP14 loop benchmarks;abstract acceleration;array bounds;bounded model checking;loop abstraction;loop over-approximation technique;output abstraction;program properties;software verification competition 2014","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Predictive dynamic thermal and power management for heterogeneous mobile platforms","Singla, G.; Kaur, G.; Unver, A.K.; Ogras, U.Y.","Sch. of Electr., Comput., & Energy Eng., Arizona State Univ., Tempe, AZ, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","960","965","Heterogeneous multiprocessor systems-on-chip (MPSoCs) powering mobile platforms integrate multiple asymmetric CPU cores, a GPU, and many specialized processors. When the MPSoC operates close to its peak performance, power dissipation easily increases the temperature, hence adversely impacts reliability. Since using a fan is not a viable solution for hand-held devices, there is a strong need for dynamic thermal and power management (DTPM) algorithms that can regulate temperature with minimal performance impact. This paper presents a DTPM algorithm based on a practical temperature prediction methodology using system identification. The DTPM algorithm dynamically computes a power budget using the predicted temperature, and controls the types and number of active processors as well as their frequencies. Experiments on an octa-core big. LITTLE processor and common Android apps demonstrate that the proposed technique predicts temperature within 3% accuracy, while the DTPM algorithm provides around 6× reduction in temperature variance, and as large as 16% reduction in total platform power compared to using a fan.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092527","","Benchmark testing;Graphics processing units;Mathematical model;Power demand;Prediction algorithms;Temperature measurement;Thermal management","Android (operating system);graphics processing units;mobile computing;multiprocessing systems;power aware computing;system-on-chip","Android apps;DTPM;GPU;MPSoC;asymmetric CPU cores;dynamic thermal and power management algorithms;hand-held devices;heterogeneous mobile platforms;heterogeneous multiprocessor systems-on-chip;octa-core big.LITTLE processor;power budget;power dissipation;system identification;temperature prediction methodology;temperature variance;total platform power","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Using structural relations for checking combinationality of cyclic circuits","Wan-Chen Weng; Yung-Chih Chen; Jui-Hung Chen; Ching-Yi Huang; Chun-Yao Wang","Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsinchu, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","325","328","Functionality and combinationality are two main issues that have to be dealt with in cyclic combinational circuits, which are combinational circuits containing loops. Cyclic circuits are combinational if nodes within the circuits have definite values under all input assignments. For a cyclified circuit, we have to check whether it is combinational or not. Thus, this paper proposes an efficient two-stage algorithm to verify the combinationality of cyclic circuits. A set of cyclified IWLS 2005 benchmarks are performed to demonstrate the efficiency of the proposed algorithm. Compared to the state-of-the-art algorithm, our approach has a speedup of about 4000 times on average.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092408","","Algorithm design and analysis;Benchmark testing;Combinational circuits;Delays;Integrated circuit modeling;Logic gates;Open systems","combinational circuits;logic design","cyclic combinational circuits;cyclified IWLS 2005 benchmarks;cyclified circuit","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Optimized selection of reliable and cost-effective cyber-physical system architectures","Bajaj, N.; Nuzzo, P.; Masin, M.; Sangiovanni-Vincentelli, A.","EECS Dept., Univ. of California at Berkeley, Berkeley, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","561","566","We address the problem of synthesizing safety-critical cyber-physical system architectures to minimize a cost function while guaranteeing the desired reliability. We cast the problem as an integer linear program on a reconfigurable graph which models the architecture. Since generating symbolic probability constraints by exhaustive enumeration of failure cases on all possible graph configurations takes exponential time, we propose two algorithms to decrease the problem complexity, i.e. Integer-Linear Programming Modulo Reliability (ILP-MR) and Integer-Linear Programming with Approximate Reliability (ILP-AR). We compare the two approaches and demonstrate their effectiveness on the design of aircraft electric power system architectures.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092450","","Algorithm design and analysis;Complexity theory;Computer architecture;Power system reliability;Reliability engineering;Reliability theory","graph theory;integer programming;linear programming;probability;reliability;safety-critical software","ILP-AR;ILP-MR;aircraft electric power system architectures;cost function minimization;graph configurations;integer linear program;integer-linear programming modulo reliability;integer-linear programming with approximate reliability;optimized cyber-physical system architecture selection;problem complexity;reconfigurable graph;safety-critical cyber-physical system architecture synthesis;symbolic probability constraints","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Solving DQBF through quantifier elimination","Gitina, K.; Wimmer, R.; Reimer, S.; Sauer, M.; Scholl, C.; Becker, B.","Inst. of Comput. Sci., Albert-Ludwigs-Univ. Freiburg, Freiburg, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1617","1622","We show how to solve dependency quantified Boolean formulas (DQBF) using a quantifier elimination strategy which yields an equivalent QBF that can be decided using any standard QBF solver. The elimination is accompanied by a number of optimizations which help reduce memory consumption and computation time. We apply our solver HQS to problems from the domain of verification of incomplete combinational circuits to demonstrate the effectiveness of the proposed algorithm. The results show enormous improvements both in the number of solved instances and in the computation times compared to existing work on validating DQBF.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092652","","Automation;Benchmark testing;Boolean functions;Europe;Inverters;Logic gates;Syntactics","Boolean functions;computational complexity;optimisation","DQBF;NP-complete SAT problem;QBF solver;dependency quantified Boolean formulas;incomplete combinational circuit verification;quantifier elimination strategy","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Coherence based message prediction for optically interconnected chip multiprocessors","Van Laer, A.; Ellawala, C.; Madarbux, M.R.; Watts, P.M.; Jones, T.M.","Dept. of Electron. & Electr. Eng., Univ. Coll. London, London, UK","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","613","616","Photonic networks on chip have been proposed to reduce latency and power consumption of on-chip communication in chip multiprocessors. However, in switched photonic networks, the path setup latency can create a high overhead, particularly for the short messages generated by shared memory chip multiprocessors (CMP). This has led to proposals for networks which avoid switching using all-to-all or single writer multiple reader (SWMR) networks which dramatically increase optical component counts and hence power consumption. In this work we propose a predictor which uses information from the coherence protocol and previously transmitted messages to predict future messages and hence hide the path setup latency by speculatively setup photonic paths. We show that a directly mapped predictor can achieve prediction hit rates of up to 85% for PARSEC benchmarks in a 16-core x86 system using the MESI coherence protocol whereas a more resource efficient set associative predictor can still achieve prediction rates up to 75%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092461","","Benchmark testing;Coherence;Optical switches;Photonics;Protocols;System-on-chip;Table lookup","integrated optics;microprocessor chips;multiprocessing systems;multiprocessor interconnection networks;network-on-chip;optical interconnections","CMP;MESI coherence protocol;PARSEC benchmarks;coherence based message prediction;optically interconnected chip multiprocessors;photonic networks on chip;photonic paths;prediction hit rates;set associative predictor;switched optical NoC","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Improving SIMD code generation in QEMU","Sheng-Yu Fu; Jan-Jan Wu; Wei-Chung Hsu","Dept. of Comput. Sci. & Inf. Eng., Nat. Taiwan Univ., Taipei, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1233","1236","Modern processors are often enhanced using SIMD instructions, such as the MMX, SSE, and AVX instructions set in the x86 architecture, or the NEON instruction set in the ARM architecture. Using these SIMD instructions could significantly increase application performance, hence in application binaries a significant proportion of instructions are likely to be SIMD instructions. However, Dynamic Binary Translation (DBT) has largely overlooked SIMD instruction translation. For example, in the popular QEMU system emulator, guest SIMD instructions are often emulated with a sequence of scalar instructions even when the host machines have SIMD instructions to support such parallel computation, leaving significant potential for performance enhancement. In this paper, we propose two approaches, one leveraging the existing helper function implementation in QEMU, and the other using a newly introduced vector IR (Intermediate Representation) to enhance the performance of SIMD instruction translation in DBT of QEMU. Both approaches were implemented in the QEMU to support ARM and IA32 frontend and x86-64 backend. Preliminary experiments show that adding vector IR can significantly enhance the performance of guest applications containing SIMD instructions for both ARM and IA32 architectures when running with QEMU on the x86-64 platform.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092577","","Benchmark testing;Computer architecture;Emulation;Generators;Hardware;Optimization;Registers","instruction sets;parallel architectures;program compilers","ARM architecture;AVX instructions set;DBT;IA32 architectures;MMX instructions set;NEON instruction set;QEMU system emulator;SIMD code generation;SIMD instruction translation;SSE instructions set;dynamic binary translation;parallel computation;vector IR;vector intermediate representation;x86 architecture","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Fault-based attacks on the Bel-T block cipher family","Jovanovic, P.; Polian, I.","Univ. of Passau, Passau, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","601","604","We present the first fault-based attack on the Bel-T block cipher family which has been adopted recently as a national standard of the Republic of Belarus. Our attack successfully recovers the secret key of the 128-bit, 192-bit and 256-bit versions of Bel-T using 4, 7 and 10 fault injections, respectively. We also show the results from our comprehensive simulation-based experiments.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092458","block cipher;fault injection;fault-based cryptanalysis","Automation;Ciphers;Circuit faults;Encryption;Mathematical model;Standards","cryptography;digital simulation;standards","Bel-T block cipher family;Republic of Belarus;comprehensive simulation-based experiments;fault injections;fault-based attack;national standard;secret key","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Multi-core fixed-priority scheduling of real-time tasks with statistical deadline guarantee","Tianyi Wang; Linwei Niu; Shaolei Ren; Gang Quan","Dept. of Electr. &Comput. Eng., Florida Int. Univ., Miami, FL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1335","1340","The rising performance variance of IC chips and increased resource sharing in multi-core platforms have significantly degraded the predictability of real-time systems. The traditional deterministic approaches can be extremely pessimistic, if not infeasible at all. In this paper, we adopt a probabilistic approach for fixed-priority preemptive scheduling of real-time tasks on multi-core platforms with statistical deadline miss probability guarantee. Rather than a single-valued worst-case execution time (WCET), we formulate the task execution time as a probabilistic distribution. We develop a novel algorithm to partition real-time tasks on multiple homogenous cores, which takes not only task execution time distributions but their period relationships into considerations. Our extensive experimental results show that our proposed methods can greatly improve the schedulability of real-time tasks when compared with the traditional bin packing approaches.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092599","harmonic;multi-core;probabilistic;real-time systems;task partitions","Algorithm design and analysis;Harmonic analysis;Indexes;Measurement;Partitioning algorithms;Probabilistic logic;Real-time systems","multiprocessing systems;probability;processor scheduling;statistical distributions","IC chips;WCET;bin packing approach;deterministic approach;multicore fixed-priority preemptive scheduling;multiple homogenous cores;probabilistic approach;probabilistic distribution;real-time systems;real-time task scheduling;resource sharing;single-valued worst-case execution time;statistical deadline miss probability guarantee;task execution time distributions","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Source level performance simulation of GPU cores","Gerum, C.; Bringmann, O.; Rosenstiel, W.","Univ. of Tubingen, Tu&#x0308;bingen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","217","222","Graphic processing units (GPUs) contain a lot of complex architectural features, which make performance analysis and simulation of applications using them for general purpose computation very difficult. Especially when trying to do performance simulations at a higher abstraction level than interpreted instruction set simulators these features are not handled accurately by state of the art simulation techniques. This paper proposes a method for source level performance simulation of the microarchitecture of a GPU core that provides high enough simulation speeds to make testing of large application scenarios possible.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092385","","Algorithm design and analysis;Analytical models;Graphics processing units;Instruction sets;Kernel;Pipelines;Timing","digital simulation;graphics processing units;instruction sets","GPU cores;general purpose computation;graphic processing units;instruction set simulators;microarchitecture;performance analysis;source level performance simulation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Race to idle or not: Balancing the memory sleep time with DVS for energy minimization","Chenchen Fu; Minming Li; Xue, C.J.","Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","13","18","Reducing energy consumption is a critical problem in most of the computing systems today. In recent years, dynamic voltage scaling (DVS) has been often applied in the multi-core processor systems. The leakage power of the main memory shared by the multiple DVS cores is becoming a larger problem with technology scaling. This paper focuses on minimizing the system-wide energy consumption by applying DVS on each core and turning the memory to sleep when all the cores have common idle time. This work presents systematic analysis for the target problem based on different system models and task models. For tasks with common release time, optimal schemes are presented for the systems both with and without considering the static power of the cores. For the general task model, a heuristic online algorithm is proposed. Furthermore, the scheme is extended to handle the problem when the transition overhead between the active and sleep modes is not negligible. The experimental results show that the heuristic algorithm can reduce the energy consumption of the overall system by 8.73% in average (up to 28.44%) compared to a state-of-the-art multi-core DVS scheduling scheme.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092351","","Algorithm design and analysis;Energy consumption;Heuristic algorithms;Memory management;Multicore processing;Switching circuits;Voltage control","multiprocessing systems;power aware computing;storage management chips","DVS;dynamic voltage scaling;energy consumption minimization;heuristic online algorithm;memory sleep time;multicore processor;static power;transition overhead","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Enabling multi-threaded applications on hybrid shared memory manycore architectures","Rawat, T.; Shrivastava, A.","Comput. Microarchitecture Lab., Arizona State Univ., Tempe, AZ, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","742","747","As the number of cores per chip increases, maintaining cache coherence becomes prohibitive for both power and performance. Non Coherent Cache (NCC) architectures do away with hardware-based cache coherence, but become difficult to program. Some existing architectures provide a middle ground by providing some shared memory in the hardware. Specifically, the 48-core Intel Single-chip Cloud Computer (SCC) provides some off-chip (DRAM) shared memory and some on-chip (SRAM) shared memory. We call such architectures Hybrid Shared Memory, or HSM, manycore architectures. However, how to efficiently execute multi-threaded programs on HSM architectures is an open problem. To be able to execute a multi-threaded program correctly on HSM architectures, the compiler must: i) identify all the shared data and map it to the shared memory, and ii) map the frequently accessed shared data to the on-chip shared memory. In this paper, we present a source-to-source translator written using CETUS (Dave et al. [1]) that identifies a conservative superset of all the shared data in a multi-threaded application, and maps it to the off-chip shared memory such that it enables execution on HSM architectures. This improves the performance of our benchmarks by 32x. Following, we identify and map the frequently accessed shared data to the on-chip shared memory. This further improves the performance of our benchmarks by 8x on average.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092485","","Algorithm design and analysis;Instruction sets;Message systems;Multicore processing;Random access memory;System-on-chip","memory architecture;multi-threading;shared memory systems","CETUS;HSM architecture;SRAM;hybrid shared memory manycore architecture;multithreaded applications;off-chip shared memory;on-chip shared memory;shared data access;source-to-source translator","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Soft-error reliability and power co-optimization for GPGPUs register file using resistive memory","Jingweijia Tan; Zhi Li; Xin Fu","ECE Dept., Univ. of Houston, Houston, TX, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","369","374","The increasing adoption of graphics processing units (GPUs) for high-performance computing raises the reliability challenge, which is generally ignored in traditional GPUs. GPUs usually support thousands of parallel threads and require a sizable register file. Such large register file is highly susceptible to soft errors and power-hungry. Although ECC has been adopted to register file in modern GPUs, it causes considerable power overhead, which further increases the power stress. Thus, an energy-efficient soft-error protection mechanism is more desirable. Besides its extremely low leakage power consumption, resistive memory (e.g. spin-transfer torque RAM) is also immune to the radiation induced soft errors due to its magnetic field based storage. In this paper, we propose to LEverage reSistive memory to enhance the Soft-error robustness and reduce the power consumption (LESS) of registers in the General-Purpose computing on GPUs (GPGPUs). Since resistive memory experiences longer write latency compared to SRAM, we explore the unique characteristics of GPGPU applications to obtain the win-win gains: achieving the near-full soft-error protection for the register file, and meanwhile substantially reducing the energy consumption with negligible performance loss. Our experimental results show that LESS is able to mitigate the registers soft-error vulnerability by 86% and achieve 60% energy savings with negligible (e.g. 4%) performance loss.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092416","Energy Efficiency;GPGPU;Register File;Reliability;Resistive Memory;Soft Error","Benchmark testing;Error correction codes;Instruction sets;Radio frequency;Random access memory;Registers;Reliability","energy conservation;graphics processing units;integrated circuit reliability;power aware computing;radiation hardening (electronics)","GPGPU register file;energy savings;energy-efficient soft-error protection mechanism;general-purpose computing;graphics processing units;high-performance computing;leverage resistive memory;low leakage power consumption;magnetic field based storage;power cooptimization;power stress;registers soft-error vulnerability;resistive memory;soft-error protection;soft-error reliability","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Power-efficient control of thermoelectric coolers considering distributed hot spots","Dousti, M.J.; Pedram, M.","Dept. of Electr. Eng., Univ. of Southern California, Los Angeles, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","966","971","Thermoelectric coolers are compact devices that can target hot spots on a VLSI die. These devices are connected electrically in series and controlled together, i.e., all are ON or OFF at the same time. However, spatial and temporal distributions of hot spots on a VLSI die are non-uniform, and therefore, activating all of TECs to address one or a few localized hot spots is not economical. This traditional technique indeed leads to a significant power waste. This paper suggests that adjacent hot spots with the same thermal behavior can be grouped and controlled by a cluster of TECs. A bypass switch for each TEC cluster is added in order to allow selectively turning OFF some TEC clusters which are needed. More precisely, a clustering problem is formulated which aims to minimize the power waste due to excessive use of TECs. Due to the large number of variables in problems of interesting sizes, a greedy heuristic method for solving the problem is introduced. It is shown that the proposed heuristic can reduce the wasted power on average by 81% and also decrease the total TEC power consumption on average by 42%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092528","","Benchmark testing;Cooling;Graphical models;Heating;Power demand;Switches","VLSI;energy conservation;greedy algorithms;power consumption;power distribution control;thermoelectric cooling","TEC power efficient control;TECs;bypass switch;greedy heuristic method;hot spot spatial distribution;hot spot temporal distribution;nonuniform VLSI die;power consumption;power wastage minimization;thermoelectric coolers","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"MRP: Mix real cores and pseudo cores for FPGA-based chip-multiprocessor simulation","Xinke Chen; Guangfei Zhang; Huandong Wang; Ruiyang Wu; Peng Wu; Longbing Zhang","State Key Lab. of Comput. Archit., ICT, Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","211","216","Facing the speed bottleneck of software-based simulators, FPGA-based simulation has been explored more and more. This paper proposes a novel methodology to simulate a chip-multiprocessor (CMP) on the limited FPGA resource. By mixing real cores and pseudo cores together (MRP), we can simulate a multicore system with fewer FPGA resource requirements and achieve a much higher simulation speed. We propose several methods to construct the pseudo cores. We implement our idea on a dual Virtex-6 FPGA board to simulate a general-purpose 4-core high performance CMP processor. Comparison experiments against the corresponding tape-out chip prove the effectiveness of MRP. We also evaluate MRP prototype's performance by running SPEC CPU2006 benchmarks on an unmodified Linux operating system, achieving tens to hundreds speedup compared to two other commonly-used simulators.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092384","CMP;Emulation;FPGA;Multicore;Pseudo core;Simulation","Benchmark testing;Field programmable gate arrays;Hardware;Materials requirements planning;Multicore processing;Random access memory","Linux;field programmable gate arrays;microprocessor chips;multiprocessing systems","MRP;SPEC CPU2006 benchmarks;chip-multiprocessor simulation;dual Virtex-6 FPGA board;field programmable gate array resource requirements;general-purpose 4-core high performance CMP processor;mix real cores;multicore system;pseudocores;simulation speed;tape-out chip;unmodified Linux operating system","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Maximizing common idle time on multi-core processors with shared memory","Chenchen Fu; Yingchao Zhao; Minming Li; Xue, C.J.","Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","900","903","Reducing energy consumption is a critical problem in most of the computing systems today. This paper focuses on reducing the energy consumption of the shared main memory in multi-core processors by putting it into sleep state when all the cores are idle. Based on this idea, this work presents systematic analysis of different assignment and scheduling models and proposes a series of scheduling schemes to maximize the common idle time of all cores. An optimal scheduling scheme is proposed assuming the number of cores is unbounded. When the number of cores is bounded, an efficient heuristic algorithm is proposed. The experimental results show that the heuristic algorithm works efficiently and can save as much as 25.6% memory energy compared to a conventional multi-core scheduling scheme.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092514","","Benchmark testing;Energy consumption;Heuristic algorithms;Memory management;Multicore processing;Processor scheduling;Schedules","power aware computing;processor scheduling;shared memory systems","common idle time;heuristic algorithm;multicore processor scheduling scheme;shared main memory;systematic analysis","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Eliminating intra-warp conflict misses in GPU","Bin Wang; Zhuo Liu; Xinning Wang; Weikuan Yu","Dept. of Comput. Sci., Auburn Univ., Auburn, AL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","689","694","Cache indexing functions play a key role in reducing conflict misses by spreading accesses evenly among all sets of cache blocks. Although various methods have been proposed, no significant effort has been expended on the behavior of conflict misses in GPU where threads are organized into warps and execute in lock-step. When intra-warp accesses could not be coalesced into one or two cache blocks, which is often referred to as memory divergence, a warp incurs up to SIMD-width (e.g., 32) independent cache accesses. Such a burst of divergent accesses not only increases contention on cache capacity, but also incurs intra-warp associativity conflicts when they are pathologically concentrated in a few cache sets. Due to the lockstep execution, the GPU Load/Store units would be stalled when intra-warp concentration exceeds available cache associativity. Through an in-depth analysis of GPU access patterns, we find that column-majored strided accesses are likely to incur high intra-warp concentration. Based on the analysis, we propose a Full Permutation (FUP) based indexing method that adapts to both large and medium strides in this pattern. Across the 10 highly cache-sensitive GPU applications we have evaluated, FUP eliminates intra-warp associativity conflicts and outperforms two state-of-the-art indexing methods by 22% and 15%, respectively.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092476","","Benchmark testing;Graphics processing units;Indexing;Instruction sets;Measurement;Parallel processing","cache storage;graphics processing units","FUP based indexing method;GPU access patterns;column-majored strided accesses;full permutation;graphics processing units;intra-warp associativity conflicts;intra-warp concentration;intra-warp conflict misses elimination","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Fault simulation with parallel exact critical path tracing in multiple core environment","Gorev, M.; Ubar, R.; Devadze, S.","Dept. of Comput. Eng., Tallinn Univ. of Technol., Tallinn, Estonia","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1180","1185","A novel fault simulation method is proposed, based on exact critical path tracing beyond the Fan-out-Free Regions (FFR) throughout the full circuit. The method exploits two types of parallelism: bit-level parallelism for multiple pattern reasoning, and distribution the fault reasoning process between different cores in a multi-core processor environment. To increase the speed and accuracy of fault simulation, compared with previous methods, a mixed level fault reasoning approach is developed, were the fan-out re-convergence is handled on the higher FFR network level, and the fault simulation inside of FFRs relies on the gate-level information. To allow a uniform and seamless fault reasoning, Structurally Synthesized BDDs (SSBDD) are used for modeling on both levels. Experimental research demonstrated very promising results in increasing the speed and scalability of the method.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092566","","Benchmark testing;Circuit faults;Cognition;Computational modeling;Integrated circuit modeling;Logic gates;Solid modeling","multiprocessing systems;parallel processing","FFR network;SSBDD;fan-out-free regions;fault reasoning process;fault simulation;mixed level fault reasoning approach;multicore processor environment;multiple core environment;multiple pattern reasoning;parallel exact critical path tracing;structurally synthesized BDD","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A fast parallel sparse solver for SPICE-based circuit simulators","Xiaoming Chen; Yu Wang; Huazhong Yang","Dept. of Electron. Eng., Tsinghua Univ., Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","205","210","The sparse solver is a serious bottleneck in SPICE-based circuit simulators. Although several existing researches have proposed some circuit simulation-oriented parallel solvers, there is still some room to improve the speed and scalability of these solvers. This paper proposes a fast parallel sparse solver based on a pivoting-reduction technique which takes full advantage of features of circuit simulation. Experimental results show that on average, the proposed solver is up to 50% faster than the state-of-the-art solver NICSLU, and up to 3.3× faster than KLU. Real DC simulation reveals that our solver is faster than NICSLU, PARDISO, and commercial solvers.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092383","","Acceleration;Benchmark testing;Circuit simulation;Integrated circuit modeling;Pipelines;Scalability;Sparse matrices","circuit simulation;integrated circuits;parallel processing","KLU;NICSLU;PARDISO;SPICE-based circuit simulator;Simulation Program with Integrated Circuit Emphasis;circuit simulation-oriented parallel solvers;parallel sparse solver;pivoting-reduction technique","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Evaluation of diverse compiling for software-fault detection","Holler, A.; Kajtazovic, N.; Rauter, T.; Romer, K.; Kreiner, C.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","531","536","Although software fault prevention techniques improve continually, faults remain in every complex software system. Thus safety-critical embedded systems need mechanisms to tolerate software faults. Typically, these systems use static redundancy to detect hardware faults during operation. However, the reliability of a redundant system not only depends on the reliability of each version, but also on the dissimilarity between them. Thus, researchers have investigated ways to automatically add cost-efficient diversity to software to increase the efficiency of redundancy strategies. One of these automated software diversification methods is diverse compiling, which exploits the diversity introduced by different compilers and different optimization flags. Today, diverse compiling is used to improve the hardware fault tolerance and to avoid common defects from compilers. However, in this paper we show that diverse compiling also enhances the software fault tolerance by increasing the chance of finding defects in the source code of the executed software during runtime. More precisely, the memory is organized differently, when using different compilers and compiler flags. This enhances the chance of detecting memory-related software bugs, such as missing memory initialization, during runtime. Here we experimentally quantify the efficiency of diverse compiling for software fault tolerance and we show that diverse compiling can help to detect up to about 70% of memory-related software bugs.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092445","","Benchmark testing;Computer bugs;Fault tolerance;Fault tolerant systems;Hardware;Optimization;Software","program compilers;program debugging;software fault tolerance;software reliability;source code (software)","automated software diversification methods;compiler flags;complex software system;cost-efficient diversity;diverse compiling evaluation;hardware fault tolerance;memory-related software bugs;missing memory initialization;redundant system reliability;safety-critical embedded systems;software fault prevention techniques;software-fault detection;source code;static redundancy","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Potential applications based on NVM emerging technologies","Senni, S.; Brum, R.M.; Torres, L.; Sassatelli, G.; Gamatie, A.; Mussard, B.","LIRMM, Univ. of Montpellier Montpellier, Montpellier, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1012","1017","Energy efficiency is a critical figure of merit for battery-powered applications. Today's embedded systems suffer from significant increase of power consumption essentially due to a high leakage current in advanced technology node. A significant portion of the total power consumption is spent into memory systems because of an increasing trend of embedded volatile memory area among the building components in System-on-Chips (SoCs). That is why new Non-Volatile Memory (NVM) technologies are considered as a potential solution to solve the energy efficiency issue. Among these NVM technologies, Magnetic RAM (MRAM) is a promising candidate to replace current memories since it combines non-volatility, high scalability, high density, low latency and low leakage. This paper explores use of MRAM into a memory hierarchy (from cache memory to register) of a processor-based system analyzing both performance and energy consumption.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092538","","Bandwidth;Benchmark testing;Computer architecture;Energy consumption;Magnetic tunneling;Nonvolatile memory;Random access memory","MRAM devices;leakage currents;power consumption","NVM emerging technologies;cache memory;energy efficiency;high density;high scalability;leakage current;low latency;low leakage;magnetic RAM;memory systems;nonvolatile memory technologies;power consumption;register","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A universal macro block mapping scheme for arithmetic circuits","Xing Wei; Yi Diao; Tak-Kei Lam; Yu-Liang Wu","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1629","1634","A macro block is a functional unit that can be re-used in circuit designs. The problem of general macro block mapping is to identify such embedded parts, whose I/O signals are unknown, from the netlist that may have been optimized in various ways. The mapping results can then be used to ease the functional verification process or for replacement by more advanced intellectual property (IP) macros. In the past literatures, the mapping problem is mostly limited to the identification of a single adder or multiplier with I/O signals given, which is already NP-hard. However, in today's typical arithmetic circuits (like digital signal processing (DSP) applications), it is not unusual to have combinations of arithmetic operators implemented as macro blocks for performance gain. To solve this new practical mapping problem, we propose a flow to identify and build a forest of one-bit-adder trees using structural information and formal verification techniques, followed by algorithms that locate macro boundaries and I/O signal orders. Experimental results show that our algorithm is highly practical and scalable. It is capable of identifying any combinations of arbitrary adders and multipliers such as (a + b) × c and a × b + c × d +e × f, where each operand is a multi-bit constant or variable. Most of the benchmarks in ICCAD 2013 CAD Contest [1] can be well handled by our algorithm.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092654","Adder;Arithmetic logic;Multiplier;Technology mapping","Adders;Boolean functions;Data structures;Indexes;Logic gates;Pins;Vegetation","adders;formal verification;logic circuits;logic design;multiplying circuits","DSP;I/O signals;ICCAD 2013 CAD contest;NP-hard;arbitrary adders;arithmetic circuits;circuit designs;digital signal processing;embedded parts;formal verification techniques;intellectual property macros;macro block mapping;multipliers;one-bit-adder trees;single adder;structural information","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A scalable and high-density FPGA architecture with multi-level phase change memory","Chunan Wei; Dhar, A.; Deming Chen","Dept. of Electr. & Comput. Eng., Univ. of IllinoisIllinois, Urbana, IL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1365","1370","As CMOS technology is stretched to its limits it has become imperative to look to alternative solutions for the next generation of FPGAs. In particular, due to the configurable nature of FPGAs, on-chip memory remains to be a major concern for designers. In this work we explore the use of Phase-Change Memory (PCM). We exploit the ability of PCM to exist in multiple intermediate states to store 2 bits per cell and develop a new Look Up Table (LUT) architecture. The new LUT can either store two functions with shared inputs or a single function with an additional input. We also explore the use of PCM in local routing mechanisms and thus propose a new Configurable Logic Block (CLB) composed of CMOS and PCM. The new design promises significant improvements in logic density and performance with area improvements of over 40% for all LUT sizes and delay improvements of 7% to 13% on an average for LUTs of size 10 to 6.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092604","","Delays;Field programmable gate arrays;Microprocessors;Phase change materials;Random access memory;Table lookup","CMOS logic circuits;field programmable gate arrays;integrated circuit design;logic design;network routing;phase change memories;table lookup","CLB;CMOS technology;LUT;PCM;configurable logic block;high-density FPGA architecture;local routing mechanisms;logic density;look up table architecture;multilevel phase change memory;on-chip memory;scalable FPGA architecture","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Minimum current consumption transition time optimization methodology for low power CTS","Sharma, V.","MCU Innovations, CR&D NXP Semicond., Eindhoven, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","412","416","The clock tree network can consume up to 40% of the power budget and is one of the limiting factors for realizing low power designs. This paper presents a novel clock transition time optimization based low power clock tree synthesis, for the non-throughput constraint designs. The proposed methodology quantifies the dependence of short circuit and switching power of the buffers on the input clock transition time, with the newly defined “weighted current strength” parameter. The reduction in the weighted current strength parameter value directly maps into the reduction in the total dynamic power of the clock tree. The proposed methodology determines the transition time constraint values for the clock signals which result in the minimum weighted current strength for the synthesized clock tree network. This technique results in up to 34% reduction in the dynamic power of the clock tree network with the existing clock tree synthesis tools and the clock tree library.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092425","clock tree network;short circuit power;switching power;transition time;weighted current strength","Clocks;Flip-flops;Libraries;Optimization;Switching circuits;Time factors;Timing","circuit optimisation;clock distribution networks;integrated circuit design;low-power electronics","clock tree library;clock tree network;low power CTS;low power clock tree synthesis;low power design;minimum current consumption transition time optimization;nonthroughput constraint design","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Side-channel attacks from static power: When should we care?","Del Pozo, S.M.; Standaert, F.-X.; Kamel, D.; Moradi, A.","ICTEAM/ELEN/Crypto Group, Univ. catholique de Louvain, Louvain, Belgium","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","145","150","Static power consumption is an increasingly important concern when designing circuits in deep submicron technologies. Besides its impact for low-power implementations, recent research has investigated whether it could lead to exploitable side-channel leakages. Both simulated analyses and measurements from FPGA devices have confirmed that such a static signal can indeed lead to successful key recoveries. In this respect, the main remaining question is whether it can become the target of choice for actual adversaries, especially since it has smaller amplitude than its dynamic counterpart. In this paper, we answer this question based on actual measurements taken from an AES S-box prototype chip implemented in a 65-nanometer CMOS technology. For this purpose, we first provide a fair comparison of the static and dynamic leakages in a univariate setting, based on worst-case information theoretic analysis. This comparison confirms that the static signal is significantly less informative than the dynamic one. Next, we extend our evaluations to a multivariate setting. In this case, we observe that simple averaging strategies can be used to reduce the noise in static leakage traces. As a result, we mainly conclude that (a) if the target chip is working at maximum clock frequency (which prevents the previously mentioned averaging), the static leakage signal remains substantially smaller than the dynamic one, so has limited impact, and (b) if the adversary can reduce the clock frequency, the noise of the static leakage traces can be reduced arbitrarily. Whether the static signal leads to more informative leakages than the dynamic one then depends on the quality of the measurements (as the former one has very small amplitude). But it anyway raises a warning flag for the implementation of algorithmic countermeasures such as masking, that require high noise levels.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092373","","Cryptography;Measurement;Power demand;Principal component analysis;Signal to noise ratio","CMOS integrated circuits;cryptography;field programmable gate arrays;integrated circuit design","65-nanometer CMOS technology;AES S-box prototype chip;FPGA devices;circuits design;deep submicron technologies;dynamic leakages;low-power implementations;maximum clock frequency;noise reduce;side-channel attacks;side-channel leakages;static leakage signal;static power consumption;target chip;worst-case information theoretic analysis","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Spintronics-based nonvolatile logic-in-memory architecture towards an ultra-low-power and highly reliable VLSI computing paradigm","Hanyu, T.; Suzuki, D.; Onizawa, N.; Matsunaga, S.; Natsui, M.; Mochizuki, A.","Res. Inst. of Electr. Commun., Tohoku Univ., Sendai, Japan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1006","1011","Novel logic-LSI architecture, called “spintronics-based nonvolatile logic-in-memory (NV-LIM) architecture,” where nonvolatile spintronic storage elements are distributed over a logic-circuit plane, is proposed as a promising candidate to overcome performance wall and power wall due to the present CMOS-only-based logic-LSIs. Some concrete design examples based on the NV-LIM architecture are demonstrated and their usefulness is discussed in comparison with the corresponding CMOS-only-based realization.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092537","","Computer architecture;Delays;Logic gates;Magnetic tunneling;Nonvolatile memory;Random access memory;Transistors","CMOS integrated circuits;VLSI;integrated circuit reliability;logic circuits;logic design;low-power electronics;magnetoelectronics;random-access storage","CMOS;VLSI computing paradigm;logic-LSI architecture;logic-circuit plane;nonvolatile spintronic storage elements;spintronics-based nonvolatile logic-in-memory architecture","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Architecture of ring-based redundant TSV for clustered faults","Wei-Hen Lo; Kang Chi; TingTing Hwang","Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsinchu, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","848","853","Three-dimensional Integrated Circuits (3D-ICs) that employ the Through-Silicon Vias (TSVs) vertically stacking multiple dies provide many benefits, such as high density, high bandwidth, low-power. However, the fabrication and bonding of TSVs may fail because of many factors, such as the winding level of the thinned wafers, the surface roughness and cleaness of silicon dies, and bonding technology. To improve the yield of 3D-ICs, many redundant TSV architectures were proposed to repair 3D-ICs with faulty TSVs. These methods reroute siganls of faulty TSVs to other regular or redundant TSVs. In practice, the faulty TSVs may cluster because of imperfect bonding technology. To resolve the problem of clustered TSV faults, router-based [1] redundant TSV architecture was the first paper proposed to pay attention to this clustering problem. Their method enables faulty TSVs to be repaired by redundant TSVs that are farther apart. However, for some rarely occurring defective patterns, their method consumes too much area. In this paper, we propose a ring-based redundant TSV architecture to utilize the area more efficiently as well as to maintain high yield. Simulation results show that for a given number of TSVs (8 × 8) and TSV failure rate (1%), our design achieves 54% area reduction of MUXes per signal, while the yield of our ring-based redundant TSV architectures can still maintain 98.47% to 99.00% as compared with router-based desgin [1]. Furthermore, the minimum shifting length of our ring-based redundant TSV architecture is at most 1 which guarantees the minimum timing overhead of each signal.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092503","","Circuit faults;Compounds;Computer architecture;Hardware;Maintenance engineering;Redundancy;Through-silicon vias","fault tolerance;integrated circuit design;integrated circuit reliability;redundancy;three-dimensional integrated circuits","3D-IC;clustered TSV fault;clustered fault;ring based redundant TSV architecture;three dimensional integrated circuits;through silicon via;timing overhead","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Variability-aware dark silicon management in on-chip many-core systems","Shafique, M.; Gnad, D.; Garg, S.; Henkel, J.","Embedded Syst., Karlsruhe Inst. of Technol., Karlsruhe, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","387","392","Dark Silicon refers to the constraint that only a fraction of on-chip resources (cores) can be simultaneously powered-on (running at full performance) in order to stay within the allowable power budget and safe temperature limits, while others remain `dark'. In this paper, we demonstrate how these `dark cores' can be leveraged to improve the temperature profile at run-time, thus providing opportunities to power-on more cores at the nominal voltage than the number allowed when strictly obeying the conventional Thermal Design Power (TDP) constraint. In this paper, we propose a computationally efficient dark silicon management technique that determines the best set of cores to keep dark and the mapping of threads to cores at run-time, while also accounting for the impact of process variations. We have developed a lightweight temperature prediction mechanism that determines the impact of different candidate solutions on the chip thermal profile. Experimental evaluation of the proposed techniques on a simulated 8×8 many-core processor, and across a range of chips to account for process variations, show that the total instruction throughput is increased by 1.8× on average while keeping the temperature within the safe limits, when compared with state-of-the-art approaches.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092419","","Heating;Instruction sets;Power demand;Silicon;Temperature;Temperature dependence;Thermal management","integrated circuit design;integrated circuit packaging;multiprocessing systems;thermal management (packaging)","dark core;on-chip many core systems;temperature profile;thermal design power constraint;variability aware dark silicon management","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Timing analysis of an avionics case study on complex hardware/software platforms","Wartel, F.; Kosmidis, L.; Gogonel, A.; Baldovino, A.; Stephenson, Z.; Triquet, B.; Quinones, E.; Lo, C.; Mezzetta, E.; Broster, I.; Abella, J.; Cucu-Grosjean, L.; Vardanega, T.; Cazorla, F.J.","Airbus, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","397","402","Probabilistic Timing Analysis (PTA) in general and its measurement-based variant called MBPTA in particular have been shown to facilitate the estimation of the worst-case execution time (WCET). MBPTA relies on specific hardware and software support to randomise and/or upper bound a number of sources of execution time variation to drastically reduce the need for user-provided information, thus replacing uncertainty by probabilities. MBPTA has been proven effective for specific single-core processor designs. However, particular hardware features and multicores in general challenge MBPTA application in industrial-quality developments. While solutions to those challenges have been proven on benchmarks, they have not been proven yet on real-world applications, whose timing analysis is far more challenging than that of simple benchmarks. This paper discusses the application of MBPTA to a real avionics system in the context of (1) software-only single-core solutions and (2) hardware-only multicore solutions with an ARINC 653 operating system.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092421","","Aerospace electronics;Hardware;Multicore processing;Probabilistic logic;Software;Timing","aerospace computing;avionics;integrated circuit design;microprocessor chips;multiprocessing systems;operating systems (computers);probability","ARINC 653 operating system;MBPTA;PTA;WCET;avionics case study;complex hardware platforms;complex software platforms;hardware-only multicore solutions;industrial-quality developments;measurement-based variant;probabilistic timing analysis;single-core processor designs;software-only single-core solutions;worst-case execution time estimation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"RTL property abstraction for TLM assertion-based verification","Bombieri, N.; Filippozzi, R.; Pravadelli, G.; Stefanni, F.","Dept. of Comput. Sci., Univ. of Verona, Verona, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","85","90","Different techniques and commercial tools are at the state of the art to reuse existing RTL IP implementations to generate more abstract (i.e., TLM) IP models for systemlevel design. In contrast, reusing, at TLM, an assertion-based verification (ABV) environment originally developed for an RTL IP is still an open problem. The lack of an effective and efficient solution forces verification engineers to shoulder a time consuming and error-prone manual re-definition, at TLM, of existing assertion libraries. This paper is intended to fill in the gap by presenting a technique to automatically abstract properties defined for RTL IPs with the aim of creating dynamic ABV environments for the corresponding TLM models.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092363","","Clocks;Context;Protocols;Semantics;Time-domain analysis;Time-varying systems;Timing","electronic design automation;flip-flops;formal verification;logic circuits","RTL IP implementations;RTL property abstraction;TLM assertion-based verification;abstract IP models;assertion libraries;assertion-based verification environment;register-transfer level;system-level design;transaction-level modeling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A packet-switched interconnect for many-core systems with BE and RT service","Runan Ma; Zhida Hui; Jantsch, A.","Sch. of Microelectron., Fudan Univ., Shanghai, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","980","983","A packet-switched interconnect design which supports real-time and best-effort services is proposed. This interconnect is different from traditional NoCs in that we use direction channels to replace the large input buffers and use less resource to realize the network transfer. The connection between our interconnect design and IP core is an on-chip memory management block named DME. The real-time service implies preferential transfer channel allocation, maximum delay bound and time stamping of every real-time packet. The solution is geared towards many-core systems, such as complex industrial control systems and communication devices, which require these features to facilitate efficient SW and application development.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092531","NoC router;best-effort;packet-switched;real-time","Delays;Integrated circuit interconnections;Ports (Computers);Real-time systems;Routing;Switches;System-on-chip","integrated circuit design;integrated circuit interconnections;logic circuits;multiprocessing systems;network routing;network-on-chip","BE service;IP core;NoC router;RT service;application development;communication devices;complex industrial control systems;direction channels;many-core systems;maximum delay bound;network transfer;networks-on-chip;on-chip memory management block;packet-switched interconnect design;preferential transfer channel allocation;time stamping","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Hardware Trojan detection for gate-level ICs using signal correlation based clustering","Cakir, B.; Malik, S.","Dept. of Electr. Eng., Princeton Univ., Princeton, NJ, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","471","476","Malicious tampering of the internal circuits of ICs can lead to detrimental results. Insertion of Trojan circuits may change system behavior, cause chip failure or send information to a third party. This paper presents an information-theoretic approach for Trojan detection. It estimates the statistical correlation between the signals in a design, and explores how this estimation can be used in a clustering algorithm to detect the Trojan logic. Compared with the other algorithms, our tool does not require extensive logic analysis. We neither need the circuit to be brought to the triggering state, nor the effect of the Trojan payload to be propagated and observed at the output. Instead we leverage already available simulation data in this information-theoretic approach. We conducted experiments on the TrustHub benchmarks to validate the practical efficacy of this approach. The results show that our tool can detect Trojan logic with up to 100% coverage with low false positive rates.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092435","","Clustering algorithms;Correlation;Integrated circuit modeling;Logic gates;Payloads;Trojan horses;Wires","information theory;integrated circuit testing;invasive software;logic testing","Trojan circuits;Trojan logic;chip failure;clustering algorithm;hardware Trojan detection;integrated circuit;internal circuits;logic analysis;malicious tampering;signal correlation based clustering;statistical correlation;system behavior","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Empirical modelling of FDSOI CMOS inverter for signal/power integrity simulation","Dghais, W.; Rodriguez, J.","Dept. of Electron., Univ. of Aveiro, Aveiro, Portugal","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1555","1558","This paper presents a multiport empirical model based on artificial neural network for I/O memory interface (e.g. inverter) designed based on fully depleted silicon on isolator (FDSOI) CMOS 28 nm process for signal and power integrity assessments. The analog mixed-signal identification signals that carry the information about the I/O interface's nonlinear dynamic behavior are recorded from large signal simulation setup. The model's functions are extracted based on a nonlinear optimization algorithm and then implemented in Simulink software. The performance of the resulted model is validated in typical power and ground switching noise scenario. The developed empirical model accurately predicts the timing signal waveforms at the power, ground, and at the output port.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092637","FDSOI CMOS inverter;large signal multiport model;signal and power integrity;transient analysis","CMOS integrated circuits;Integrated circuit modeling;Inverters;Mathematical model;Predictive models;Semiconductor device modeling;Solid modeling","CMOS integrated circuits;integrated circuit design;integrated circuit modelling;invertors;mixed analogue-digital integrated circuits;silicon-on-insulator","FDSOI CMOS inverter;I/O memory interface;Simulink software;analog mixed-signal identification signals;artificial neural network;fully depleted silicon on isolator;multiport empirical model;nonlinear optimization algorithm;signal/power integrity simulation;size 28 nm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"On-chip measurement of bandgap reference voltage using a small form factor VCO based zoom-in ADC","Erol, O.E.; Ozev, S.; Suresh, C.; Parekhji, R.; Balasubramanian, L.","Dept. of Electr. Eng., Arizona State Univ., Tempe, AZ, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1559","1562","A robust and scalable technique for measuring the output voltage of a band-gap reference (BGR) circuit is described. The proposed technique is based on an ADC architecture that uses a voltage controlled oscillator (VCO) for voltage to frequency conversion. During production testing, an external voltage reference is used to approximate the voltage/frequency characteristics of the VCO with 5ms test time. The proposed zoom-in ADC approach is manufactured with 0.5μm CMOS process. Measurement results indicate that 12 bits of resolution within the measurement range can be achieved with the zoom-in approach. Worst-case INL for the ADC is less than 0.25LSB (50μV).","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092638","","Calibration;Frequency measurement;Radiation detectors;System-on-chip;Voltage control;Voltage measurement;Voltage-controlled oscillators","CMOS digital integrated circuits;analogue-digital conversion;integrated circuit measurement;integrated circuit testing;reference circuits;voltage-controlled oscillators","ADC architecture;BGR circuit;CMOS process;analogue-to-digital converter;band-gap reference circuit;bandgap reference voltage;on-chip measurement;size 0.5 mum;small form factor VCO;voltage 50 muV;voltage controlled oscillator;voltage reference;zoom-in ADC","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"[Front matter]","","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1","83","The following topics are dealt with: formal specification; network-on-chip; integrated circuit design and testing; green computing system; reconfigurable computing; embedded system compilers; embedded software architecture.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092348","","","formal specification;green computing;integrated circuit design;integrated circuit testing;network-on-chip;program compilers;software architecture","embedded software architecture;embedded system compilers;formal specification;green computing system;integrated circuit design;integrated circuit testing;network-on-chip;reconfigurable computing","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"On-line prediction of NBTI-induced aging rates","Baranowski, R.; Firouzi, F.; Kiamehr, S.; Chang Liu; Tahoori, M.; Wunderlich, H.-J.","Inst. of Comput. Archit. & Comput. Eng., Univ. of Stuttgart, Stuttgart, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","589","592","Nanoscale technologies are increasingly susceptible to aging processes such as Negative-Bias Temperature Instability (NBTI) which undermine the reliability of VLSI systems. Existing monitoring techniques can detect the violation of safety margins and hence make the prediction of an imminent failure possible. However, since such techniques can only detect measurable degradation effects which appear after a relatively long period of system operation, they are not well suited to early aging prediction and proactive aging alleviation. This work presents a novel method for the monitoring of NBTI-induced degradation rate in digital circuits. It enables the timely adoption of proper mitigation techniques that reduce the impact of aging. The developed method employs machine learning techniques to find a small set of so called Representative Critical Gates (RCG), the workload of which is correlated with the degradation of the entire circuit. The workload of RCGs is observed in hardware using so called workload monitors. The output of the workload monitors is evaluated on-line to predict system degradation experienced within a configurable (short) period of time, e.g. a fraction of a second. Experimental results show that the developed monitors predict the degradation rate with an average error of only 1.6% at 4.2% area overhead.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092455","NBTI;Representative critical gates;aging prediction;workload monitoring","Aging;Degradation;Delays;Logic gates;Monitoring;Temperature measurement;Temperature sensors","VLSI;ageing;digital integrated circuits;integrated circuit reliability;learning (artificial intelligence);logic design;nanoelectronics;negative bias temperature instability;prediction theory","NBTI-induced aging rates;NBTI-induced degradation rate;RCG;VLSI systems;aging alleviation;aging prediction;aging processes;digital circuits;machine learning techniques;nanoscale technologies;negative-bias temperature instability;on-line prediction;representative critical gates;system degradation;workload monitors","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Dictionary-based sparse representation for resolution improvement in laser voltage imaging of CMOS integrated circuits","Berkin Cilingiroglu, T.; Zangeneh, M.; Uyar, A.; Clem Karl, W.; Konrad, J.; Joshi, A.; Goldberg, B.B.; Selim Unlu, M.","Dept. of Electr. & Comput. Eng., Boston Univ., Boston, MA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","597","600","The rapid decrease in the dimensions of integrated circuits with a simultaneous increase in component density have introduced resolution challenges for optical failure analysis techniques. Although optical microscopy efforts continue to increase resolution of optical systems through hardware modifications, signal processing methods are essential to complement these efforts to meet the resolution requirements for the nanoscale integrated circuit technologies. In this work, we focus on laser voltage imaging as the optical failure analysis technique and show how an overcomplete dictionary-based sparse representation can improve resolution and localization accuracy. We describe a reconstruction approach based on this sparse representation and validate its performance on simulated data. We achieve an 80% reduction of the localization error.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092457","","Dictionaries;Harmonic analysis;Image reconstruction;Image resolution;Logic gates;Modulation;Thyristors","CMOS integrated circuits;failure analysis;integrated circuit testing;laser beam applications;signal processing","CMOS integrated circuits;dictionary-based sparse representation;laser voltage imaging;localization error;optical failure analysis technique;reconstruction approach;resolution improvement","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Hardware Trojan detection by delay and electromagnetic measurements","Ngo, X.-T.; Exurville, I.; Bhasin, S.; Danger, J.-L.; Guilley, S.; Najm, Z.; Rigaud, J.-B.; Robisson, B.","TELECOM ParisTech Paris, Paris, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","782","787","Hardware Trojans (HT) inserted in integrated circuits have received special attention of researchers. In this paper, we present firstly a novel HT detection technique based on path delays measurements. A delay model, which considers intra-die process variations, is established for a net. Secondly, we show how to detect HT using ElectroMagnetic (EM) measurements. We study the HT detection probability according to its size taking into account the inter-die process variations with a set of FPGA. The results show, for instance, that there is a probability greater than 95% with a false negative rate of 5% to detect a HT larger than 1.7% of the original circuit.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092492","","Clocks;Delays;Field programmable gate arrays;Noise;Registers;Trojan horses","delays;field programmable gate arrays;integrated circuit design;invasive software","FPGA;delay measurement;delay model;electromagnetic measurement;hardware Trojan detection;integrated circuits;path delays measurement","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A TSV noise-aware 3-D placer","Yu-Min Lee; Chun Chen; JiaXing Song; Kuan-Te Pan","Nat. Chiao Tung Univ., Hsinchu, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1653","1658","In this work, a three-dimensional partitioning-based force-directed placer is developed to minimize coupling noise between through silicon vias (TSVs) in three-dimensional integrated circuits. TSV decoupling force is introduced and determined by the TSV coupling noise to separate TSVs with strong coupling noise. The experimental results indicate that TSV coupling noise can be effectively reduced by 36.3% on average with only 6.0% wirelength overhead. Besides, the developed 3-D placer shows great performance in wirelength that is competitive to a state-of-the-art 3-D placer.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092658","","Couplings;Force;Law;Noise;Runtime;Through-silicon vias","integrated circuit design;integrated circuit noise;three-dimensional integrated circuits","TSV coupling noise;TSV decoupling force;TSV noise-aware 3D placer;three-dimensional integrated circuits;three-dimensional partitioning-based force-directed placer;through silicon vias;wirelength overhead","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"d<sup>2</sup>-LBDR: Distance-driven routing to handle permanent failures in 2D mesh NoCs","Bishnoi, R.; Laxmi, V.; Gaur, M.S.; Flich, J.","Malaviya Nat. Inst. of Technol. Jaipur, Jaipur, India","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","800","805","With the advent of deep sub-micron technology, fault-tolerant solutions are needed to keep many-core chips operative. In NoCs, Logic Based Distributed Routing (LBDR) proved to be a flexible routing framework for 2D meshes with link and router faults. However, to provide full coverage, LBDR requires a module named FORKS which replicates some messages. This imposes the use of virtual cut-through switching and a complex router arbiter, increasing excessively the router cost, mainly in buffer area. Also, some failure combinations require the use of a non-trivial dynamic reconfiguration strategy to avoid deadlocks. We propose d<sup>2</sup>-LBDR which adds, on every router, a distance register to the closest failure. This enables the support of more failure combinations without an excessive implementation cost. Indeed, we restore the use of wormhole switching, keeping router architecture simple, while achieving the same fault coverage as the best LBDR version, without requiring complex switching strategies nor any dynamic reconfiguration strategy. Results show that a small area overhead (3%) is enough for the implementation of a fully flexible routing method without any limiting support case when compared with LBDR. d<sup>2</sup>-LBDR reduces area overhead over the best LBDR approach (300% overhead against 3%) while preserving fault coverage. Results show d<sup>2</sup>-LBDR performance equal to LBDR.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092495","","Clocks;Ports (Computers);Registers;Routing;Switches;System recovery;Topology","fault tolerance;logic design;network-on-chip","2D mesh NoC;complex router arbiter;deep sub-micron technology;distance-driven routing;fault-tolerant solutions;logic based distributed routing;virtual cut-through switching","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Occupancy detection via iBeacon on Android devices for smart building management","Corna, A.; Fontana, L.; Nacci, A.A.; Sciuto, D.","Politec. di Milano, Milan, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","629","632","Building heating, ventilation, and air conditioning (HVAC) systems are considered to be the main target for energy reduction due to their significant contribution to commercial buildings' energy consumption. Knowing a building's occupancy plays a crucial role in implementing demand-response HVAC. In this paper we propose a new solution based on the iBeacon technology. This solution is different from the previous ones because it leverages on the Bluetooth Low Energy standard, which provides lower power consumption. Moreover, the iBeacon protocol can be used both on iOs systems and Android ones, making this new approach portable. Differently from our previous work based on iOS devices, in this paper we focus on an Android based solution with the aim of increasing the accuracy of the location and the energy efficiency of the entire system. We increased the accuracy by 10% and the energy efficiency by 15%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092465","energy efficiency;iBeacon;indoor location;smart buildings","Accuracy;Androids;Bluetooth;Buildings;Energy efficiency;Humanoid robots;IEEE 802.11 Standards","Bluetooth;home automation;mobile computing;power aware computing;protocols;smart phones","Android devices;Bluetooth low energy standard;iBeacon protocol;occupancy detection;smart building management","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Energy versus data integrity trade-offs in embedded high-density logic compatible dynamic memories","Teman, A.; Karakonstantis, G.; Giterman, R.; Meinerzhagen, P.; Burg, A.","Telecommun. Circuits Lab. (TCL), Ecole Polytech. Fed. de Lausanne (EPFL), Lausanne, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","489","494","Current variation aware design methodologies, tuned for worst-case scenarios, are becoming increasingly pessimistic from the perspective of power and performance. A good example of such pessimism is setting the refresh rate of DRAMs according to the worst-case access statistics, thereby resulting in very frequent refresh cycles, which are responsible for the majority of the standby power consumption of these memories. However, such a high refresh rate may not be required, either due to extremely low probability of the actual occurrence of such a worst-case, or due to the inherent error resilient nature of many applications that can tolerate a certain number of potential failures. In this paper, we exploit and quantify the possibilities that exist in dynamic memory design by shifting to the so-called approximate computing paradigm in order to save power and enhance yield at no cost. The statistical characteristics of the retention time in dynamic memories were revealed by studying a fabricated 2kb CMOS compatible embedded DRAM (eDRAM) memory array based on gain-cells. Measurements show that up to 73% of the retention power can be saved by altering the refresh time and setting it such that a small number of failures is allowed. We show that these savings can be further increased by utilizing known circuit techniques, such as body biasing, which can help, not only in extending, but also in preferably shaping the retention time distribution. Our approach is one of the first attempts to access the data integrity and energy tradeoffs achieved in eDRAMs for utilizing them in error resilient applications and can prove helpful in the anticipated shift to approximate computing.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092438","DRAM;Data Integrity;Embedded Memories;Energy Efficiency;Error Resilience;Refresh Power","Arrays;Error probability;Memory management;Power demand;Random access memory;Semiconductor device measurement;Tin","CMOS memory circuits;DRAM chips;data integrity;embedded systems;power aware computing;statistical analysis","CMOS compatible embedded DRAM;approximate computing paradigm;data integrity;dynamic memory design;eDRAM memory array;embedded DRAM memory array;embedded high-density logic compatible dynamic memories;energy trade-offs;error resilient applications;memory power consumption;retention power;retention time distribution;statistical characteristics;worst-case access statistics","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"On the statistical memory architecture exploration and optimization","Antoniadis, C.; Karakonstantis, G.; Evmorfopoulos, N.; Burg, A.; Stamoulis, G.","Dept. of Electr. & Comput. Eng., Univ. of Thessaly, Volos, Greece","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","543","548","The worsening of process variations and the consequent increased spreads in circuit performance and consumed power hinder the satisfaction of the targeted budgets and lead to yield loss. Corner based design and adoption of design guardbands might limit the yield loss. However, in many cases such methods may not be able to capture the real effects which might be way better than the predicted ones leading to increasingly pessimistic designs. The situation is even more severe in memories which consist of substantially different individual building blocks, further complicating the accurate analysis of the impact of variations at the architecture level leaving many potential issues uncovered and opportunities unexploited. In this paper, we develop a framework for capturing non-trivial statistical interactions among all the components of a memory/cache. The developed tool is able to find the optimum memory/cache configuration under various constraints allowing the designers to make the right choices early in the design cycle and consequently improve performance, energy, and especially yield. Our, results indicate that the consideration of the architectural interactions between the memory components allow to relax the pessimistic access times that are predicted by existing techniques.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092447","","Arrays;Decoding;Delays;Integrated circuit modeling;Standards;Transistors","cache storage;memory architecture;optimisation;statistical analysis","architecture level;corner based design;nontrivial statistical interactions;optimum memory-cache configuration;statistical memory architecture","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Error recovery in digital microfluidics for personalized medicine","Ibrahim, M.; Chakrabarty, K.","Dept. of Electr. & Comput. Eng., Duke Univ., Durham, NC, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","247","252","Due to its emergence as an efficient platform for point-of-care clinical diagnostics, design optimization of digital-microfluidic biochips (DMFBs) has received considerable attention in recent years. In particular, error recoverability is of key interest in medical applications due to the need for system reliability. Errors are likely during droplet manipulation due to defects, chip degradation, and the lack of precision inherent in biochemical experiments. We present an illustrative survey on recently proposed techniques for error recovery. The parameters of the error-recovery design space are shown and evaluated for these schemes. Next, we make use of these evaluations to describe how they can guide error recovery in DMFBs. Finally, an experimental case study is presented to demonstrate how an error-recovery scheme can be applied to real-life biochips.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092390","","Arrays;Charge coupled devices;Electrodes;Monitoring;Reliability;Software;System-on-chip","biological techniques;computational fluid dynamics;diseases;lab-on-a-chip;medicine;microfluidics;molecular biophysics;patient treatment","DMFB;biochemical experiments;chip degradation;design optimization;digital-microfluidic biochips;droplet manipulation;error recoverability;error-recovery design space;infectious disease management improvement;infectious disease treatment improvement;personalized medicine;point-of-care clinical diagnostics;system reliability","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Towards binary circuit models that faithfully capture physical solvability","Fugger, M.; Najvirt, R.; Nowak, T.; Schmid, U.","Vienna Univ. of Technol., Vienna, Austria","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1455","1460","In contrast to analog models, binary circuit models are high-level abstractions that play an important role in assessing the correctness and performance characteristics of digital circuit designs: (i) modern circuit design relies on fast digital timing simulation tools and, hence, on binary-valued circuit models that faithfully model signal propagation, even throughout a complex design, and (ii) binary circuit models provide a level of abstraction that is amenable to formal correctness proofs. A mandatory feature of any such model is the ability to trace glitches and other short pulses precisely as they occur in physical circuits, as their presence may affect a circuit's correctness and its performance characteristics. Unfortunately, it was recently proved [Függer et al., ASYNC'13] that none of the existing binary-valued circuit models proposed so far, including the two most commonly used pure and inertial delay channels and any other bounded single-history channel, is realistic in the following sense: For the simple Short-Pulse Filtration (SPF) problem, which is related to a circuit's ability to suppress a single glitch, they showed that every bounded single-history channel either contradicts the unsolvability of SPF in bounded time or the solvability of SPF in unbounded time in physical circuits, i.e., no existing model correctly captures physical solvability with respect to glitch propagation. We propose a binary circuit model, based on so-called involution channels, which do not suffer from this deficiency. In sharp contrast to what is possible with all the existing models, they allow to solve the SPF problem precisely when this is possible in physical circuits. To the best of our knowledge, our involution channel model is hence the very first binary circuit model that realistically models glitch propagation, which makes it a promising candidate for developing more accurate tools for simulation and formal verification of digital circuits.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092619","","Analytical models;Channel models;Delays;Integrated circuit modeling;Logic gates;Predictive models","digital circuits;formal verification;network synthesis","SPF;binary circuit models;binary-valued circuit models;bounded single-history channel;digital circuit designs;digital circuits;digital timing simulation tools;formal verification;glitch propagation;high-level abstractions;inertial delay channels;involution channels;physical solvability;short-pulse filtration;signal propagation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Paper, pen and ink: An innovative system and software framework to assist writing rehabilitation","Guardati, L.; Casamassima, F.; Farella, E.; Benini, L.","Dept. of Electr. Electron. & Inf. Eng. (DEI), Univ. of Bologna, Bologna, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1473","1478","Handwriting analysis and rehabilitation is an actively explored area in the diagnosis and treatment of Parkinson's disease, which is usually performed in an ambulatory setting under direct supervision of a clinician. Technology can play an important role to reduce the need of therapist assistance and to enhance diagnostic precision through the computation of non-subjective handwriting quality metrics. This paper introduces an innovative handwriting rehabilitation system for PD patients, which ensures a natural writing experience as it is based on pen, ink and paper (as opposed to tablet and stylus). The system is designed for human-in-the loop operation and it can analyze handwriting in real-time and provide vocal feedback to guide the patient during the execution of exercises. We present a detailed comparative characterization of the key components of the system, namely wireless digital pens; in addition, in-field test assessed the system usability regarding its ease of use, calibration precision and vocal feedback effectiveness.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092622","","Calibration;Feature extraction;Mice;Performance evaluation;Receivers;Universal Serial Bus;Writing","diseases;medical diagnostic computing;patient diagnosis;patient rehabilitation;patient treatment;software engineering","PD patients;Parkinson disease diagnosis;Parkinson disease treatment;handwriting analysis;human-in-the loop operation;in-field test;ink;innovative handwriting rehabilitation system;nonsubjective handwriting quality metrics;paper;software framework;therapist assistance;vocal feedback effectiveness;wireless digital pens","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Privacy-preserving functional IP verification utilizing fully homomorphic encryption","Konstantinou, C.; Keliris, A.; Maniatakos, M.","Polytech. Sch. of Eng., Electr. & Comput. Eng., New York Univ., New York, NY, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","333","338","Intellectual Property (IP) verification is a crucial component of System-on-Chip (SoC) design in the modern IC design business model. Given a globalized supply chain and an increasing demand for IP reuse, IP theft has become a major concern for the IC industry. In this paper, we address the trust issues that arise between IP owners and IP users during the functional verification of an IP core. Our proposed scheme ensures the privacy of IP owners and users, by a) generating a privacy-preserving version of the IP, which is functionally equivalent to the original design, and b) employing homomorphically encrypted input vectors. This allows the functional verification to be securely outsourced to a third-party, or to be executed by either parties, while revealing the least possible information regarding the test vectors and the IP core. Experiments on both combinational and sequential benchmark circuits demonstrate up to three orders of magnitude IP verification slowdown, due to the computationally intensive fully homomorphic operations, for different security parameter sizes.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092410","","Encryption;IP networks;Libraries;Logic gates;Noise","cryptography;data privacy;industrial property","IC design business model;IC industry;IP core;IP reuse;IP theft;IP users;SoC design;fully homomorphic encryption;functional verification;globalized supply chain;intellectual property verification;magnitude IP verification;privacy-preserving functional IP verification;privacy-preserving version;security parameter sizes;sequential benchmark circuits;system-on-chip","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Layout-aware sizing of analog ICs using floorplan & routing estimates for parasitic extraction","Lourenco, N.; Martins, R.; Horta, N.","Inst. de Telecomun., Inst. Super. Tecnico - ULisbon, Lisbon, Portugal","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1156","1161","The design of analog integrated circuits (ICs) is characterized by time-consuming and non-systematic iterations between electrical and physical design steps in order to achieve successful post-layout designs. This paper presents an innovative methodology for automatic optimization-based sizing of analog ICs that takes into consideration complete layout-related data for both circuit's geometric requirements, which are obtained from the real-time in-loop floorplan packing, and circuits' electrical performance that is evaluated using circuit simulator and considering accurate layout parasitic estimates. In order to boost the parasitic extraction efficiency, the need for expensive detailed layout generation, as found in previous state-of-the-art layout-aware sizing approaches, is here circumvented. However, the interconnect parasitic capacitances that are major contributors to performance degradation and on-die signal integrity problems, must be accurately accounted for. Therefore, an empirical-based parasitic extraction is performed on an early-stage layout obtained from the floorplan, computing the optimal electromigration-aware wiring topology and shortest rectilinear paths in-loop, without the need for detailed routing. Finally, the methodology is demonstrated for the UMC 130nm design process using well-known analog building blocks proving the generality, accuracy and fast execution of the proposed approach.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092562","","Capacitance;Couplings;Generators;Layout;Mathematical model;Optimization;Routing","analogue integrated circuits;circuit optimisation;integrated circuit interconnections;integrated circuit layout;network routing","UMC design process;analog integrated circuit;automatic optimization based sizing;circuit electrical performance;circuit simulator;floorplan estimation;layout aware sizing;layout parasitic estimation;optimal electromigration aware wiring topology;parasitic extraction;real-time in-loop floorplan packing;routing estimation;size 130 nm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"High performance AXI-4.0 based interconnect for extensible smart memory cubes","Azarkhish, E.; Rossi, D.; Loi, I.; Benini, L.","DEI, Univ. of Bologna, Bologna, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1317","1322","The recent technological breakthrough represented by the Hybrid Memory Cube is on its way to improve bandwidth, power consumption, and density. This is while heterogeneous 3D integration has provided another opportunity for revisiting near memory computation to fill the gap between the processors and memories even further. In this paper, we take the first step towards a “Smart Memory Cube (SMC)”, a fully backward compatible and modular extension to the standard HMC, supporting near memory computation on its Logic Base (LoB), through a high performance interconnect designed for this purpose. The main feature of SMC is the high bandwidth, low latency, and AXI-4.0 compatible interconnect, designed to serve the huge bandwidth demand by HMC's serial links, and to provide extra bandwidth to a processor-in-memory (PIM) embedded in the Logic Base (LoB). Our results obtained from cycle accurate simulation demonstrate that this interconnect can easily meet the demands of current and future projections of HMC (Up to 87GB/s READ bandwidth with 4 serial links and 16 memory vaults, and 175GB/s with 8 serial links and 32 memory vaults, for injected random traffic). Moreover, the interference between the PIM traffic and the main links was found to be negligible with execution time increase of less than 5%, and average memory access time increase of less than 15% when 56GB/s bandwidth is requested by the main links and 15GB/s bandwidth is delivered to the PIM port. Moreover, preliminary logic synthesis with Synopsys Design Compiler confirms that our interconnect is implementable and realistic.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092596","","Bandwidth;Clocks;Memory management;Ports (Computers);Random access memory;Standards;Three-dimensional displays","memory cards;power aware computing;program compilers","HMC;LoB;PIM port;SMC;average memory access time;backward compatible extension;extensible smart memory cubes;heterogeneous 3D integration;high performance AXI-4.0 based interconnect;high performance interconnect;hybrid memory cube;logic base;modular extension;near memory computation;power consumption;processor-in-memory;synopsys design compiler","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Spintronic devices as key elements for energy-efficient neuroinspired architectures","Locatelli, N.; Vincent, A.F.; Mizrahi, A.; Friedman, J.S.; Vodenicarevic, D.; Joo-Von Kim; Klein, J.-O.; Weisheng Zhao; Grollier, J.; Querlioz, D.","Inst. d'Electron. Fondamentale, Univ. Paris-Sud, Orsay, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","994","999","Processing the current deluge of data using conventional CMOS architectures requires a tremendous amount of energy, as it is inefficient for tasks such as data mining, recognition and synthesis. Alternative models of computation based on neuroinspiration can prove much more efficient for these kinds of tasks, but do not map ideally to traditional CMOS. Spintronics, by contrast, can bring features such as embedded nonvolatile memory and stochastic and memristive behavior, which, when associated with CMOS, can be key enablers for neuroinspired computing. In this paper, we explore different works that go in this direction. First, we illustrate how recent developments in embedded nonvolatile memory based on magnetic tunnel junctions (MTJs) can provide the large amount of nonvolatile memory required in neuro-inspired designs while avoiding Von Neumann bottleneck. Second, we show that recently developed spintronic memristors can implement artificial synapses for neuromorphic systems. With a more groundbreaking design, we show how the probabilistic writing of single MTJ bits can efficiently replace multi-level weighting for some classes of neuroinspired architectures. Finally, we show that a special class of MTJs can exhibit the phenomenon of stochastic resonance, a strategy used in biological systems to detect weak signals. These results suggest that the impact of spintronics extends beyond the traditional standalone and embedded memory markets.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092535","","CMOS integrated circuits;Magnetic tunneling;Magnetoelectronics;Neurons;Nonvolatile memory;Stochastic processes;Switches","CMOS memory circuits;circuit resonance;embedded systems;magnetic tunnelling;magnetoelectronics;memristors;random-access storage","CMOS;MTJ;artificial synapses;biological systems;embedded nonvolatile memory;energy efficient neuroinspired architecture;magnetic tunnel junction;neuroinspired design;neuromorphic systems;nonvolatile memory;spintronic device;spintronic memristors;stochastic resonance","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Assisted generation of frame conditions for formal models","Niemann, P.; Hilken, F.; Gogolla, M.; Wille, R.","Inst. of Comput. Sci., Univ. of Bremen, Bremen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","309","312","Modeling languages such as UML or SysML allow for the validation and verification of the structure and the behavior of designs even in the absence of a specific implementation. However, formal models inherit a severe drawback: Most of them hardly provide a comprehensive and determinate description of transitions from one system state to another. This problem can be addressed by additionally specifying so-called frame conditions. However, only naive “workarounds” based on trivial heuristics or completely relying on a manual creation have been proposed for their generation thus far. In this work, we aim for a solution which neither leaves the burden of generating frame conditions entirely on the designer (avoiding the introduction of another time-consuming and expensive design step) nor is completely automatic (which, due to ambiguities, is not possible anyway). For this purpose, a systematic design methodology for the assisted generation of frame conditions is proposed.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092404","","Analytical models;Computational modeling;Context;Manuals;Microphones;Systematics;Unified modeling language","Unified Modeling Language;formal specification","assisted frame condition generation;formal model;modeling language;systematic design methodology;trivial heuristics","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Integrated CMOS receiver for wearable coil arrays in MRI applications","Sporrer, B.; Bettini, L.; Vogt, C.; Mehmann, A.; Reber, J.; Marjanovic, J.; Brunner, D.O.; Burger, T.; Pruessmann, K.P.; Troster, G.; Qiuting Huang","Integrated Syst. Lab., ETH Zurich, Zurich, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1689","1694","Surface coil arrays brought in proximity of the human body enhance the performance of an MRI measurement both in speed and signal-to-noise ratio. However, size and cabling of such arrays can deteriorate the performance of the imaging, or put at risk the safety of the patient. An integrated CMOS direct conversion receiver is proposed, to be placed directly onto the receive coil and enhance the usability. The integrated design needs to preserve the high performance (both in silent noise figure and dynamic range) of discrete solutions, which benefit from dedicated technologies for every receiver sub-block. To exploit the full potential of a coil array, the receiver on each module must also minimize the coupling to nearby modules. The PCB carrying the ASIC will be fabricated with flexible substrate materials to further enhance the wearability and comfort for the patient. Such a modular approach together with the transmission of data over optical fibers results in a lightweight system that allows us to achieve fast development times.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092664","","Clocks;Magnetic resonance imaging;Radio frequency;Receivers;Resonant frequency;Signal to noise ratio","CMOS integrated circuits;biomedical MRI;biomedical electronics;coils;medical image processing;patient diagnosis;printed circuits","ASIC-carrying PCB;CMOS conversion receiver;MRI applications;MRI measurement performance;PCB fabrication;application-specific integrated circuit;coil array cable;coil array potential;coil array size;complementary metal oxide semiconductor;direct conversion receiver;discrete solution dynamic range;discrete solution noise figure;discrete solution performance;enhanced coil array wearability;enhanced conversion receiver usability;enhanced patient comfort;flexible substrate materials;human body-coil array proximity;imaging performance;integrated CMOS receiver;integrated conversion receiver design;lightweight system;magnetic resonance imaging applications;magnetic resonance imaging measurement performance;measurement performance speed;minimized module coupling;modular approach;module coupling minimization;module receiver;optical fiber-based data transmission;patient safety risk;printed circuit board fabrication;receiver coil;receiver sub-block;signal-to-noise ratio measurement;silent noise figure;substrate material-fabricated PCB;surface coil arrays;wearable coil arrays","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Workload uncertainty characterization and adaptive frequency scaling for energy minimization of embedded systems","Das, A.; Kumar, A.; Veeravalli, B.; Shafik, R.; Merrett, G.; Al-Hashimi, B.","Sch. of ECS, Univ. of Southampton, Southampton, UK","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","43","48","A primary design optimization objective for multi-core embedded systems is to minimize the energy consumption of applications while satisfying their performance requirement. A system-level approach to this problem is to scale the frequency of the processing cores based on the readings obtained from the hardware performance monitors. However, performance monitor readings contain uncertainty, which becomes prominent when applications are executed in a multicore environment. This uncertainty can be attributed to factors such as cache contention and DRAM access time, that are very difficult to predict dynamically. We demonstrate that such uncertainty can be controlled to make better decision on the processor frequency in order to minimize energy consumption. To achieve this, we propose a multinomial logistic regression model, which combines probabilistic interpretation with maximum likelihood (ML) estimation to classify an incoming workload, at run-time, into a finite set of classes. Every workload class corresponds to a frequency pre-determined using an appropriate training set and results in minimum energy consumption. The classifier incorporates (1) uncertainty with arbitrary probability distribution to estimate the actual frame workload; and (2) the frequency switching overhead, neither of which are considered in any of the existing approaches. The classified frequency is applied on the processing cores to execute the workload. The proposed approach is engineered into an embedded multicore system and is validated with a set of standard multimedia applications. Results demonstrate that the proposed approach minimizes energy consumption by an average 20% as compared to the existing techniques.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092356","","Energy consumption;Logistics;Multicore processing;Optimization;Probability distribution;Training;Uncertainty","DRAM chips;maximum likelihood estimation;multiprocessing systems;optimisation;regression analysis","DRAM access time;adaptive frequency scaling;cache contention;embedded systems;energy minimization;frequency switching overhead;maximum likelihood estimation;multicore embedded system;multinomial logistic regression model;primary design optimization objective;processing cores;system-level approach;workload uncertainty characterization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Dynamic power and performance back-annotation for fast and accurate functional hardware simulation","Dongwook Lee; John, L.K.; Gerstlauer, A.","Dept. of Electr. Comput. Eng., Univ. of Texas Austin, Austin, TX, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1126","1131","Virtual platform prototypes are widely used for early design space exploration at the system level. There is, however, a lack of accurate and fast power and performance models of hardware components at such high levels of abstraction. In this paper, we present an approach that extends fast functional hardware models with the ability to produce detailed, cycle-level timing and power estimates. Our approach is based on back-annotating behavioral hardware descriptions with a dynamic power and performance model that allows capturing cycle-accurate and data-dependent activity without a significant loss in simulation speed. By integrating with existing high-level synthesis (HLS) flows, back-annotation is fully automated for custom hardware synthesized by HLS. We further leverage state-of-the-art machine learning techniques to synthesize abstract power models, where we introduce a structural decomposition technique to reduce model complexities and increase estimation accuracy. We have applied our back-annotation approach to several industrial-strength design examples under various architecture configurations. Results show that our models predict average power consumption to within 1% and cycle-by-cycle power dissipation to within 10% of a commercial gate-level power estimation tool, all while running several orders of magnitude faster.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092557","","Computational modeling;Data models;Estimation;Hardware;Logic gates;Switches;Timing","high level synthesis;learning (artificial intelligence);performance evaluation;power aware computing;virtual reality","HLS flows;abstract power models;back-annotating behavioral hardware descriptions;commercial gate-level power estimation tool;cycle-accurate activity;cycle-by-cycle power dissipation;cycle-level timing;data-dependent activity;design space exploration;functional hardware simulation;hardware components;high level abstraction;high-level synthesis;industrial-strength design;machine learning techniques;structural decomposition technique;virtual platform prototypes","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Spatial and temporal granularity limits of body biasing in UTBB-FDSOI","Kuhn, J.M.; Peterson, D.; Amano, H.; Bringmann, O.; Rosenstiel, W.","Comput. Eng., Univ. of Tubingen, Tu&#x0308;bingen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","876","879","Advances in SOI technology such as STMicro's 28nm UTBB-FDSOI enabled a renaissance of body biasing. Body biasing is a fast and efficient technique to change power and performance characteristics. As the electrical task to change the substrate potential is small compared to Dynamic Voltage Scaling, much finer island sizes are conceivable. This however creates new challenges in regard to design partitioning into body bias islands and body bias combinations across such designs. These combinations should be chosen so that energy efficiency improves while maintaining timing constraints. We introduce a combination based analysis tool to find optimized body bias island partitions and body biasing levels. For such partitions, optimized body bias assignments for static, programmable and dynamic body biasing can be computed. The overheads incurred by dynamically switching body biases are estimated to yield actual improvements and to give an upper bound for the power consumption of required additional circuitry. Based on these partitionings and the switching overheads, optimized application specific switching strategies are computed. The effectiveness of this method is demonstrated in a frequency scaling scenario using forward body biasing on a Dynamic Reconfigurable Processor (DRP) design. We show that leakage can be greatly reduced using the proposed methods and that dynamic body biasing can be beneficial even at small time periods.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092508","","Clocks;Delays;Layout;Optimization;Power demand;Switches","circuit analysis computing;reconfigurable architectures;silicon-on-insulator","DRP design;SOI technology;UTBB-FDSOI;additional circuitry;application specific switching strategies;body bias combinations;body bias islands;body biasing levels;combination based analysis tool;dynamic body biasing;dynamic reconfigurable processor;dynamic voltage scaling;dynamically switching body biases;electrical task;energy efficiency;finer island sizes;forward body biasing;frequency scaling scenario;optimized body bias assignments;optimized body bias island partitions;performance characteristics;power consumption;substrate potential;switching overheads;temporal granularity;timing constraints","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"GPU-accelerated small delay fault simulation","Schneider, E.; Holst, S.; Kochte, M.A.; Xiaoqing Wen; Wunderlich, H.-J.","Univ. of Stuttgart, Stuttgart, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1174","1179","The simulation of delay faults is an essential task in design validation and reliability assessment of circuits. Due to the high sensitivity of current nano-scale designs against smallest delay deviations, small delay faults recently became the focus of test research. Because of the subtle delay impact, traditional fault simulation approaches based on abstract timing models are not sufficient for representing small delay faults. Hence, timing accurate simulation approaches have to be utilized, which quickly become inapplicable for larger designs due to high computational requirements. In this work we present a waveform-accurate approach for fast high-throughput small delay fault simulation on Graphics Processing Units (GPUs). By exploiting parallelism from gates, faults and patterns, the proposed approach enables accurate exhaustive small delay fault simulation even for multimillion gate designs without fault dropping for the first time.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092565","","Circuit faults;Computational modeling;Delays;Instruction sets;Integrated circuit modeling;Logic gates","circuit CAD;fault diagnosis;graphics processing units;nanotechnology","GPU-accelerated small delay fault simulation;abstract timing models;accurate simulation approaches timing;circuit reliability assessment;delay deviations;design validation;fault simulation approaches;graphics processing units;multimillion gate designs;nano-scale designs;waveform-accurate approach","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Sub-10 nm FinFETs and tunnel-FETs: From devices to systems","Sharma, A.; Goud, A.A.; Roy, K.","Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1443","1448","In this paper, a detailed device/circuit/system level assessment of sub-10nm GaSb-InAs Tunneling Field Effect Transistors (TFET) versus Silicon FinFETs operating at near-threshold voltages is reported. A source underlapped GaSb-InAs TFET is used to achieve lower subthreshold swings than previously reported TFETs and an analytical justification is provided to explain the observed improvement. Through atomistic, 2D ballistic simulations using self-consistently, coupled Non-equilibrium Green's Function (NEGF)-Poisson approach, GaSb-InAs TFET and Silicon FinFET device characteristics are derived from which compact models are extracted for SPICE simulations. Circuit simulations of a 6-stage inverter chain show that sub-10nm underlapped TFETs are especially suited for near-threshold computing because of their ability to achieve higher throughput while consuming ~100x lower power compared to Si FinFETs. To analyze the suitability of sub-10 nm TFETs for medium-throughput and ultra-low power applications in future very large scale integrated designs, a LEON3 processor is synthesized at V<sub>DD</sub>=0.25V. The impact of interconnect parasitics on the performance of TFETs is considered by studying the power-performance of the LEON3 under varying wire-load conditions. Under moderate interconnect parasitics, TFETs-based processor is shown to exhibit more than 50% power reduction compared to FinFETs.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092617","Double-gate (DG);FinFET;Heterojunction TFET (Het-j TFET);International Technology Roadmap for Semiconductors (ITRS);LEON3 Processor;Subthreshold Swing (SS);Tunnel field-effect transistors (TFETs)","Delays;FinFETs;Integrated circuit interconnections;Inverters;Logic gates;Performance evaluation;Tunneling","Green's function methods;MOSFET;SPICE;gallium compounds;indium compounds;invertors;silicon;stochastic processes;tunnel transistors","2D ballistic simulations;6-stage inverter chain;FinFET device characteristics;GaSb-InAs;LEON3 processor;NEGF;Poisson approach;SPICE simulations;Si;TFET device characteristics;atomistic;circuit simulations;device-circuit-system level assessment;interconnect parasitics;lower subthreshold swings;medium-throughput;near-threshold computing;nonequilibrium Green's function;power reduction;threshold voltages;tunnel-FET;tunneling field effect transistors;ultra low power applications;very large scale integrated designs;voltage 0.25 V;wire-load conditions","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"DESTINY: A tool for modeling emerging 3D NVM and eDRAM caches","Poremba, M.; Mittal, S.; Dong Li; Vetter, J.S.; Yuan Xie","Pennsylvania State Univ., University Park, PA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1543","1546","The continuous drive for performance has pushed the researchers to explore novel memory technologies (e.g. nonvolatile memory) and novel fabrication approaches (e.g. 3D stacking) in the design of caches. However, a comprehensive tool which models both conventional and emerging memory technologies for both 2D and 3D designs has been lacking. We present DESTINY, a microarchitecture-level tool for modeling 3D (and 2D) cache designs using SRAM, embedded DRAM (eDRAM), spin transfer torque RAM (STT-RAM), resistive RAM (ReRAM) and phase change RAM (PCM). DESTINY facilitates design-space exploration across several dimensions, such as optimizing for a target (e.g. latency or area) for a given memory technology, choosing the suitable memory technology or fabrication method (i.e. 2D v/s 3D) for a desired optimization target etc. DESTINY has been validated against industrial cache prototypes. We believe that DESTINY will drive architecture and system-level studies and will be useful for researchers and designers.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092634","Cache;PCM;ReRAM;SRAM;STT-RAM;eDRAM;modeling tool;non-volatile memory (NVM or NVRAM);validation","Integrated circuit modeling;Nonvolatile memory;Prototypes;Random access memory;Solid modeling;Stacking;Three-dimensional displays","DRAM chips;SRAM chips;cache storage;memory architecture;phase change memories;resistive RAM","3D NVM modeling;3D cache design modeling;DESTINY;PCM;ReRAM;SRAM;STT-RAM;design space exploration;eDRAM cache;embedded DRAM;fabrication method;microarchitecture level tool;phase change RAM;resistive RAM;spin transfer torque RAM","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Uncertainty-aware reliability analysis and optimization","Khosravi, F.; Muller, M.; Glas, M.; Teich, J.","Hardware/Software Co.-Design, Friedrich-Alexander-Univ. Erlangen-Nurnberg (FAU), Erlangen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","97","102","Due to manufacturing tolerances and aging effects, future embedded systems have to cope with unreliable components. The intensity of such effects depends on uncertain aspects like environmental or usage conditions such that highly safety-critical systems are pessimistically designed for worst-case mission profiles. In this work, we propose to explicitly model the uncertain characteristics of system components, i. e. we model components using reliability functions with parameters distributed between a best and worst case. Since destructive effects like temperature may affect several components simultaneously (e. g. those in the same package), a correlation between uncertainties of components exists. The proposed uncertainty-aware method combines a formal analysis approach and a Monte Carlo simulation to consider uncertain characteristics and their different correlations. It delivers a holistic view on the system's reliability with best/worst/average-case behavior and also insights on variance and quantiles. But, existing optimization approaches typically assume design objectives to be single values or to follow a predefined distribution. As a remedy, we propose a dominance criterion for meta-heuristic optimization approaches like evolutionary algorithms that enables the comparison of system implementations with arbitrarily distributed characteristics. Our presented experimental results show that (a) the proposed analysis comes at low overhead while capturing existing uncertainties with sufficient accuracy, and (b) the optimization process is significantly enhanced when guiding the search process by additional aspects like variance and the 95% quantile, delivering better system implementations as found by an uncertainty-oblivious optimization approach.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092365","","Boolean functions;Correlation;Data structures;Embedded systems;Optimization;Reliability;Uncertainty","Monte Carlo methods;embedded systems;evolutionary computation;optimisation;safety-critical software","Monte Carlo simulation;best/worst/average-case behavior;design objectives;destructive effects;dominance criterion;embedded systems;evolutionary algorithm;formal analysis approach;meta-heuristic optimization approach;safety-critical systems;system component uncertain characteristics;uncertainty-aware reliability analysis;uncertainty-oblivious optimization approach;worst-case mission profiles","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"May-happen-in-parallel analysis of ESL models using UPPAAL model checking","Che-wei Chang; Domer, R.","Center for Embedded Comput. Syst., Univ. of California, Irvine, Irvine, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1567","1570","In this paper, we propose an approach for May-Happen-in-Parallel (MHP) analysis of electronic system level (ESL) design which models parallel discrete event simulation with concurrent automaton processes and formally identify those MHP states. Our MHP analysis utilizes formal verification by use of the UPPAAL model checker. The proposed approach converts the system model in SpecC SLDL into an UPPAAL model and generates a set of queries that automatically and completely finds all possible MHP pairs. The experimental results show our approach can report more precise MHP analysis results compared to other works at the cost of extended analysis run time.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092640","","Analytical models;Automata;Computational modeling;Generators;Optimization;Semantics;Transform coding","discrete event simulation;electronic engineering computing;formal verification;parallel processing","ESL model;MHP analysis;SpecC SLDL;UPPAAL model checker;UPPAAL model checking;concurrent automaton process;electronic system level design;formal verification;may-happen-in-parallel analysis;parallel discrete event simulation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A high efficiency Hardware Trojan detection technique based on fast SEM imaging","Courbon, F.; Loubet-Moundi, P.; Fournier, J.J.A.; Tria, A.","Security Labs., GEMALTO, La Ciotat, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","788","793","In the semiconductor market where more and more companies become fabless, malicious integrated circuits' modifications are seen as possible threats. Those Hardware Trojans can have various effects and can be implemented by different entities with different means. This article includes the integration of an almost automatic Hardware Trojan detection. The latter is based on a visual inspection implemented within the integrated circuit life cycle. The proposed detection methodology is quite efficient regarding tools, user experience and time needed. A single layer of the chip is accessed and then imaged with a Scanning Electron Microscope (SEM). The acquisition of several hundred images at high magnification is automated as does the images registration. Then depending on the reference availability, one can check if any supplementary gates have been inserted in the design using a golden reference or a graphic/text design file. Depending on the reference, either basic image processing is used to compare the chip extracted image with a golden model or some pattern recognition can be used to retrieve the number of occurrences of each standard cell. The depicted methodology aims to detect any gate modification, substitution, removal or addition and so far require an invasive approach and a reference.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092493","","Correlation;Hardware;Image processing;Logic gates;Scanning electron microscopy;Standards;Trojan horses","image registration;inspection;integrated circuit measurement;invasive software;scanning electron microscopy","chip extracted image;fast SEM imaging;graphic-text design file;high efficiency Hardware Trojan detection technique;image acquisition;image processing;image registration;integrated circuit life cycle;pattern recognition;scanning electron microscope;semiconductor market;supplementary gates;visual inspection","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Optimization of quantum computer architecture using a resource-performance simulator","Ahsan, M.; Jungsang Kim","Dept. of Comput. Sci., Duke Univ. Durham, Durham, NC, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1108","1113","The hardware technology characterized by the device parameters (DPs) often drives the architectural optimization in a novel computer design such as the quantum computer. We highlight the role of DPs by quantifying the performance of a fully error-corrected 1024-bit quantum carry look-ahead adder on a modular, reconfigurable architecture based on trapped ions. We develop a simulation tool that estimates the performance and resource requirements for running a quantum circuit on various quantum architectures as a function of the underlying DPs. Using this tool, we found that (1) the latency of the adder circuit execution due to slow entanglement generation process for qubit communication can be adequately eliminated with a small increase in entangling qubits, and (2) the failure probability of the circuit is ultimately determined by the qubit coherence time, which needs to be improved in order to reliably execute the adders comprising core of the Shor's algorithm.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092554","device parameter;performance simulation;quantum architecture;resource performance trade-off","Computer architecture;Hardware;Logic gates;Optical switches;Performance evaluation;Quantum computing","computer architecture;optimisation;performance evaluation;probability;quantum computing","DP;Shor algorithm;architectural optimization;circuit execution;computer design;device parameters;failure probability;hardware technology;quantum circuit;quantum computer architecture optimisation;qubit communication;reconfigurable architecture;resource performance simulator;trapped ions","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Data mining diagnostics and bug MRIs for HW bug localization","Farkash, M.; Hickerson, B.; Samynathan, B.","Univ. of Texas, Austin, TX, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","79","84","This paper addresses the challenge of minimizing the time and resources required to localize bugs in HW dynamic functional verification. Our diagnostics solution eliminates the need to back trace from point of failure to its origin, decreasing the overall debugging time. The proposed solution dynamically analyses data extracted from sets of passing and failing tests to identify behavior discrepancies, which it expresses as source code lines, coverage events and timing during simulation. It also provides a visual diagnostic support, an image of the behavior discrepancies in time which we call a Machine Reasoning Image (MRI). This paper describes in detail our data mining solution based on coverage data, HDL hierarchies and time analysis of coverage events. Our approach brings a data mining solution to the problem of HW bug localization. It defines new concepts, provides in-depth analysis, presents supporting algorithms, and shows actual results on archetypical problems from PowerPC core verification as an industrial application.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092362","EDA tools;bug localization;debugging;diagnostics;verification","Data mining;Debugging;Decision trees;Magnetic resonance imaging;Monitoring;Timing;Visualization","computer debugging;data mining;inference mechanisms;program diagnostics;source code (software)","HDL hierarchies;HW bug localization;HW dynamic functional verification;behavior discrepancies;bug MRI;coverage events;data mining diagnostics;debugging time;diagnostics solution;failing tests;failure point;machine reasoning image;passing tests;source code lines;visual diagnostic support","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Automatic extraction of assertions from execution traces of behavioural models","Danese, A.; Ghasempouri, T.; Pravadelli, G.","Dept. of Comput. Sci., Univ. of Verona, Verona, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","67","72","Several approaches exist for specification mining of hardware designs. Most of them work at RTL and they extract assertions in the form of temporal relations between Boolean variables. Other approaches work at system level (e.g., TLM) to mine assertions that specify the behaviour of the communication protocol. However, these techniques do not generate assertions addressing the design functionality. Thus, there is a lack of studies related to the automatic mining of assertions for capturing the functionality of behavioural models, where logic expressions among more abstracted (e.g., numeric) variables than bits and bit vectors are necessary. This paper is intended to fill in the gap, by proposing a tool for automatic extraction of temporal assertions from execution traces of behavioural models by adopting a mix of static and dynamic techniques.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092360","","Automata;Data mining;Electronic mail;Hardware;Numerical models;Protocols;Software","Boolean functions;circuit CAD;data mining","Boolean variables;RTL;automatic temporal assertions extraction;behavioural models;bit vectors;design functionality;dynamic techniques;execution traces;hardware designs;logic expressions;specification mining;static techniques;temporal relations","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Architecture description language based retargetable symbolic execution","Ibing, A.","Dept. of IT Security, Tech. Univ. Munchen, Garching, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","241","246","This paper presents an approach to retargetable SMT-constrained symbolic execution of machine code. The retargetability is based on an existing open-source processor architecture description language which has been used for processor design and automatic generation of toolchains for dynamic program analysis. The benefit of the presented approach is that with a given architecture description, no manual writing of an instruction set grammar or of a translation of instruction semantics into logics is necessary. The proposed tool architecture relies on language reflection, code generation and dynamic loading to retarget symbolic execution to different machine code syntax. Instruction semantics is translated into SMT bit-vector logic equations by symbolically interpreting the architecture description language. The approach is implemented as plug-in extension to the Eclipse IDE and evaluated by automatically detecting integer overflows in binaries for the ARMv5 and SPARCv8 architectures.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092389","","Computer architecture;Grammar;Mathematical model;Registers;Semantics;Software;Syntactics","program compilers;program diagnostics;programming languages;public domain software","ARMv5 architecture;Eclipse IDE;SMT bit-vector logic equations;SMT-constrained symbolic execution;SPARCv8 architecture;architecture description language based retargetable symbolic execution;code generation;dynamic loading;dynamic program analysis;instruction semantics;integer overflow detection;language reflection;machine code syntax;open-source processor architecture description language;plug-in extension;processor design;toolchain automatic generation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"The next generation of virtual prototyping: Ultra-fast yet accurate simulation of HW/SW systems","Bringmann, O.; Ecker, W.; Gerstlauer, A.; Goyal, A.; Mueller-Gritschneder, D.; Sasidharan, P.; Singh, S.","Univ. of Tuebingen, Tubingen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1698","1707","Virtual Prototypes (VPs) have been now widely adopted by industry as platforms for early SW development, HW/SW co-verification, performance analysis and architecture exploration. Yet, rising design complexity, the need to test an increasing amount of software functionality as well as the verification of timing properties pose a growing challenge in the application of VPs. New approaches overcome the accuracy-speed bottleneck of today's virtual prototyping methods. These next-generation VPs are centered around ultra-fast host-compiled software models. Accuracy is obtained by advanced methods, which reconstruct the execution times of the software and model the timing behavior of the operating system, target processor and memory system. It is shown that simulation speed can further be increased by abstract TLM-based communication models and efficient hardware peripheral models. Additionally, an industrial flow for efficient model development is outlined. This support of ultra-fast and accurate HW/SW co-simulation will be a key enabler for successfully developing tomorrow's multiprocessor system-on-chip (MPSoC) platforms.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092666","","Accuracy;Computational modeling;Hardware;Kernel;Time-varying systems;Timing","digital simulation;formal verification;hardware-software codesign;multiprocessing systems;operating systems (computers);software performance evaluation;system-on-chip;virtual prototyping","abstract TLM-based communication models;design complexity;execution times;hardware peripheral models;hardware-software architecture exploration;hardware-software coverification;hardware-software performance analysis;hardware-software system simulation;industrial flow;memory system;model development;multiprocessor system-on-chip platforms;operating system;simulation speed;software functionality;target processor;timing behavior;ultra-fast host-compiled software models;virtual prototyping methods","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"DSP based programmable FHD HEVC decoder","Sangjo Lee; Joonho Song; Wonchang Lee; Doohyun Kim; Jaehyun Kim; Shihwa Lee","DMC R&D Center, Samsung Electron., Suwon, South Korea","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","972","973","A programmable video decoding system with multi-core DSP and co-processors is presented. This system is adopted by Digital TV System on Chip (SoC) and is used for FHD High Efficiency Video Coding (HEVC) decoder under 400MHz. Using the DSP based programmable solution, we can reduce commercialization period by one year because we can parallelize algorithm development, software optimization and hardware design. In addition to the HEVC decoding, the proposed system can be used for other application such as other video decoding standard for multi-format decoder or video quality enhancement.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092529","DSP;FHD;HEVC","Computer architecture;Decoding;Hardware;Instruction sets;SDRAM;Standards;VLIW","coprocessors;decoding;digital television;multiprocessing systems;system-on-chip;video coding","High Efficiency Video Coding decoder;coprocessor system;digital TV SoC;digital TV system on chip;hardware design;multicore DSP based programmable FHD HEVC decoder;parallelize algorithm development;programmable video decoding system;software optimization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A re-entrant flowshop heuristic for online scheduling of the paper path in a large scale printer","Waqas, U.; Geilen, M.; Kandelaars, J.; Somers, L.; Basten, T.; Stuijk, S.; Vestjens, P.; Corporaal, H.","Dept. of Electr. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","573","578","A Large Scale Printer (LSP) is a Cyber Physical System (CPS) printing thousands of sheets per day with high quality. The print requests arrive at run-time requiring online scheduling. We capture the LSP scheduling problem as online scheduling of reentrant flowshops with sequence dependent setup times and relative due dates with makespan minimization as the scheduling criterion. Exhaustive approaches like Mixed Integer Programming can be used, but they are compute intensive and not suited for online use. We present a novel heuristic for scheduling of LSPs that on average requires 0.3 seconds per sheet to find schedules for industrial test cases. We compare the schedules to lower bounds, to schedules generated by the current scheduler and schedules generated by a modified version of the classical NEH (MNEH) heuristic [1], [2]. On average, the proposed heuristic generates schedules that are 40% shorter than the current scheduler, have an average difference of 25% compared to the estimated lower bounds and generates schedules with less than 67% of the makespan of schedules generated by the MNEH heuristic.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092452","","Job shop scheduling;Printers;Printing;Processor scheduling;Productivity;Schedules","flow shop scheduling;integer programming;minimisation;printers","CPS;LSP scheduling problem;MNEH heuristic;cyber physical system;large scale printer;makespan minimization;mixed integer programming;online paper path scheduling;online reentrant flowshop scheduling;reentrant flowshop heuristic;relative due dates;sequence dependent setup times","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Digital circuits reliability with in-situ monitors in 28nm fully depleted SOI","Saliva, M.; Cacho, F.; Huard, V.; Federspiel, X.; Angot, D.; Benhassain, A.; Bravaix, A.; Anghel, L.","STMicroelectron., Crolles, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","441","446","Aging induced degradation mechanisms occurring in digital circuits are of a greater importance in the latest technologies. Monotonic degradation such as Bias Temperature Instability (BTI) or Hot Carrier Injection (HCI) but also sudden degradation such as Dielectric Breakdown (DB) are identified as the major sources of reliability hazard. The impact of these phenomena on the digital circuits is usually observed in terms of timing degradations and thus may result in setup/hold violation. In this paper we will focus on the impact of aging related degradation mechanisms on timing. In-situ monitor is a promising strategy to measure timing slacks and to provide pre-error warnings prior to timing violation. In this paper, we have developed a dedicated test structure to measure and benchmark the behavior of different monitors. The design of monitors is mostly based on delay elements. Three types of delays are proposed in this paper: flip-flop's Master delay, Buffers delay and Passive delay. In addition, we investigate the impact of global and local variations on the accuracy of the measurements by providing complete monitors characterization. The technology used for the test structure and in-situ monitors is 28nm Fully Depleted Silicon On Insulator. Experimental results show a good agreement with SPICE simulation. Finally the proposed in-situ monitors will be compared and their applications to circuit aging prediction will be discussed.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092430","28FullyDepleted-SOI;BTI;Dielectric Breakdown;HCI;aging;in-situ monitors;reliability;simulations;timing","Degradation;Delays;Monitoring;Stress;Temperature measurement;Temperature sensors","digital circuits;electric breakdown;integrated circuit reliability;silicon-on-insulator","BTI;DB;HCI;SPICE simulation;aging induced degradation mechanism;bias temperature instability;buffer delay;circuit aging prediction;delay element;dielectric breakdown;digital circuit reliability;flipflop master delay;fully depleted SOI;hot carrier injection;in-situ monitor;local variation;monotonic degradation;passive delay;preerror warning;reliability hazard;setup/hold violation;silicon on insulator;size 28 nm;timing slack","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Profiling-driven multi-cycling in FPGA high-level synthesis","Hadjis, S.; Canis, A.; Sobue, R.; Hara-Azumi, Y.; Tomiyama, H.; Anderson, J.","Dept. of Electr. & Comput. Eng., Univ. of Toronto, Toronto, ON, Canada","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","31","36","Multi-cycling is a well-known strategy to improve performance in digital design, wherein the required time for selected combinational paths is lengthened to multiple clock cycles (rather than just one). The approach can be applied to paths associated with computations whose results are not needed immediately - such paths are allowed multiple clock cycles to “complete”, reducing the opportunity for them to form the critical path of the circuit. In this paper, we consider multi-cycling in the high-level synthesis context (HLS) and use software profiling to guide multi-cycling optimizations. Specifically, prior to HLS, we execute the program in software with typical datasets to gather data on the number of times each code segment executes. During HLS, we then extend the schedule for infrequently executed code segments and apply multi-cycling to the dilated schedules, which exhibit greater opportunities for multi-cycling. In essence, our approach ensures that non-frequently executed code segments will not form the critical path of the HLS-generated circuit. In an experimental study targeting the Altera Stratix IV FPGA, we evaluate the impact on speed performance and area for both traditional multi-cycling, as well as the proposed software profiling-driven multi-cycling, and show that profiling-driven multi-cycling leads to an average speedup of over 10% across 13 benchmark circuits, with some circuit speedups in excess of 30%. Circuit area is reduced by 11%, yielding a mean 20% improvement in area-delay product.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092354","","Clocks;Cutoff frequency;Delays;Hardware;Particle separators;Registers;Software","field programmable gate arrays;high level synthesis","Altera Stratix IV FPGA high-level synthesis;HLS-generated circuit;benchmark circuit;multiple clock cycle;nonfrequently executed code segment;software profiling-driven multicycling optimization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"System level exploration of a STT-MRAM based level 1 data-cache","Perumkunnil Komalan, M.; Tenllado, C.; Gomez Perez, J.I.; Tirado Fernandez, F.; Catthoor, F.","Dept. of Comput. Archit. & Autom., Univ. Complutense de Madrid, Madrid, Spain","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1311","1316","Since Non-Volatile Memory (NVM) technologies are being explored extensively nowadays as viable replacements for SRAM based memories in LLCs and even L2 caches, we try to take stock of their potential as level 1 (L1) data caches. These NVMs like Spin Torque Transfer RAM(STT-MRAM), Resistive-RAM(ReRAM) and Phase Change RAM (PRAM) are not subject to leakage problems with technology scaling. They also show significant area gains and lower dynamic power consumption. A direct drop-in replacement of SRAM by NVMs is, however, still not feasible due to a number of shortcomings with latency (write or read) and/or endurance/reliability among them being the major issues. STT-MRAM is increasingly becoming the NVM of choice for high performance and general purpose embedded platforms due to characteristics like low access latency, low power and long lifetime. With advancements in cell technology, and taking into account the stringent reliability and performance requirements for advanced technology nodes, the major bottleneck to the use of STT-MRAM in high level caches has become read latency (instead of write latency as previously believed). The main focus of this paper is the exploration of read penalty issues in a NVM based L1 data cache (D-cache) for an ARM like single core general purpose system. We propose a design method for the STT-MRAM based D-cache in such a platform. This design addresses the adverse effects due to the STT-MRAM read penalty issues by means of micro-architectural modifications along with code transformations. According to our simulations, the appropriate tuning of selective architecture parameters in our proposal and suitable optimizations can reduce the performance penalty introduced by the NVM (initially ~54%) to extremely tolerable levels (~8%).","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092595","","Computer architecture;Nonvolatile memory;Optimization;Organizations;Phase change random access memory;Proposals","SRAM chips;resistive RAM","LLC;NVM based L1 data cache;NVM technologies;PRAM;ReRAM;SRAM based memories;STT-MRAM based D-cache;STT-MRAM based level 1 data cache;advanced technology nodes;cell technology;code transformations;direct drop-in replacement;dynamic power consumption;high level caches;microarchitectural modifications;nonvolatile memory;performance penalty;phase change RAM;resistive RAM;selective architecture parameters;spin torque transfer RAM;stringent reliability;system level exploration;technology scaling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Improved practical differential fault analysis of Grain-128","Dey, P.; Chakraborty, A.; Adhikari, A.; Mukhopadhyay, D.","Dept. of Pure Math., Univ. of Calcutta, Kolkata, India","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","459","464","Differential Fault Attacks (DFA) on stream ciphers have been an active field of research. However, their practical realizations have not been reported in the public literature. Hence, the assumptions on the fault models made in the context of DFA for stream ciphers have not been studied. Furthermore, there have been few efforts reported on the popular stream cipher candidate, Grain-128. We consider a simple low-cost fault injection set-up, using clock glitches and show that in stream ciphers the critical path of the circuit affects few bit positions (the feedback bit for the Shift Registers in the stream ciphers). Thus the fault is often localized to single bit position, and because of the absence of required faulty ciphers makes existing theoretical DFAs invalid. In order to create multiple instance of faults, we use clock glitches to induce the fault, and then use the shifting property of the internal registers of Grain to create multiple instances of contiguously located faults. In parallel, we also develop a more relaxed DFA for Grain-128, to show that when the fault is k neighbourhood bits, k ϵ {1,...,5}, the attack is successful to retrieve the key without knowing the locations or exact number of bits flipped by the internal fault. We also devise a technique for rejecting the bad faults with high probabilities, i.e., when the faults are not in the contiguous location as required in the attack. Combining the above attacks we demonstrate using a simple set-up via clock glitches that such faults can be practically obtained and analysed using the proposed attack algorithm to retrieve the key.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092433","","Ciphers;Circuit faults;Clocks;Computational modeling;Fault location;Shift registers","clocks;fault diagnosis","DFA;Grain-128;attack algorithm;clock glitches;differential fault analysis;differential fault attacks;fault injection set-up;fault models;faulty ciphers;feedback bit;internal fault;internal registers;shift registers;shifting property;stream ciphers","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A hybrid packet/circuit-switched router to accelerate memory access in NoC-based chip multiprocessors","Mazloumi, A.; Modarressi, M.","Sch. of Electr. & Comput. Eng., Univ. of Tehran, Tehran, Iran","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","908","911","Modern chip multiprocessors will feature a large shared last-level cache (LLC) that is decomposed into smaller slices and physically distributed throughout the chip area. These architectures rely on a network-on-chip (NoC) to handle remote cache access and hence, NoCs play a critical role in optimizing memory access latency and power consumption. Circuit-switching is the most power- and performance-efficient switching mechanism in NoCs, but is not advantageous when the packet transmission time is not long enough compared to the circuit setup time. In this paper, we propose a zero-latency circuit setup scheme to make circuit-switching applicable in transferring individual data packets. The design leverages the fact that in CMPs with distributed LLC (where a considerable portion of the on-chip traffic is composed of remote LLC access requests and data responses), every response packet is sent in reply to a request packet and traverses the same path as its corresponding request, but at the backward direction. The short request packets, then, are responsible to reserve a path for their corresponding response packets. This NoC tries to reduce conflict among circuit paths by considering conflicts in backward direction during request packet routing, backed by a run-time technique to resolve conflicts when circuits are actually set up. Experimental results show that the proposed NoC architecture considerably reduces average packet latency that directly translates to faster memory access.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092516","Chip-multiprocessor;Circuit-switching;Memory-access;Network-on-chip","Computer architecture;Ports (Computers);Probes;Resource management;Routing;Switching circuits;System-on-chip","circuit switching;integrated memory circuits;microprocessor chips;network routing;network-on-chip;packet switching","NoC-based chip multiprocessors;circuit-switching;hybrid packet/circuit-switched router;last-level cache;memory access latency;network-on-chip;packet routing;power consumption;remote cache access","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Quality configurable reduce-and-rank for energy efficient approximate computing","Raha, A.; Venkataramani, S.; Raghunathan, V.; Raghunathan, A.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","665","670","Approximate computing is an emerging design paradigm that exploits the intrinsic ability of applications to produce acceptable outputs even when their computations are executed approximately. In this work, we explore approximate computing for a key computation pattern, Reduce-and-Rank (RnR), which is prevalent in a wide range of workloads including video processing, recognition, search and data mining. An RnR kernel performs a reduction operation (e.g., distance computation, dot product, L1-norm) between an input vector and each of a set of reference vectors, and ranks the reduction outputs to select the top reference vectors for the current input. We propose two complementary approximation strategies for the RnR computation pattern. The first is interleaved reduction-and-ranking, wherein the vector reductions are decomposed into multiple partial reductions and interleaved with the rank computation. Leveraging this transformation, we propose the use of intermediate reduction results and ranks to identify future computations that are likely to have low impact on the output, and can hence be approximated. The second strategy, input similarity based approximation, exploits the spatial or temporal correlation of inputs (e.g., pixels of an image or frames of a video) to identify computations that are amenable to approximation. These strategies address a key challenge in approximate computing - identification of which computations to approximate - and may be used to drive any approximation mechanism such as computation skipping and precision scaling to realize performance or energy improvements. A second key challenge in approximate computing is that the extent to which computations can be approximated varies significantly from application to application, and across inputs for even a single application. Hence, quality configurability, or the ability to automatically modulate the degree of approximation at runtime is essential. To enable quality configurability in RnR ker- els, we propose a kernel-level quality metric that correlates well to application-level quality, and identify key parameters that can be used to tune the proposed approximation strategies dynamically. We develop a runtime framework that modulates the identified parameters during execution of RnR kernels to minimize their energy while meeting a given target quality. To evaluate the proposed concepts, we designed quality-configurable hardware implementations of 6 RnR-based applications from the recognition, mining, search and video processing application domains in 45nm technology. Our experiments demonstrate 1.06X-2.18X reduction in energy consumption with virtually no loss in output quality (<;0.5%) at the application-level. The energy benefits further improve up to 2.38X and 2.5X when the quality constraints are relaxed to 2.5% and 5% respectively.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092472","","Approximation algorithms;Approximation methods;Calibration;Correlation;Kernel;Training","approximation theory;data mining;pattern recognition;search problems","RnR computation pattern;application-level quality;computation skipping;energy efficient approximate computing;interleaved reduction-and-ranking;kernel-level quality metric;precision scaling;quality configurable reduce-and-rank;search and data mining;video processing;video recognition","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Multi/many-core programming: Where are we standing?","Castrillon, J.; Thiele, L.; Schorr, L.; Weihua Sheng; Juurlink, B.; Alvarez-Mesa, M.; Jessenberger, R.; Reyes, V.; Leupers, R.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1708","1717","This paper presents different views exposed in a special session on the current standing of programming and design tools for multi and manycores in the embedded domain. After approximately ten years of the advent of multicore architectures, we take a look at state-of-the-art and trends in model-based programming methodologies from an academic point of view. This view is contrasted with early experiences in transferring multicore compiler research to industry, and complemented with a critical view on the performance gap introduced by compilers for complex architectures. Today, multicores permeate new applications domains, creating new requirements and forcing researchers to rethink some underlying assumptions. This paper exposes the requirements of one such new domain, namely automotive. Applications in this domain require not only programming tools that comply to standards (e.g., ISO 26262) but also tools for high-level simulation, performance analysis and debugging. In this context, we discuss the role of virtual platforms in managing complexity of hardware-software interactions and accelerating the design of multicore systems for automotive applications.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092667","","Industries;Multicore processing;Parallel processing;Programming;Real-time systems;Software","multiprocessing systems;program compilers;program debugging","automotive applications;complex architectures;debugging;hardware-software interactions;many-core programming;model-based programming methodologies;multicore architectures;multicore compiler;multicore programming;performance analysis;programming tools;virtual platforms","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"SelectDirectory: A selective directory for cache coherence in many-core architectures","Yuan Yao; Guanhua Wang; Zhiguo Ge; Mitra, T.; Wenzhi Chen; Naxin Zhang","Coll. of Comput. Sci. & Technol., Zhejiang Univ., Hangzhou, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","175","180","As we move into many-core era fueled by Moore's Law, it has become unprecedentedly challenging to provide the shared memory abstraction through directory-based cache coherence. The main difficulty is the high area and power overhead of the directory in tracking the presence of a memory block in all the private caches. Sparse directory offers relatively better design trade-offs by decoupling the coherence meta-data from the last-level cache (LLC); but still suffers from high area/power issues. In this work, we propose a compact directory design by exploiting the observation that a significant fraction of the memory blocks are temporarily exclusive in the cache hierarchy and hence only needs minimal sharer information. Inspired by this observation, we propose to further decouple the tag array from the coherence meta-data array in the sparse directory and allocate a sharer list only for the actively shared blocks. Experimental results reveal that our proposal, called SelectDirectory, can substantially save directory storage area and energy without sacrificing performance.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092378","","Arrays;Coherence;Proposals;Protocols;System-on-chip;Tracking;Upper bound","cache storage;meta data;multiprocessing systems;resource allocation;shared memory systems","LLC;Moore Law;SelectDirectory;actively shared blocks;coherence metadata array;directory storage area;directory-based cache coherence;last-level cache;many-core architectures;memory block;memory blocks;private caches;selective directory;shared memory abstraction;tag array","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A generic, scalable and globally arbitrated memory tree for shared DRAM access in real-time systems","Dev Gomony, M.; Garside, J.; Akesson, B.; Audsley, N.; Goossens, K.","Eindhoven Univ. of Technol., Eindhoven, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","193","198","Predictable arbitration policies, such as Time Division Multiplexing (TDM) and Round-Robin (RR), are used to provide firm real-time guarantees to clients sharing a single memory resource (DRAM) between the multiple memory clients in multi-core real-time systems. Traditional centralized implementations of predictable arbitration policies in a shared memory bus or interconnect are not scalable in terms of the number of clients. On the other hand, existing distributed memory interconnects are either globally arbitrated, which do not offer diverse service according to the heterogeneous client requirements, or locally arbitrated, which suffers from larger area, power and latency overhead. Moreover, selecting the right arbitration policy according to the diverse and dynamic client requirements in reusable platforms requires a generic re-configurable architecture supporting different arbitration policies. The main contributions in this paper are: (1) We propose a novel generic, scalable and globally arbitrated memory tree (GSMT) architecture for distributed implementation of several predictable arbitration policies. (2) We present an RTL-level implementation of Accounting and Priority assignment (APA) logic of GSMT that can be configured with five different arbitration policies typically used for shared memory access in real-time systems. (3) We compare the performance of GSMT with different centralized implementations by synthesizing the designs in a 40 nm process. Our experiments show that with 64 clients GSMT can run up to four times faster than traditional architectures and have over 51% and 37% reduction in area and power consumption, respectively.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092381","","Bandwidth;Clocks;Real-time systems;Registers;Silicon;Time division multiplexing","DRAM chips;multiprocessing systems;real-time systems;time division multiplexing","APA logic;GSMT architecture;RR;TDM;accounting and priority assignment;distributed memory interconnects;diverse client requirements;dynamic client requirements;generic arbitrated memory tree;globally arbitrated memory tree;multicore real-time systems;real-time systems;round-robin;scalable arbitrated memory tree;shared DRAM access;shared memory bus;single memory resource;time division multiplexing","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Approximate associative memristive memory for energy-efficient GPUs","Rahimi, A.; Ghofrani, A.; Kwang-Ting Cheng; Benini, L.; Gupta, R.K.","CSE, UC San Diego, La Jolla, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1497","1502","Multimedia applications running on thousands of deep and wide pipelines working concurrently in GPUs have been an important target for power minimization both at the architectural and algorithmic levels. At the hardware level, energy-efficiency techniques that employ voltage overscaling face a barrier so-called “path walls”: reducing operating voltage beyond a certain point generates massive number of timing errors that are impractical to tolerate. We propose an architectural innovation, called A<sup>2</sup>M<sup>2</sup> module (approximate associative memristive memory) that exhibits few tolerable timing errors suitable for GPU applications under voltage overscaling. A<sup>2</sup>M<sup>2</sup> is integrated with every floating point unit (FPU), and performs partial functionality of the associated FPU by pre-storing high frequency patterns for computational reuse that avoids overhead due to re-execution. Voltage overscaled A<sup>2</sup>M<sup>2</sup> is designed to match an input search pattern with any of the stored patterns within a Hamming distance range of 0-2. This matching behavior under voltage overscaling leads to a controllable approximate computing for multimedia applications. Our experimental results for the AMD Southern Islands GPU show that four image processing kernels tolerate the mismatches during pattern matching resulting in a PSNR ≥ 30dB. The A<sup>2</sup>M<sup>2</sup> module with 8-row enables 28% voltage overscaling in 45nm technology resulting in 32% average energy saving for the kernels, while delivering an acceptable quality of service.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092626","","Approximation methods;Graphics processing units;Image processing;Kernel;Memristors;PSNR;Pattern matching","content-addressable storage;energy conservation;graphics processing units;image matching;multimedia systems;power aware computing;quality of service","A<sup>2</sup>M<sup>2</sup> module;AMD Southern Islands GPU;FPU;Hamming distance;algorithmic level;approximate associative memristive memory;architectural innovation;architectural level;computational reuse;energy-efficient GPU;floating point unit;high frequency patterns;image processing kernels;multimedia applications;path walls;pattern matching;power minimization;quality of service;timing errors;voltage overscaling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"QR-decomposition architecture based on two-variable numeric function approximation","Rust, J.; Ludwig, F.; Paul, S.","Inst. of Electrodynamics & Microelectron., Univ. of Bremen, Bremen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","892","895","This paper presents a new approach for hardware-based QR-decomposition using an efficient computation scheme of the Givens-Rotation. In detail, the angle of rotation and its application to the Givens-Matrix are processed in a direct, straightforward manner. High-performance signal processing is achieved by piecewise approximation of the arctangent and sine function. In order to identify appropriate function approximations, several designs with varying constraints are automatically generated and analyzed. Physical and logical synthesis is performed in a 130 nm CMOS-technology. The application of our proposal in a multi-antenna mobile communication scenario highlights our work to be very efficient in terms of calculation accuracy and computation performance.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092512","Givens-Rotation;QR-decomposition;VLSI;numeric function approximation;two-variable","Accuracy;Bit error rate;Computer architecture;Function approximation;MIMO;Signal processing","function approximation;matrix decomposition;signal processing","CMOS-technology;Givens-matrix;Givens-rotation;QR-decomposition architecture;arctangent function;high-performance signal processing;piecewise approximation;sine function;two-variable numeric function approximation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"HReRAM: A hybrid reconfigurable resistive random-access memory","Lastras-Montano, M.A.; Ghofrani, A.; Kwang-Ting Cheng","Dept. of Electr. & Comput. Eng., Univ. of California, Santa Barbara, Santa Barbara, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1299","1304","Passive crossbar arrays of memristors have been identified as excellent alternatives for future random-access memories. One limitation is their inability of selecting a memory cell without the interference caused by the sneak-path currents from other partially selected cells, as it results not only in unnecessary waste of energy but also in larger current requirements. The complementary resistive switch (CRS), consisting in two anti-serially connected memristors, is considered a potential solution to the sneak-path problem. However, the destructive read operation and reduced endurance of the CRS render it unattractive for the otherwise excellent candidate for next-generation crossbar-based non-volatile memories. In this paper we explore the feasibility and tradeoffs of configuring part of the CRS memory into a memristive mode to mitigate these limitations. The inherent locality of memory accesses for most computer programs offers an opportunity for designing a cache-like adaptive CRS-based crossbar memory with hybrid configurations of CRS and memristive modes, enabling optimization for both endurance and energy consumption. Our simulation results validate that the proposed hybrid system achieves 1.5-7x reduction in energy consumption in comparison with a memristive-only memory system and significantly improves the endurance of the CRS-based memory.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092593","","Energy consumption;Memory management;Memristors;Random access memory;Resistance;Switches;Voltage measurement","cache storage;memristors;reconfigurable architectures;resistive RAM","HReRAM;anti-serially connected memristors;cache like adaptive CRS-based crossbar memory;complementary resistive switch;destructive read operation;energy consumption;hybrid reconfigurable resistive random access memory;memory access;next generation crossbar-based nonvolatile memory;optimization;passive crossbar array;reduced endurance;sneak path problem","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A closed loop transmitting power self-calibration scheme for energy efficient WiNoC architectures","Mineo, A.; Rusli, M.S.; Palesi, M.; Ascia, G.; Catania, V.; Marsono, M.N.","Univ. of Catania, Catania, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","513","518","In a wireless Network-on-Chip (WiNoC) the radio transceiver accounts for a significant fraction of the total communication energy. Recently, a configurable transceiver architecture able to regulate its transmitting power based on the location of the destination node has been proposed. Unfortunately, the use of such transceiver requires a costly, time consuming and complex characterization phase performed at design time and mainly based on the use of field solver simulators whose accuracy has not yet been proved in the context of integrated on-chip antennas. In this paper we present a closed loop transmitting power self-calibration mechanism which allows to determine on-line the optimal transmitting power for each transmitting and receiving pair in a WiNoC. The proposed mechanism is general and can be applied to any WiNoC architecture with a low overhead in terms of silicon area. Its application to three well known WiNoC architectures shows its effectiveness in drastically reducing the overall communication energy (up to 50%) with a limited impact on performance.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092442","","Antennas;Attenuation;Bit error rate;Radio transmitters;Receivers;Transceivers;Wireless communication","low-power electronics;network-on-chip;radio transceivers","closed loop transmitting power self-calibration scheme;energy efficient WiNoC architectures;integrated on-chip antennas;radio transceiver;transceiver architecture;wireless Network-on-Chip","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Inter-tile reuse optimization applied to bandwidth constrained embedded accelerators","Peemen, M.; Mesman, B.; Corporaal, H.","Dept. of Electr. Eng., Eindhoven Univ. of Technol., Eindhoven, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","169","174","The adoption of High-Level Synthesis (HLS) tools has significantly reduced accelerator design time. A complex scaling problem that remains is the data transfer bottleneck. To scale-up performance accelerators require huge amounts of data, and are often limited by interconnect resources. In addition, the energy spent by the accelerator is often dominated by the transfer of data, either in the form of memory references or data movement on interconnect. In this paper we drastically reduce accelerator communication by exploration of computation reordering and local buffer usage. Consequently, we present a new analytical methodology to optimize nested loops for inter-tile data reuse with loop transformations like interchange and tiling. We focus on embedded accelerators that can be used in a multi-accelerator System on Chip (SoC), so performance, area, and energy are key in this exploration. 1) On three common embedded applications in the image/video processing domain (demosaicing, block matching, object detection), we show that our methodology reduces data movement up to 2.1x compared to the best case of intra-tile optimization. 2) We demonstrate that our small accelerators (1-3% FPGA resources) can boost a simple MicroBlaze soft-core to the performance level of a high-end Intel-i7 processor.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092377","","Arrays;Bismuth;Cost function;Data transfer;Schedules;Steady-state","buffer storage;circuit optimisation;embedded systems;graphics processing units;high level synthesis;multiprocessor interconnection networks;system-on-chip","MicroBlaze soft core;bandwidth constrained embedded accelerator;buffer usage;complex scaling problem;data transfer;embedded applications;high-end Intel-i7 processor;high-level synthesis;inter-tile reuse optimization;interconnect resource;loop transformation;multiaccelerator SoC;nested loop optimization;system on chip","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A CNN-inspired mixed signal processor based on tunnel transistors","Sedighi, B.; Palit, I.; Hu, X.S.; Nahas, J.; Niemier, M.","Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1150","1155","Novel devices are under investigation to extend the performance scaling trends that have long been associated with Moore's Law-based device scaling. Among the emerging devices being studied, tunnel FETs (or TFETs) are particularly attractive, especially when targeting low power systems. This paper studies the potential of analog/mixed-signal information processing using TFETs. The design of a highly-parallel processor - inspired by cellular neural networks - is presented. Signal processing is performed partially in the time-domain to better leverage the unique properties of TFETs, i.e., (i) steep slopes (high g<sub>m</sub>/I<sub>DS</sub>) in the subthreshold region, and (ii) high output resistance in the saturation region. Assuming an InAs TFET with feature sizes comparable to the 14 nm technology node, a power efficiency of 10,000 GOPS/W is projected. By comparison, state-of-the-art hardware assuming CMOS technology promises a power efficiency only close to 1,000 GOPS/W.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092561","","CMOS integrated circuits;Clocks;Computer architecture;Microprocessors;Power dissipation;Radiation detectors;Transistors","CMOS digital integrated circuits;cellular neural nets;field effect transistors;microprocessor chips;mixed analogue-digital integrated circuits;time-domain analysis;tunnel transistors","CMOS technology;CNN-inspired mixed signal processor;Moore law-based device scaling;analog-mixed-signal information processing;cellular neural networks;high-output resistance;highly-parallel processor;indium arsenide TFET;low-power systems;performance scaling trend;power efficiency;saturation region;signal processing;steep slopes;subthreshold region;time-domain;tunnel FET;tunnel transistors","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Towards an accurate reliability, availability and maintainability analysis approach for satellite systems based on probabilistic model checking","Hoque, K.A.; Mohamed, O.A.; Savaria, Y.","Concordia Univ., Montreal, QC, Canada","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1635","1640","From navigation to telecommunication, and from weather forecasting to military, or entertainment services-satellites play a major role in our daily lives. Satellites in the Medium Earth Orbit (MEO) and geostationary orbit have a life span of 10 years or more. Reliability, Availability and Maintainability (RAM) analysis of a satellite system is a crucial part at their design phase to ensure the highest availability and optimized reliability. This paper shows the formal modeling and verification of RAM related properties of a satellite system. In a previously reported approach, time between possible failures and time between repairs are assumed to follow an exponential distribution, which does not represent a realistic scenario. In contrast, in our work, discrete time delays in the classical Continuous Time Markov Chain (CTMC) are approximated using the Erlang distribution. This is done by approximating nonexponential holding time with several intermediate states based on a phase type distribution. The RAM properties are then verified using the PRISM model checker. We present and compare modeling results with those obtained with a previously reported approach that demonstrate an improved modeling accuracy.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092655","","Availability;Maintenance engineering;Markov processes;Model checking;Probabilistic logic;Satellites","Markov processes;aerospace computing;artificial satellites;delays;formal verification;reliability","CTMC;Erlang distribution;PRISM model checker;RAM analysis;continuous time Markov chain;discrete time delays;formal modeling;formal verification;nonexponential holding time approximation;phase type distribution;probabilistic model checking;reliability-availability-and-maintainability analysis;satellite systems","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"PhaseNoC: TDM scheduling at the virtual-channel level for efficient network traffic isolation","Psarras, A.; Seitanidis, I.; Nicopoulos, C.; Dimitrakopoulos, G.","Electr. & Comput. Eng, Democritus Univ. of Thrace, Xanthi, Greece","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1090","1095","The efficiency of modern Networks-on-Chip (NoC) is no longer judged solely by their physical scalability, but also by their ability to deliver high performance, Quality-of-Service (QoS), and flow isolation at the minimum possible cost. Although traditional architectures supporting Virtual Channels (VC) offer the resources for flow partitioning and isolation, an adversarial workload can still interfere and degrade the performance of other workloads that are active in a different set of VCs. In this paper, we present PhaseNoC, a truly non-interfering VC-based architecture that adopts Time-Division Multiplexing (TDM) at the VC level. Distinct flows, or application domains, mapped to disjoint sets of VCs are isolated, both inside the router's pipeline and at the network level. Any latency overhead is minimized by appropriate scheduling of flows in separate phases of operation, irrespective of the chosen topology. The resulting design yields significant reductions in the area/delay cost of the network. Experimental results corroborate that - with lower cost than state-of-the-art NoC architectures, and with minimum latency overhead - we remove any flow interference and allow for efficient network traffic isolation.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092551","","Pipeline processing;Pipelines;Resource management;Schedules;Switches;Throughput;Time division multiplexing","telecommunication channels;telecommunication network routing;telecommunication scheduling;telecommunication traffic;time division multiplexing","NoC architectures;PhaseNoC;QoS;TDM scheduling;VC-based architecture;flow interference;flow isolation;flow partitioning;network traffic isolation;networks-on-chip;quality-of-service;router pipeline;time-division multiplexing;virtual-channel level","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Gait analysis for fall prediction using hierarchical textile-based capacitive sensor arrays","Baldwin, R.; Bobovych, S.; Robucci, R.; Patel, C.; Banerjee, N.","CSEE, Univ. of Maryland, Baltimore County, Baltimore, MD, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1293","1298","Falls are a major cause of injuries in adults above the age of sixty-five. The economic aftermath of falls and their consequent hospitalization can be huge, totaling more than 30 billion dollars in 2010 alone. A plausible way of mitigating this problem is accurate prediction of future falls and taking proactive remedial action. Spatio-temporal variation in gait is a reliable indicator of a future fall, however, existing systems focus on gait analysis in clinical settings and are not tuned towards continuous gait analysis. In this paper, we present the design of a novel textile capacitive sensor array-based system built into clothing that can reliably capture spatio-temporal gait attributes in a home setting. A key novel research contribution of our work is a context-aware hierarchical signal processing architecture that breaks down the signal processing algorithm into a hierarchy of processing elements. The lower power processing components perform generic feature extraction using observations derived from the capacitor plates, while the higher-level processors aggregate features to infer gait attributes such as stride speed and inter-leg spacing. The system activates the higher power processing elements only when it detects walking. We have prototyped our system using textile capacitive plates built into an ace-bandage and a custom FPGA-based system and show that our system can accurately detect gait attributes that have high correlation with falls, while consuming minimal energy as estimated for a multi-clock-domain 180-nm IC.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092592","","Accuracy;Capacitive sensors;Capacitors;Feature extraction;Legged locomotion;Sensor arrays","capacitive sensors;capacitors;feature extraction;field programmable gate arrays;gait analysis;injuries;medical signal detection;medical signal processing;sensor arrays;spatiotemporal phenomena","FPGA-based system;ace-bandage;context-aware hierarchical signal processing architecture;fall prediction;feature extraction;gait analysis;hierarchical textile-based capacitive sensor arrays;higher-level processors aggregate features;hospitalization;injuries;inter-leg spacing;multiclock-domain IC;spatiotemporal gait attributes;spatiotemporal variation;stride speed;textile capacitive plates;walking","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A neural machine interface architecture for real-time artificial lower limb control","Kane, J.; Qing Yang; Hernandez, R.; Simoneau, W.; Seaton, M.","Dept. of Electr., Comput., & Biomed. Eng., Univ. of Rhode Island, Kingston, RI, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","633","636","This paper presents a novel architecture of a lower limb neural machine interface (NMI) for determination of user intent. Our new design and implementation paves the way for future bionic legs that require high speed real-time deterministic response, high accuracy, easy portability, and low power consumption. A working FPGA-based prototype has been built, and experiments have shown that it achieves average performance gains of around 8x that of the equivalent software algorithm running on an Intel Core i7 2670QM, or 24x that of an Intel Atom Z530 with no perceivable loss in accuracy. Furthermore, our fully pipelined and parallel non-linear support vector machine-based FPGA implementation led to a 6.4x speedup over an equivalent GPU-based design. In this paper, we also characterize our achieved timing margin to show that our design is capable of supporting real-time wireless communications. With additional refinement, such a wireless personal area network (PAN) system will provide improved flexibility on an individual basis for electromyography (EMG) sensor placement.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092466","Artificial Leg Control;Field Programmable Gate Arrays (FPGA);Neural Machine Interface (NMI);Parallel Architectures;Support Vector Machines (SVM)","Electromyography;Feature extraction;Field programmable gate arrays;Hardware;Real-time systems;Support vector machines;Wireless communication","artificial limbs;brain-computer interfaces;field programmable gate arrays;parallel processing;personal area networks;pipeline processing;support vector machines","PAN system;neural machine interface architecture;nonlinear support vector machine;parallel FPGA implementation;pipelined FPGA implementation;real-time artificial lower limb control;real-time wireless communications;timing margin;user intent determination;wireless personal area network","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A new distributed framework for integration of district energy data from heterogeneous devices","Brundu, F.G.; Patti, E.; Acquaviva, A.; Grosso, M.; Rascona, G.; Rinaudo, S.; Macii, E.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","992","993","The introduction of ”smart” low-cost sensing (and actuating) devices enabled the recent diffusion of technological products within the ”Internet of Things” paradigm. In a city district context, such devices are crucial for visualization and simulation of energy consumption trends, to increase the energy distribution network efficiency and promote user awareness. Nevertheless, to unlock the potential of this technology, many challenges have to be faced at district level due to the current lack of interoperability between heterogeneous data sources. In this work, we introduce an original infrastructure model, which efficiently manage and integrate district energy data.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092534","","Buildings;Cities and towns;Data models;Databases;Energy consumption;Interoperability;Web services","Internet of Things;data integration;distribution networks;energy consumption;open systems;power engineering computing;sensors","Internet of Things paradigm;district energy data integration;energy consumption;energy distribution network efficiency;heterogeneous data sources;heterogeneous devices;interoperability;smart low-cost actuating devices;smart low-cost sensing devices;user awareness","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Efficient bit error rate estimation for high-speed link by Bayesian model fusion","Chenlei Fang; Qicheng Huang; Fan Yang; Xuan Zeng; Xin Li; Chenjie Gu","Microelectron. Dept., Fudan Univ., Shanghai, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1024","1029","High-speed I/O link is an important component in computer systems, and estimating its bit error rate (BER) is a critical task to guarantee its performance. In this paper, we propose an efficient method to estimate BER by Bayesian Model Fusion. Its key idea is to borrow conventional extrapolated BER value as prior knowledge, and combine it with additional measurement data to “calibrate” the BER value. This method can be viewed as an application of Bayesian Model Fusion (BMF) technique. We further propose some novel methodologies to make BMF applicable in the BER estimation case. In this way, we can sufficiently decrease the number of bits needed to estimate BER value. Several experiments demonstrate that our proposed method achieves up to 8× speed-up over direct estimation method.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092540","","Bayes methods;Bit error rate;Extrapolation;Maximum likelihood estimation;Time measurement;Voltage measurement","Bayes methods;error statistics;extrapolation;input-output programs;sensor fusion","BER extrapolation value;BER value calibration;Bayesian model fusion;efficient bit error rate estimation;high-speed I-O link;measurement data","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Cooperatively managing dynamic writeback and insertion policies in a last-level DRAM cache","Shouyi Yin; Jiakun Li; Leibo Liu; Shaojun Wei; Yike Guo","Inst. of Microelectron., Tsinghua Univ., Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","187","192","Stacked-DRAM used as the last-level caches(LLC) in multi-core systems delivers performance enhancement due to its capacity benefit. While the performance of LLC depends heavily upon its block replacement policy, conventional replacement policy needs redesigning to exploit the best of DRAM cache while avoiding its drawbacks. Existing DRAM cache insertion policy blindly forwards victim lines to the off-chip memory, regardless of the potential for increased hits by placing a fraction of them in the DRAM cache; nevertheless, a näıve design that steers all dirty victims to the DRAM cache introduces excessive writeback traffic which aggravates capacity misses and DRAM interference. To leverage insertions in terms of writeback or fill requests, we propose a cooperative writeback and insertion policy that adapts to the distinct access patterns of heterogeneous applications based on runtime misses and writeback efficiency, thereby increasing HMIPC (harmonic instruction per cycle) throughput by 22.2%, 13.7% and 14.5% compared to LRU and two static writeback policies.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092380","","Bandwidth;Electronics packaging;Interference;Monitoring;Radiation detectors;Random access memory;Writing","DRAM chips;cache storage;multiprocessing systems","DRAM cache;block replacement policy;cooperative writeback;dynamic writeback;insertion policies;insertion policy;multi-core systems;writeback efficiency","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Analog neuromorphic computing enabled by multi-gate programmable resistive devices","Calayir, V.; Darwish, M.; Weldon, J.; Pileggi, L.","Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","928","931","Analog neural networks represent a massively parallel computing paradigm by mimicking the human brain. Two important functions that are not efficiently built by CMOS technology for their practical hardware implementations are weighting for synapse circuits and summing for neuron circuits. In this paper we propose the use of tunable analog resistances, such as multi-gate graphene devices, to efficiently enable these two functions. We design and demonstrate a complete analog neuromorphic circuitry enabled by such devices. Simulation results based on Verilog-A compact models for graphene devices confirm its functionality. We also provide experimental demonstration of our proposed graphene device along with projected circuit performance based on scaling targets. Our proposed design is suitable not only for the device example shown in this paper, but also for any beyond-CMOS technology that exhibits similar device characteristics.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092521","","Associative memory;Graphene;Integrated circuit modeling;Logic gates;Neuromorphics;Neurons;Resistance","CMOS analogue integrated circuits;brain;electric resistance;graphene devices;hardware description languages;neural nets;parallel processing","CMOS technology;Verilog-A compact model;analog neuromorphic computing;brain;complete analog neuromorphic circuitry;graphene device;massively parallel computing;multigate programmable resistive devices;neuron circuit;synapse circuits;tunable analog resistance","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Spintastic: Spin-based stochastic logic for energy-efficient computing","Venkatesan, R.; Venkataramani, S.; Xuanyao Fong; Roy, K.; Raghunathan, A.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1575","1578","Spintronics is one of the leading technologies under consideration for the post-CMOS era. While spintronic memories have demonstrated great promise due to their density, non-volatility and low leakage, efforts to realize spintronic logic have been much less fruitful. Recent studies project the performance and energy efficiency of spintronic logic to be considerably inferior to CMOS. In this work, we explore Stochastic Computing (SC) as a new direction for the realization of energy-efficient logic using spintronic devices. We establish the synergy between stochastic computing and spintronics by demonstrating that (i) the peripheral circuits required for SC to convert to/from stochastic domains, which incur significant energy overheads in CMOS, can be efficiently realized by exploiting the characteristics of spintronic devices, and (ii) the low logic complexity and finegrained parallelism in SC circuits can be leveraged to alleviate the shortcomings of spintronic logic. We propose Spintastic, a new design approach in which all the components of stochastic circuits - stochastic number generators, stochastic arithmetic units, and stochastic-to-binary converters - are realized using spintronic devices. Our experiments on a range of benchmarks from different application domains demonstrate that Spintastic achieves 2.8X improvement in energy over CMOS stochastic implementations and 1.9X over a CMOS binary baseline.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092642","","CMOS integrated circuits;Energy consumption;Generators;Magnetic switching;Magnetic tunneling;Magnetoelectronics;Stochastic processes","CMOS integrated circuits;magnetoelectronics;power aware computing;stochastic processes","CMOS stochastic implementations;SC circuits;Spintastic;energy-efficient computing;peripheral circuits;spin based stochastic logic;spintronic devices;spintronic logic;spintronic memories;stochastic computing","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Accurate electrothermal modeling of thermoelectric generators","Dousti, M.J.; Petraglia, A.; Pedram, M.","Univ. of Southern California, Los Angeles, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1603","1606","Thermoelectric generators (TEGs) provide a unique way for harvesting thermal energy. These devices are compact, durable, inexpensive, and scalable. Unfortunately, the conversion efficiency of TEGs is low. This requires careful design of energy harvesting systems including the interface circuitry between the TEG module and the load, with the purpose of minimizing power losses. In this paper, it is analytically shown that the traditional approach for estimating the internal resistance of TEGs may result in a significant loss of harvested power. This drawback comes from ignoring the dependence of the electrical behavior of TEGs on their thermal behavior. Accordingly, a systematic method for accurately determining the TEG input resistance is presented. Next, through a case study on automotive TEGs, it is shown that compared to prior art, more than 11% of power losses in the interface circuitry that lies between the TEG and the electrical load can be saved by the proposed modeling technique. In addition, it is demonstrated that the traditional approach would have resulted in a deviation from the target regulated voltage by as much as 59%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092649","","Contacts;Energy harvesting;Generators;Integrated circuit modeling;Temperature;Thermal resistance","electric resistance;energy harvesting;load (electric);losses;thermal analysis;thermoelectric conversion","TEG input resistance;accurate electrothermal modeling;automotive TEG module;conversion efficiency;electrical load behavior;interface circuitry;internal resistance;power losses minimization;systematic method;thermal behavior;thermal energy harvesting;thermoelectric generators;voltage regulation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"An ultra-low power dual-mode ECG monitor for healthcare and wellness","Bortolotti, D.; Mangia, M.; Bartolini, A.; Rovatti, R.; Setti, G.; Benini, L.","DEI, Univ. of Bologna, Bologna, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1611","1616","Technology scaling enables today the design of ultra-low cost wireless body sensor networks for wearable biomedical monitors. These devices, according to the application domain, show greatly varying tradeoffs in terms of energy consumption, resources utilization and reconstructed biosignal quality. To achieve minimal energy operation and extend battery life, several aspects must be considered, ranging from signal processing to the technological layers of the architecture. The recently proposed Rakeness-based Compressed Sensing (CS) expands the standard CS paradigm deploying the localization of input signal energy to further increase data compression without sensible RSNR degradation. This improvement can be used either to optimize the usage of a non volatile memory (NVM) to store in the device a record of the biosignal or to minimize the energy consumption for the transmission of the entire signal as well as some of its features. We specialize the sensing stage to achieve signal qualities suitable for both Healthcare (HC) and Wellness (WN), according to an external input (e.g. the patient). In this paper we envision a dual-operation wearable ECG monitor, considering a multi-core DSP for input biosignal compression and different technologies for either transmission or local storage. The experimental results show the effectiveness of the Rakeness approach (up to ≈ 70% more energy efficient than the baseline) and evaluate the energy gains considering different use case scenarios.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092651","","Biomedical monitoring;Digital signal processing;Electrocardiography;Medical services;Monitoring;Sensors;Standards","body sensor networks;compressed sensing;data compression;electrocardiography;health care;medical signal processing;random-access storage","RSNR degradation;Rakeness approach;Rakeness-based compressed sensing;biosignal quality;data compression;dual-operation wearable ECG monitor;energy consumption;healthcare;multicore DSP;nonvolatile memory;signal processing;ultralow cost wireless body sensor networks;ultralow power dual-mode ECG monitor;wearable biomedical monitors","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"ECRIPSE: An efficient method for calculating RTN-induced failure probability of an SRAM cell","Awano, H.; Hiromoto, M.; Sato, T.","Grad. Sch. of Inf., Kyoto Univ., Kyoto, Japan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","549","554","Failure rate degradation of an SRAM cell due to random telegraph noise (RTN) is calculated for the first time. ECRIPSE, an efficient method for calculating the RTN-induced failure probability of an SRAM cell, has been developed to exhaustively cover a large number of possible bias-voltage combinations on which RTN statistics strongly depend. In order to shorten computational time, the Monte Carlo calculation of a single gate-bias condition is accelerated by incorporating two techniques: 1) construction of an optimal importance sampling using particles that move about the “important” regions in a variability space, and 2) a classifier that quickly judges whether the random samples are in failure regions or not. We show that the proposed method achieves at least 15.6× speed-up over the state-of-the-art method. We then integrate an RTN model to modulate failure probability. In our experiment, RTN worsens failure probability by six times than that calculated without the effect of RTN.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092448","","Logic gates;Monte Carlo methods;Probability;Resource description framework;SRAM cells;Training;Transistors","SRAM chips;importance sampling;probability","ECRIPSE;Monte Carlo calculation;RTN model;RTN statistics;RTN-induced failure probability;SRAM cell;bias-voltage combinations;efficient method;failure rate degradation;gate-bias condition;optimal importance sampling;random telegraph noise","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"ACSEM: Accuracy-configurable fast soft error masking analysis in combinatorial circuits","Kriebel, F.; Rehman, S.; Duo Sun; Aceituno, P.V.; Shafique, M.; Henkel, J.","Dept. of Embedded Syst. (CES), Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","824","829","Small feature sizes and associated low-operating voltages have led to radiation-induced soft errors as a major source of unreliability in modern circuits. As not all errors propagate to the final output of a combinatorial circuit (e.g., because of logical masking effects), an analysis of the error masking characteristics is required to evaluate and enhance the quality of a reliable processor design. State-of-the-art gate-level soft error masking techniques require a significant amount of analysis time due to their inherent nature of parsing and analyzing the complete processor's netlist, which may take up to several days. In this paper, we present a fast and Accuracy-Configurable Soft Error Masking analysis technique (ACSEM) that performs error probability analysis on parts of netlist within the user-provided masking accuracy range. To enable this, we theoretically derive the maximum number of steps in the netlist graph that has to be processed to reach the required masking accuracy level. This significantly reduces the analysis time by orders of magnitude compared to traditional state-of-the art approaches that process all logic gate paths in a given combinatorial circuit.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092499","","Accuracy;Circuit faults;Error probability;Integrated circuit modeling;Logic gates;Reliability","combinational circuits;error statistics;logic gates;radiation hardening (electronics)","ACSEM;accuracy-configurable fast soft error masking analysis;combinatorial circuits;error probability analysis;logic gate;logical masking effects;modern circuits;radiation-induced soft errors;user-provided masking accuracy","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"nCode: Limiting harmful writes to emerging mobile NVRAM through code swapping","Kan Zhong; Duo Liu; Linbo Long; Xiao Zhu; Weichen Liu; Qingfeng Zhuge; Sha, E.H.-M.","Key Lab. of Dependable Service Comput. in Cyber Phys. Soc., Chongqing Univ., Chongqing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1305","1310","Mobile applications are becoming more and more powerful but also dependent on large main memories, which consume a large portion of system energy. Swapping to byte-addressable, non-volatile memory (NVRAM) is a promising solution to this problem. However, most NVRAMs have limited write endurance. To make it practical, the design of an NVRAM based swapping system must also consider endurance. In this paper, we target at prolonging the lifetime of NVRAM based swap area in mobile devices. Different from traditional wisdom, such as wear leveling and hot/cold data identification, we propose to build a system called nCode, which exploits the fact that code pages are easy to identify, read-only, and therefore a perfect candidate for swapping. Utilizing NVRAM's byte-addressability, we support execute-in-place (XIP) of the code pages in the swap area, without copying them back to DRAM based main memory. Experimental results based on the Google Nexus 5 smartphone show that nCode can effectively prolong the lifetime of NVRAM under various workloads.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092594","","Ash;Delays;Google;Nonvolatile memory;Phase change materials;Random access memory;Switches","random-access storage;smart phones","Google Nexus 5 smartphone;XIP;byte-addressability;code pages;code swapping;cold data identification;execute-in-place;hot data identification;mobile NVRAM;mobile devices;nCode;nonvolatile memory;wear leveling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Malleable NoC: Dark silicon inspired adaptable Network-on-Chip","Bokhari, H.; Javaid, H.; Shafique, M.; Henkel, J.; Parameswaran, S.","Sch. of Comput. Sci. & Eng., Univ. of New South Wales, Sydney, NSW, Australia","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1245","1248","Network on Chip (NoC) has been envisioned as a scalable fabric for many core chips. However, NoCs can consume a considerable share of chip power. Moreover, diverse applications are executed in these multicore, where each application imposes a unique load on the NoC. To realise a NoC which is Energy and Delay efficient, we propose combining multiple VF optimized routers for each node (in traditional NoCs, we have only a single router per node) for efficient NoC for Dark Silicon chips. We present a generic NoC with routers designed for different VF levels, which are distributed across the chip. At runtime, depending on application profile, we combine these VF optimized routers to form constantly changing energy efficient NoC fabric. We call our architecture Malleable NoC. In this paper, we describe the architectural details of the proposed architecture and the runtime algorithms required to dynamically adapt the NoC resources. We show that for a variety of multi program benchmarks executing on Malleable NoC, Energy Delay product (EDP) can be reduced by up to 46% for widely differing workloads. We further show the effect on EDP savings for differing amounts of dark silicon area budget.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092580","","Clocks;Multicore processing;Runtime;Silicon;Switches;System-on-chip","network-on-chip","VF levels;VF optimized routers;application profile;chip power;core chips;dark silicon inspired adaptable network-on-chip;delay efficient;energy delay product;energy efficient NoC fabric;malleable NoC","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Identifying redundant inter-cell margins and its application to reducing routing congestion","Woohyun Chung; Seongbo Shim; Youngsoo Shin","Dept. of Electr. Eng., KAIST, Daejeon, South Korea","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1659","1664","A modern standard cell is embedded with extra space, called inter-cell margin, on its left and right ends. Margins are sometimes redundant, and so margins between some cell pairs can be removed for the benefit of area. Lithography simulations on whole layout to identify redundant margins take excessive amount of time, and thus are impractical. We propose to determine in advance the redundancy of margins between each cell pair; a few methods of approximation are introduced to accelerate the process, e.g. grouping cell pairs of similar boundary patterns, refining each group with geometry parameters, etc. Experiments indicate that the redundancy of margin is accurately determined in 93.7% of cell pairs; the remaining 6.3%, which are actually redundant, are declared irredundant by our method, so our method is inaccurate for those cell pairs yet is still safe. We take advantage of redundant margins and address the problem of routing congestion reduction. Placement is locally perturbed to identify more redundant margins; the cells in high congestion region are spread out after the margins in low congestion area are removed. The proposed method was evaluated on a few test circuits using 28-nm technology. The number of routing grids with congestion overflow was reduced by 43% with no impact on total wirelength.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092659","","Layout;Lithography;Metals;Redundancy;Routing;Standards;Wires","lithography;network routing;redundancy","cell pair;congestion overflow;lithography;margin redundancy;modern standard cell;redundant intercell margin identification;routing congestion reduction;routing grid;size 28 nm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"CyberPhysical-System-On-Chip (CPSoC): A self-aware MPSoC paradigm with cross-layer virtual sensing and actuation","Sarma, S.; Dutt, N.; Gupta, P.; Venkatasubramanian, N.; Nicolau, A.","Dept. of Comput. Sci., Univ. of California Irvine, Irvine, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","625","628","Cyber-physical systems (CPSs) are physical and engineered systems whose operations are monitored, coordinated, controlled, and integrated by a computing, control, and communication core. We propose Cyberphysical-System-on-Chip (CPSoC), a new class of sensor and actuator-rich multiprocessor systems-on-chip (MPSoCs), that augment MPSoCs with additional on-chip and cross-layer sensing and actuation capabilities to enable self-awareness within the observe-decide-act (ODA) paradigm. Unlike traditional MPSoC designs, CPSoC differs primarily on the co-design of computing-communication-control (C3) systems that interacts with the physical environment in real-time in order to adapt system behavior so as to dynamically react to environmental changes while achieving overall design goals. We illustrate CPSoC's potential through a virtual sensor network that accurately estimates run-time power for variability affected subsystems using noisy thermal sensors in improving system goals and Quality-of-Service (QoS).","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092464","Adaptive Computing;Cross-Layer Approach;Cyber Physical Systems;CyberPhysical-System-On-Chip (CPSoC);MPSoC;Self-Aware Computing","Computer architecture;Noise measurement;System-on-chip;Temperature measurement;Temperature sensors","multiprocessing systems;quality of service;system-on-chip","C3;CPSoC;ODA;QoS;actuation;actuator-rich multiprocessor systems-on-chip;computing-communication-control systems codesign;cross-layer virtual sensing;cyberphysical-system-on-chip;noisy thermal sensors;observe-decide-act paradigm;quality-of-service;run-time power;self-aware MPSoC paradigm;virtual sensor network","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Retention time measurements and modelling of bit error rates of WIDE I/O DRAM in MPSoCs","Weis, C.; Jung, M.; Ehses, P.; Santos, C.; Vivet, P.; Goossens, S.; Koedam, M.; Wehn, N.","Univ. of Kaiserslautern, Kaiserslautern, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","495","500","DRAM cells use capacitors as volatile and leaky bit storage elements. The time spent without refreshing them is called retention time. It is well known that the retention time depends inverse exponentially on the temperature. In 3D stacking, the challenges of high power densities and thermal dissipation are exacerbated and have a much stronger impact on the retention time of 3D-stacked WIDE I/O DRAMs that are placed on top of an MPSoC. Consequently, it is very important to study the temperature behaviour of WIDE I/O DRAMs. To the best of our knowledge, no investigations based on real measurements were done for stacked DRAM-on-logic devices. In this paper, we first provide detailed measurements on temperature-dependent retention time and bit error rates of WIDE I/O DRAMs. To obtain the correct temperature distribution of the WIDE-I/O DRAM die we use an advanced thermal modelling tool: the DOCEA AceThermalModeler<sup>TM</sup> (ATM). The WIDE I/O DRAM retention times and bit error rates are compared to the behaviour of 2D-DRAM chips (DIMMs) with the help of an advanced FPGA-based test system. We observed data pattern dependencies and variable retention times (VRTs). Second, based on this data, we develop and validate a SystemC-TLM2.0 DRAM bit error rate model. Our proposed DRAM bit error model enables early investigations on the temperature vs. retention time trade-off in future 3D-stacked MPSoCs with WIDE I/O DRAMs in SystemC-TLM2.0 environments.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092439","","Heating;Measurement uncertainty;Random access memory;Semiconductor device measurement;Temperature measurement;Temperature sensors","DRAM chips;capacitors;error statistics;system-on-chip","3D stacking;DRAM cells;DRAM-on-logic devices;FPGA;MPSoC;SystemC-TLM2.0 DRAM bit error rate model;VRT;WIDE I/O DRAM;advanced thermal modelling tool;capacitors;data pattern dependencies;leaky bit storage elements;power densities;retention time measurements;retention time modelling;temperature behaviour;temperature dependent retention time;temperature distribution;thermal dissipation;variable retention times;volatile bit storage elements","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Towards trustable storage using SSDs with proprietary FTL","Cui, Xiaotong; Zou, Minhui; Shi, Liang; Wu, Kaijie","Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, College of Computer Science, Chongqing University, Chongqing, China. 400044","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1213","1216","In recent years we have seen an increasing deployment of flash-based storage, such as SSD, in mission-critical applications due to its fast read/write speed, small form factor, strong shock resistance, and etc. SSDs use a middle layer called flash translation layer (FTL) to maintain the compatibility with the traditional magnetic-based HDDs. Unlike the traditional HDD where the host OS has the knowledge on where and how to access data, SSD uses FTL to translate and implement all operations. Even worse, FTL, which is considered as one of most important intellectual properties of flash-based storage, is often proprietary. This brings up a serious security concern on design trustiness: what if the manufacturer either accidentally or intentionally implements those operations incorrectly or maliciously? In this paper we analyze the possible threats that are brought up by the design trust issues, and propose a simple yet effective countermeasure.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092572","","Ash;Drives;Encryption;Payloads;Radiation detectors;Trojan horses","","","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Exploiting DRAM restore time variations in deep sub-micron scaling","Xianwei Zhang; Youtao Zhang; Childers, B.R.; Jun Yang","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","477","482","Recent studies reveal that one of the major challenges in scaling DRAM in deep sub-micron regime is its significant variations on cell restore time, which affects timing constraints such as write recovery time tWR. Adopting traditional approaches results in either low yield rate or large performance degradation. In this paper, we propose schemes to expose the variations to the architectural level. By constructing memory chunks with different accessing speeds and, in particular, exploiting the performance benefits of fast chunks, a variation-aware memory controller can effectively compensate the performance loss due to relaxed timing constraints. Our experimental results show that, comparing to traditional designs such as row sparing and ECC, the proposed schemes help to improve system performance by up to 10.3% and 12.9%, respectively, for 20nm and 14nm tech nodes on a 4-core multiprocessor system.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092436","","Capacitors;Degradation;Error correction codes;Integrated circuit modeling;Random access memory;Standards;Timing","DRAM chips;microprocessor chips;multiprocessing systems;performance evaluation","4-core multiprocessor system;DRAM restore time variations;ECC;cell restore time;deep submicron scaling;memory chunks;performance degradation;relaxed timing constraints;row sparing;tWR;timing constraints;variation-aware memory controller;write recovery time","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"RNA: A reconfigurable architecture for hardware neural acceleration","Fengbin Tu; Shouyi Yin; Peng Ouyang; Leibo Liu; Shaojun Wei","Tsinghua Nat. Lab. for Inf. Sci. & Technol., Tsinghua Univ., Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","694","700","As the energy problem has become a big concern in digital system design, one promising solution is combining the core processor with a multi-purpose accelerator targeting high performance applications. Many modern applications can be approximated by multi-layer perceptron (MLP) models, with little quality loss. However, many current MLP accelerators have several drawbacks, such as the unbalance of their performance and flexibility. In this paper, we propose a scheduling framework to guide mapping MLPs onto limited hardware resources with high performance. The framework successfully solves the main constraints of hardware neural acceleration. Furthermore, we implement a reconfigurable neural architecture (RNA) based on this framework, whose computing pattern can be reconfigured for different MLP topologies. The RNA achieves comparable performance with application-specific accelerators and greater flexibility than other hardware MLPs.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092477","","Acceleration;Approximation methods;Computer architecture;Hardware;Neurons;Processor scheduling;RNA","multilayer perceptrons;reconfigurable architectures;scheduling","MLP topologies;hardware neural acceleration;multilayer perceptron;reconfigurable neural architecture;scheduling framework","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"[Back matter]","","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1","16","Conference proceedings back matter may contain various advertisements, indexes, and other miscellaneous conference information. This may in some cases also include committee or program information, blank pages, venue maps or other general information relating to the conference that was part of the original conference proceedings.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092670","","","","","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Fault modeling in controllable polarity silicon nanowire circuits","Mohammadi, H.G.; Gaillardon, P.-E.; De Micheli, G.","Integrated Syst. Lab. (LSI), EPFL Lausanne, Lausanne, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","453","458","Controllable polarity silicon nanowire transistors are among the promising candidates to replace current CMOS in the near future owing to their superior electrostatic characteristics and advanced functionalities. From a circuit testing point of view, it is unclear if the current CMOS and Fin-FET fault models are comprehensive enough to model all defects of controllable polarity nanowires. In this paper, we deal with the above problem using inductive fault analysis on three-independent-gate silicon nanowire FETs. Simulations revealed that the current fault models, i.e. stuck-open faults, are insufficient to cover all modes of operation. The newly introduced test algorithm for stuck open can adequately capture the malfunction behavior of controllable polarity logic gates in the presence of nanowire break and bridge on polarity terminals.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092432","","CMOS integrated circuits;Circuit faults;Delays;Integrated circuit modeling;Logic gates;Semiconductor device modeling;Transistors","fault diagnosis;field effect transistors;logic gates;nanowires;semiconductor device models","CMOS fault models;Fin-FET fault models;controllable polarity logic gates;controllable polarity silicon nanowire transistors;electrostatic characteristics;inductive fault analysis;malfunction behavior;nanowire break;nanowire bridge;polarity terminals;stuck-open faults;three-independent-gate silicon nanowire FET","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Energy-aware cooling for hot-water cooled supercomputers","Conficoni, C.; Bartolini, A.; Tilli, A.; Tecchiolli, G.; Benini, L.","DEI, Univ. of Bologna, Bologna, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1353","1358","Hot-water liquid cooling is a key technology in future green supercomputers as it maximizes the cooling efficiency and energy reuse. However the cooling system still is responsible for a significant percentage of modern HPC power consumption. Standard design of liquid-cooling control relies on rules based on worst-case scenarios, or on CFD simulation of portion of the entire system, which cannot account for all the real supercomputer working conditions (workload and ambient temperature). In this work we first introduce an analytical model, based on lumped parameters, which can effectively describe the cooling components and dynamics, and can be used for analysis and control purposes. We then use it to design an energy-optimal control strategy which is capable to minimize the pump and chiller power consumption while, meeting the supercomputer cooling requirements. We validate the method with simulation tests, taking data from a real HPC cooling mechanism, and comparing the results with state-of-the-art commercial cooling system control strategies.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092602","","Coolants;Heating;Optimization;Power demand;Supercomputers;Tin","mainframes;parallel machines;power aware computing","HPC power consumption;chiller power consumption;cooling efficiency;energy aware cooling;energy optimal control strategy;green supercomputers;hot water cooled supercomputers;hot water liquid cooling;pump power consumption","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"OpenMP and timing predictability: A possible union?","Vargas, R.; Quinones, E.; Marongiu, A.","Barcelona Supercomput. Center (BSC), Tech. Univ. of Catalonia (UPC), Barcelona, Spain","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","617","620","Next-generation many-core embedded platforms have the chance of intercepting a converging need for high performance and predictability. Programming methodologies for such platforms will have to promote predictability as a first-class design constraint, along with features for massive parallelism exploitation. OpenMP, increasingly adopted in the embedded systems domain, has recently evolved to deal with the programmability of heterogeneous many-cores, with mature support for fine-grained task parallelism. While tasking is potentially very convenient for coding real-time applications modeled as periodic task graphs, OpenMP adopts an execution model completely agnostic to any timing requirement that the target application may have. In this position paper we reason about the suitability of the current OpenMP v4 specification and execution model to provide timing guarantees in many-cores.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092462","","Estimation;Instruction sets;Processor scheduling;Programming;Real-time systems;Timing","embedded systems;multiprocessing systems;parallel processing","OpenMP;embedded systems domain;fine-grained task parallelism;heterogeneous many-cores;massive parallelism exploitation;next generation many-core embedded platforms;periodic task graphs;possible union;timing predictability","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Low-cost checkpointing in automotive safety-relevant systems","Hernandez, C.; Abella, J.","Barcelona Supercomput. Center (BSC-CNS), Barcelona, Spain","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","91","96","The use of checkpointing and roll-back recovery (CRR) schemes is common practice to increase the likelihood of a task completing with the correct result despite the presence of faults. However, the use of CRR mechanisms is challenging in the severely constrained design space of safety-relevant embedded systems, such as those controlling critical functions in the automotive domain. CRR schemes introduce non-negligible time and memory overheads that may jeopardize the feasibility of their implementation. In this paper we propose a low-cost checkpointing mechanism suitable for safety-relevant embedded systems deploying light-lockstep architectures. The proposed checkpointing mechanism increases the reliability of the system while keeping timing and memory overhead low enough.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092364","","Automotive engineering;Checkpointing;Computer architecture;Registers;Reliability;Software;Timing","automotive engineering;checkpointing;embedded systems;mechanical engineering computing;reliability;safety systems","CRR schemes;automotive safety-relevant systems;checkpointing and roll-back recovery;light-lockstep architectures;reliability;safety-relevant embedded systems","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Retraining-based timing error mitigation for hardware neural networks","Jiacnao Deng; Yuntan Fang; Zidong Du; Ying Wang; Huawei Li; Temam, O.; Ienne, P.; Novo, D.; Xiaowei Li; Yunji Chen; Chengyong Wu","SKL Comput. Archit., Inst. of Comput. Technol., Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","593","596","Recently, neural network (NN) accelerators are gaining popularity as part of future heterogeneous multi-core architectures due to their broad application scope and excellent energy efficiency. Additionally, since neural networks can be retrained, they are inherently resillient to errors and noises. Prior work has utilized the error tolerance feature to design approximate neural network circuits or tolerate logical faults. However, besides high-level faults or noises, timing errors induced by delay faults, process variations, aging, etc. are dominating the reliability of NN accelerator under nanoscale manufacturing process. In this paper, we leverage the error resiliency of neural network to mitigate timing errors in NN accelerators. Specifically, when timing errors significantly affect the output results, we propose to retrain the accelerators to update their weights, thus circumventing critical timing errors. Experimental results show that timing errors in NN accelerators can be well tamed for different applications.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092456","error tolerance;machine learning;neural networks;overclocking;timing errors","Accuracy;Biological neural networks;Delays;Logic gates;Neurons","fault tolerant computing;learning (artificial intelligence);neural nets","NN accelerators;error resiliency;hardware neural networks;retraining-based timing error mitigation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"FPGA accelerated DNA error correction","Ramachandran, A.; Yun Heo; Wen-mei Hwu; Jian Ma; Deming Chen","Dept. of Electr. & Comput. Eng., Univ. of Illinois at Urbana Champaign, Urbana, IL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1371","1376","Correcting errors in DNA sequencing data is an important process that can improve the quality of downstream analysis using the data. Even though many error-correction methods have been proposed for Illumina reads, their throughput is not high enough to process data from large genomes. The current paper describes the first FPGA-based error-correction tool, called FPGA Accelerated DNA Error Correction (FADE), which targets to improve the throughput of DNA error correction for Illumina reads. The base algorithm of FADE is BLESS that is highly accurate but slow. A Bloom filter that is the main data structure of BLESS and BLESS' error correction subroutines for different types of errors have been implemented on a FPGA. We compared our design with the software version of BLESS using DNA sequencing data generated from four genomes and we could achieve up to 43 times speedup for the best case, and 36 times speedup on the average.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092605","Bloom filter;DNA;FPGA;error correction","DNA;Error correction;Field programmable gate arrays;Genomics;Memory management;Sequential analysis;Solids","DNA;biocomputing;data structures;error correction;field programmable gate arrays;genomics","BLESS;DNA sequencing data;FADE;FPGA accelerated DNA error correction;FPGA-based error correction tool;bloom filter;data structure;downstream analysis;error-correction methods;genomes;illumina reads","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Coherent crosstalk noise analyses in ring-based optical interconnects","Duong, L.H.K.; Nikdast, M.; Jiang Xu; Zhehui Wang; Thonnart, Y.; Le Beux, S.; Peng Yang; Xiaowen Wu; Zhifei Wang","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","501","506","Recently, optical interconnects have been proposed for ultra-high bandwidth and low latency inter/intra-chip communication in multiprocessor systems-on-chip (MPSoCs). These optical interconnects employ the microresonators (MRs) to direct/detect the optical signal. However, utilized MRs suffer from intrinsic crosstalk noise and power loss, degrading the network efficiency via the signal-to-noise ratio (SNR). In this paper, both coherent and incoherent crosstalk in wavelength-division multiplexing (WDM) networks are discussed and systematically analyzed. We carefully develop our analytical models at the optical-circuit level, and apply them to two ring-based networks: SUOR and Corona ONoCs. The quantitative results have demonstrated that the architectural design of the ONoCs determines the impact of crosstalk on the SNR. Even though SUOR and Corona are both ring-based ONoCs, the worst-case SNR can be differed up to 50dB. Our analyses of the worst-case SNR can be utilized as a platform to compare the realistic performance among different optical interconnection networks via the degradation of BER and data bandwidth.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092440","","Corona;Crosstalk;Detectors;Optical crosstalk;Optical interconnections;Optical waveguides;Signal to noise ratio","error statistics;integrated circuit noise;microcavities;micromechanical resonators;optical crosstalk;optical interconnections;system-on-chip;wavelength division multiplexing","BER degradation;Corona ONoC;MPSoC;MR;SNR;SUOR;WDM network;bit error rate;coherent crosstalk noise analysis;incoherent crosstalk;interchip communication;intrachip communication;intrinsic crosstalk noise;microresonator;multiprocessor systems-on-chip;optical signal;optical-circuit level;power loss;ring-based optical interconnect;signal-to-noise ratio;ultrahigh bandwidth;wavelength-division multiplexing","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"An energy-efficient non-volatile in-memory accelerator for sparse-representation based face recognition","Yuhao Wang; Hantao Huang; Leibin Ni; Hao Yu; Mei Yan; Chuliang Weng; Wei Yang; Junfeng Zhao","Sch. of Electr. & Electron. Eng., Nanyang Technol. Univ., Singapore, Singapore","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","932","935","Data analytics such as face recognition involves large volume of image data, and hence leads to grand challenge on mobile platform design with strict power requirement. Emerging non-volatile STT-MRAM has the minimum leakage power and comparable speed to SRAM, and hence is considered as a promising candidate for data-oriented mobile computing. However, there exists significantly higher write-energy for STT-MRAM when compared to the SRAM. Based on the use of STT-MRAM, this paper introduces an energy-efficient non-volatile in-memory accelerator for a sparse-representation based face recognition algorithm. We find that by projecting high-dimension image data to much lower dimension, the current scaling for STT-MRAM write operation can be applied aggressively, which leads to significant power reduction yet maintains quality-of-service for face recognition. Specifically, compared to a baseline with SRAM, leakage power and dynamic power are reduced by 91.4% and 79% respectively with only slight compromise on recognition rate.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092522","","Computer architecture;Databases;Face recognition;Feature extraction;Nonvolatile memory;Quality of service;Random access memory","MRAM devices;SRAM chips;energy conservation;face recognition;image representation;power aware computing;quality of service","STT-MRAM write operation;dynamic power;energy-efficient nonvolatile in-memory accelerator;leakage power;power reduction;quality-of-service;sparse-representation based face recognition;spin-toque-transfer magnetic random access memory","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Reverse longstaff-schwartz american option pricing on hybrid CPU/FPGA systems","Brugger, C.; Varela, J.A.; Wehn, N.; Songyin Tang; Korn, R.","Microelectron. Syst. Design Res. Group, Univ. of Kaiserslautern, Kaiserslautern, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1599","1602","In today's markets, high-speed and energy-efficient computations are mandatory in the financial and insurance industry. At the same time, the gradual convergence of highperformance computing with embedded systems is having a huge impact on the design methodologies, where dedicated accelerators are implemented to increase performance and energy efficiency. This paper follows this trend and presents a novel way to price high-dimensional American options using techniques of the embedded community. The proposed architecture targets heterogeneous CPU/FPGA systems, and it exploits the FPGA reconfiguration to deliver high-throughput. With a bit-true algorithmic transformation based on recomputation, it is possible to eliminate the memory bottleneck and access costs. The result is a pricing system that is 16x faster and 268x more energy-efficient than an optimized Intel CPU implementation.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092648","","Bandwidth;Biological system modeling;Computational modeling;Computer architecture;Energy consumption;Field programmable gate arrays;Pricing","field programmable gate arrays;microprocessor chips;performance evaluation;power aware computing","FPGA reconfiguration;access costs;bit true algorithmic transformation;dedicated accelerators;embedded community;embedded systems;energy efficiency;energy efficient computations;financial industry;highperformance computing;hybrid CPU-FPGA systems;insurance industry;memory bottleneck;optimized Intel CPU implementation;performance efficiency;price high dimensional American options;reverse longstaff-schwartz American option pricing","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Hybrid adaptive clock management for FPGA processor acceleration","Gheolbanoiu, A.; Petrica, L.; Cotofana, S.","Univ. Politeh. of Bucharest, Bucharest, Romania","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1359","1364","As FPGAs speed, power efficiency, and logic capacity are increasing, so does the number of applications which make use of FPGA processors. However, due to placement and routing constraints, FPGA processors instruction delay balancing is a real challenge, especially when the implementation approaches the FPGA resource capacity. Consequently, even though some instructions can operate at high frequencies, the slow instructions determine the processor clock period, resulting in the underutil-isation of the processor potential. However, the fast instructions latent performance may be harnessed through Adaptive Clock Management (ACM), i.e., by dynamically adapting the clock frequency such that each instruction gets sufficient time for correct completion. Up to date, ACM augmented FPGA processors have been proposed based on Clock Multiplexing (CM), but they suffer from long clock switching delays, which could nullify most of the ACM potential performance gain. This paper proposes an effective FPGA tailored clock manipulation approach able to leverage the ACM potential. We first evaluate Clock Stretching (CS), i.e., the temporary clock period augmentation, as a CM alternative in FPGA processor designs and introduce an FPGA specific CS circuit implementation. Subsequently, we evaluate the advantages and drawbacks of the two techniques and propose a Hybrid ACM, which monitors the processor instruction stream and determines the optimal adaptive clocking strategy in order to provide the maximum speedup for the executing program. Given that CS has very low latency at the expense of limited accuracy and dynamic range we rely on it when the program requires frequent clock period changes. Otherwise we utilise CM, which is rather slow but enables the FPGA processor operation at the edge of its hardware capabilities. We evaluate our proposal on a vector processor mapped on a Xilinx Zynq FPGA. Our experiments indicate that on Sum of Squared Differences algorithm, Neural network, and - IR filter execution traces the hybrid ACM provides up to 14% performance increase over the CM based ACM.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092603","","Clocks;Delays;Field programmable gate arrays;Multiplexing;Pipelines;Switches;Table lookup","clocks;field programmable gate arrays;multiplexing","ACM;CM;CS circuit;FIR filter;FPGA processor acceleration;FPGA resource capacity;FPGA tailored clock manipulation approach;Xilinx Zynq FPGA;clock frequency;clock multiplexing;clock stretching;clock switching delay;field programmable gate array;finite impulse response filter;hybrid adaptive clock management;instruction delay balancing;neural network;optimal adaptive clocking strategy;processor clock period;sum of squared differences algorithm;temporary clock period augmentation;vector processor","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Transparent offloading of computational hotspots from binary code to Xeon Phi","Damschen, M.; Riebler, H.; Vaz, G.; Plessl, C.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1078","1083","In this paper, we study how binary applications can be transparently accelerated with novel heterogeneous computing resources without requiring any manual porting or developer-provided hints. Our work is based on Binary Acceleration At Runtime (BAAR), our previously introduced binary acceleration mechanism that uses the LLVM Compiler Infrastructure. BAAR is designed as a client-server architecture. The client runs the program to be accelerated in an environment, which allows program analysis and profiling and identifies and extracts suitable program parts to be off-loaded. The server compiles and optimizes these off-loaded program parts for the accelerator and offers access to these functions to the client with a remote procedure call (RPC) interface. Our previous work proved the feasibility of our approach, but also showed that communication time and overheads limit the granularity of functions that can be meaningfully off-loaded. In this work, we motivate the importance of a lightweight, high-performance communication between server and client and present a communication mechanism based on the Message Passing Interface (MPI). We evaluate our approach by using an Intel Xeon Phi 5110P as the acceleration target and show that the communication overhead can be reduced from 40% to 10%, thus enabling even small hotspots to benefit from off-loading to an accelerator.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092549","","Acceleration;Computer architecture;IP networks;Optimization;Runtime;Servers;Software","binary codes;client-server systems;graphics processing units;message passing;optimising compilers;program diagnostics;remote procedure calls","BAAR;Intel Xeon Phi 5110P;MPI;RPC interface;Xeon Phi;accelerator;binary acceleration at runtime;binary code;client-server architecture;high-performance communication;message passing interface;off-loaded program compilation;off-loaded program optimization;program analysis;program profiling;remote procedure call;transparent computational hotspot off-loading","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"AHEAD: Automated framework for hardware accelerated iterative data analysis","Songhori, E.M.; Mirhoseini, A.; Xuyang Lu; Koushanfar, F.","Rice Univ., Houston, TX, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","942","947","This paper introduces AHEAD, a novel domain-specific framework for automated (hardware-based) acceleration of massive data analysis applications with a dense (non-sparse) correlation matrix. Due to non-scalability of matrix inversion, often iterative computation is used for converging to a solution. AHEAD addresses two sets of domain-specific matrix computation challenges. First, the I/O and memory bandwidth constraints which limit the performance of hardware accelerators. Second, the hardness of handling large data because of the complexity of the known matrix transformations and the inseparability of non-sparse correlations. The inseparability problem translates to an increased communication cost with the accelerators. To optimize the performance within these limits, AHEAD learns the dependency structure of the domain data and suggests a scalable matrix transformation. The transformation minimizes the memory access required for matrix computing within an error threshold and thus, optimizes the mapping of domain data to the available (bandwidth constrained) accelerator resources. To facilitate automation, AHEAD also provides an Application Programming Interface (API) so users can customize the framework to an arbitrary iterative analysis algorithm and hardware mapping. Proof-of-concept implementation of AHEAD is performed on the widely used compressive sensing and general ℓ<sub>1</sub> regularized least squares solvers. On a massive light field imaging data set with 4.6B non-zeros, AHEAD attains up to 320x iteration speed improvement using reconfigurable hardware accelerators compared with the conventional solver and about 4x improvement compared to our transformed matrix solver on a general purpose processor (without hardware acceleration).","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092524","API;Dense Matrix;FISTA;FP-GAs;Gram Matrix;HLS;Iterative Solver;Least Squares;Sparse Approximation","Acceleration;Hardware;Kernel;Least squares approximations;Matrix decomposition;Sparse matrices","application program interfaces;computational complexity;data analysis;field programmable gate arrays;iterative methods;least squares approximations;matrix algebra","AHEAD;API;application programming interface;arbitrary iterative analysis algorithm;automated framework;dense correlation matrix;hardware accelerated iterative data analysis;hardware mapping;iterative computation;matrix computing;matrix inversion;reconfigurable hardware accelerators;regularized least squares solvers;scalable matrix transformation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Customization of OpenCL applications for efficient task mapping under heterogeneous platform constraints","Paone, E.; Robino, F.; Palermo, G.; Zaccaria, V.; Sander, I.; Silvano, C.","Politec. di Milano, Milan, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","736","741","When targeting an OpenCL application to platforms with multiple heterogeneous accelerators, task tuning and mapping have to cope with device-specific constraints. To address this problem, we present an innovative design flow for the customization and performance optimization of OpenCL applications on heterogeneous parallel platforms. It consists of two phases: 1) a tuning phase that optimizes each application kernel for a given platform and 2) a task-mapping phase that maximizes the overall application throughput by exploiting concurrency in the application task graph. The tuning phase is suitable for customizing parameterized OpenCL kernels considering device-specific constraints. Then, the mapping phase improves task-level parallelism for multi-device execution accounting for the overhead of memory transfers - overheads implied by multiple OpenCL contexts for different device vendors. Benefits of the proposed design flow have been assessed on a stereo-matching application targeting two commercial heterogeneous platforms.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092484","","Context;Graphics processing units;Kernel;Optimization;Programming;Throughput;Tuning","graphics processing units;optimisation;parallel processing;task analysis","application kernel optimization;application task graph;device specific constraint;efficient task mapping;heterogeneous accelerator;heterogeneous parallel platform constraint;memory transfer overhead;multidevice execution;parameterized OpenCL kernel customization;performance optimization;stereomatching application;task level parallelism;task tuning","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"STT MRAM-based PUFs","Vatajelu, E.I.; Di Natale, G.; Indaco, M.; Prinetto, P.","Dip. di Autom. e Inf., Politec. di Torino, Turin, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","872","875","Physical Unclonable Functions are emerging cryptographic primitives used to implement low-cost device authentication and secure secret key generation. In this paper we propose an innovative design based on STT-MRAM memory. We exploit the high variability affecting the electrical resistance of the MTJ device in anti-parallel magnetization. We will show that the proposed solution is robust, unclonable and unpredictable.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092507","Emerging Memory Technology;MRAMs;Physical Unclonable Functions PUFs;Security","Arrays;Hamming distance;Magnetic tunneling;Magnetization;Resistance;Robustness;Sensors","MRAM devices;magnetic tunnelling","MRAM memory;MTJ device;PUF;STT;anti-parallel magnetization;cryptographic primitives;device authentication;electrical resistance;physical unclonable functions;secret key generation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Inductor optimization for active cell balancing using geometric programming","Kauer, M.; Narayanaswami, S.; Lukasiewycz, M.; Steinhorst, S.; Chakraborty, S.","TUM CREATE, Singapore, Singapore","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","281","284","This paper proposes an optimization methodology for inductor components in active cell balancing architectures of electric vehicle battery packs. For this purpose, we introduce a new mathematical model to quantitatively describe the charge transfer of a family of inductor-based circuits. Utilizing worst case assumptions, this model yields a nonlinear program for designing the inductor and selecting the transfer current. In the next step, we transform this problem into a geometric program that can be efficiently solved. The optimized inductor reduces energy dissipation by at least 20% in various scenarios compared to a previous approach which selected an optimal off-the-shelf inductor.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092397","","Charge transfer;Computer architecture;Inductors;Mathematical model;Microprocessors;Optimization;Pulse width modulation","electric vehicles;geometric programming;inductors;secondary cells","active cell balancing architectures;electric vehicle battery packs;energy dissipation;geometric programming;inductor components;inductor optimization;inductor-based circuits;nonlinear program;optimal off-the-shelf inductor;optimization methodology;transfer current;worst case assumptions","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Logical equivalence checking of asynchronous circuits using commercial tools","Saifhashemi, A.; Hsin-Ho Huang; Bhalerao, P.; Beerel, P.A.","Intel Corp., Santa Clara, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1563","1566","We propose a method for logical equivalence check (LEC) of asynchronous circuits using commercial synchronous tools. In particular, we verify the equivalence of asynchronous circuits which are modeled at the CSP-level in SystemVerilog as well as circuits modeled at the micro-architectural level using conditional communication library primitives. Our approach is based on a novel three-valued logic model that abstracts the detailed handshaking protocol and is thus agnostic to different gate-level implementations, making it applicable to a variety of different design styles. Our experimental results with commercial LEC tools on a variety of computational blocks and an asynchronous microprocessor demonstrate the applicability and limitations of the proposed approach.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092639","","Asynchronous circuits;Electronic mail;Integrated circuit modeling;Libraries;Logic gates;Optimization;Static VAr compensators","asynchronous circuits;computer architecture;hardware description languages;microprocessor chips","CSP-level;LEC;LEC tools;SystemVerilog;asynchronous circuits;asynchronous microprocessor;commercial synchronous tools;commercial tools;computational blocks;conditional communication library primitives;gate-level implementations;logical equivalence checking;microarchitectural level;three-valued logic model","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"NoC-enabled multicore architectures for stochastic analysis of biomolecular reactions","Majumder, T.; Xian Li; Bogdan, P.; Pande, P.","Dept. of Electr. Eng., Indian Inst. of Technol. Delhi, New Delhi, India","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1102","1107","Recent medical challenges such as cancer, drug-resistant microbes or diabetes crucially affect human health. To tackle these, modern medicine must analyze molecular interactions and rely on powerful computational platforms for the design and performance evaluation of medical therapies. Towards this end, we propose a Network-on-Chip (NoC)-based multicore platform enabling the efficient analysis of stochastic molecular interactions among biological entities. Our in-depth analysis of the stochastic interactions among biological components and the characterization of their computational and communication requirements allows us to design a high-performance NoC architecture sustaining a throughput of over 1.36E5 events/ms, while consuming only 15 mJ per 1E5 stochastic events. Our proposed NoC-based multicore can offer a throughput improvement of 23% over a regular mesh-based NoC, while consuming 20% less energy.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092553","Network-on-Chip;cyber-physical system;gene therapy;multicore;personalized medicine;stochastic simulation","Biological system modeling;Computational modeling;Gene therapy;Mathematical model;Multicore processing;Stochastic processes;Wireless communication","biomedical electronics;network-on-chip","NoC-enabled multicore architecture;biological component;biomolecular reaction;cancer;diabetes;drug-resistant microbe;in-depth analysis;medical therapy;network-on-chip;performance evaluation;stochastic analysis;stochastic molecular interaction","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Monolithic 3D integration: A path from concept to reality","Shulaker, M.M.; Wu, T.F.; Sabry, M.M.; Hai Wei; Wong, H.-S.P.; Mitra, S.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1197","1202","Monolithic three-dimensional (3D) integration enables revolutionary digital system architectures of computation immersed in memory. Vertically-stacked layers of logic circuits and memories, with nano-scale inter-layer vias (with the same pitch and dimensions as tight-pitched metal layer vias), provide massive connectivity between the layers. The nano-scale inter-layer vias are orders of magnitude denser than conventional through silicon vias (TSVs). Such digital system architectures can achieve significant performance and energy efficiency benefits compared to today's designs. The massive vertical connectivity makes such architectures particularly attractive for abundant-data applications that impose stringent requirements with respect to low-latency data processing, high-bandwidth data transfer, and energy-efficient storage of massive amounts of data. We present an overview of our progress toward realizing monolithic 3D ICs, enabled by recent advances in emerging nanotechnologies such as carbon nanotube field-effect transistors and emerging memory technologies such as Resistive RAMs and Spin-Transfer Torque RAMs.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092569","","CMOS integrated circuits;CNTFETs;Energy efficiency;Logic gates;Silicon;Three-dimensional displays","energy conservation;logic circuits;monolithic integrated circuits;nanotechnology;three-dimensional integrated circuits","TSV;abundant-data applications;carbon nanotube field-effect transistors;energy-efficient storage;high-bandwidth data transfer;logic circuits;logic memory;low-latency data processing;magnitude denser;massive vertical connectivity;monolithic 3D IC integration;monolithic three-dimensional integration;nanoscale interlayer vias;nanotechnology;resistive RAM;revolutionary digital system architectures;spin-transfer torque RAM;stringent requirements;through-silicon-vias;tight-pitched metal layer vias;vertically-stacked layers","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Thermal-aware floorplanning for partially-reconfigurable FPGA-based systems","Pagano, D.; Vuka, M.; Rabozzi, M.; Cattaneo, R.; Sciuto, D.; Santambrogio, M.D.","Politec. di Milano, Milan, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","920","923","Field Programmable Gate Arrays (FPGAs) systems are being more and more frequent in high performance applications. Temperature affects both reliability and performance, therefore its optimization has become challenging for system designers. In this work we present a novel thermal aware floorplanner based on both Simulated Annealing (SA) and Mixed-Integer Linear Programming (MILP). The proposed method takes into account an accurate description of heterogeneous resources and partially reconfigurable constraints of recent FPGAs. Our major contribution is to provide a high level formulation for the problem, without resorting to low level consideration about FPGAs resources. Within our approach we combine the benefits of SA and MILP to handle both linear and non-linear optimization metrics while providing an effective exploration of the solution space. Experimental results show that, for several designs, it is possible to reduce the peak temperature by taking into account power consumption during the floorplanning stage.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092519","","Field programmable gate arrays;Linear programming;Mathematical model;Optimization;Power demand;Thermal resistance;Wires","field programmable gate arrays;integer programming;integrated circuit layout;integrated circuit packaging;integrated logic circuits;linear programming;simulated annealing;thermal management (packaging)","field programmable gate arrays;heterogeneous resource;mixed integer-linear programming;partially reconfigurable FPGA;partially reconfigurable constraints;power consumption;simulated annealing;thermal aware floorplanning","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A unified hardware/software MPSoC system construction and run-time framework","Skalicky, S.; Schmidt, A.G.; Lopez, S.; French, M.","Dept. of Comput. Eng., Rochester Inst. of Technol., Rochester, NY, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","301","304","With the continual enhancement of heterogeneous resources in FPGA devices, utilizing these resources becomes a challenging burden for developers. Especially with the inclusion of sophisticated multiple processor system-on-chips, the necessary skill set to effectively leverage these resources spans both hardware and software expertise. The maturation of high level synthesis tools and programming languages aim to alleviate these complexities, yet there still exist systematic gaps that must be bridged to provide a more cohesive hardware/software development environment. High level MPSoC design initiatives such as Redsharc have reduced the costs of entry, simplifying application implementation. We propose a unified hardware/software framework for system construction, leveraging Redsharc's APIs, efficient on-chip interconnects, and run-time controllers. We present system level abstractions that enable compilation and implementation tools for hardware and software to be merged into a single configurable system development environment. Finally, we demonstrate our proposed framework with Redsharc, using AES encryption/decryption spanning software implementations on ARM and MicroBlaze processors and hardware kernels.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092402","","Encryption;Field programmable gate arrays;Hardware;Kernel;Process control;System-on-chip","field programmable gate arrays;high level synthesis;integrated circuit interconnections;microprocessor chips;programming languages;system-on-chip","ARM processors;FPGA devices;MPSoC system construction;MicroBlaze processors;Redsharc;hardware kernels;heterogeneous resources;high level synthesis tools;multiple processor system-on-chips;on-chip interconnects;programming languages;run-time controllers;run-time framework;system level abstractions;systematic gaps","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"High-resolution online power monitoring for modern microprocessors","Oboril, F.; Ewert, J.; Tahoori, M.B.","Dept. of Dependable Nano Comput., Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","265","268","The power consumption of computing systems is nowadays a major design constraint that affects performance and reliability. To co-optimize these aspects, fine-grained adaptation techniques at runtime are of growing importance. However, to use these tools efficiently, fine-grained information about the power consumption of various on-chip components at runtime is required. Therefore, here we propose a novel software-implemented high-resolution (spatial and temporal) power monitoring approach that relies on micro-models to estimate the power consumption of all microarchitectural components inside a processor core. Combined with a self-calibration technique that uses an available on-chip power sensor, our power estimation approach can achieve an accuracy of more than 99 % and provides deep insights about the power dissipation inside a processor core during workload execution.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092393","","Estimation;Microarchitecture;Monitoring;Power demand;Runtime;Spatial resolution;System-on-chip","calibration;microprocessor chips;power aware computing","fine-grained adaptation technique;high-resolution online power monitoring;modern microprocessors;on-chip power sensor;power dissipation;processor core;self-calibration technique;software-implemented high-resolution power monitoring approach","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Engine control: Task modeling and analysis","Biondi, A.; Buttazzo, G.","Scuola Superiore Sant'Anna, Pisa, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","525","530","Engine control is characterized by computational activities that are triggered by specific crankshaft rotation angles and are designed to adapt their functionality based on the angular velocity of the engine. Although a few models have been proposed in the literature to handle such tasks, most of them are quite simplistic and do not allow expressing features that are presently used by the automotive industry. This paper proposes a new task model for expressing realistic features of engine control tasks and presents a sufficient real-time analysis for applications consisting of multiple engine control tasks and classical periodic/sporadic tasks scheduled by EDF.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092444","","Acceleration;Adaptation models;Analytical models;Computational modeling;Engines;Hysteresis;Switches","automotive components;control system analysis;internal combustion engines;scheduling","EDF scheduling;automotive industry;classical periodic-sporadic tasks;earliest deadline first;engine control;real-time analysis","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"GALS synthesis and verification for xMAS models","Burns, F.; Sokolov, D.; Yakovlev, A.","Sch. of Comput. Sci., Newcastle Univ., Newcastle upon Tyne, UK","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1419","1424","In this paper a novel Globally Asynchronous Locally Synchronous (GALS) synthesis and verification environment is introduced for xMAS models. xMAS models are a new communication paradigm which can be used to model circuits and networks for the purpose of synthesis, testing and verification. Previous attempts at synthesis and verification of xMAS models have been proposed for synchronous implementations only. This paper provides an extension of xMAS and translation into Circuit Petri net models for GALS synthesis and verification. Synthesis techniques based on Circuit Petri net translation are presented and a new xMAS component is introduced which acts as a wrapper for different GALS styles. Novel verification techniques using unfolding to occurrence nets are then proposed. Our results show that the work presented here provides a suitable platform for integrating xMAS into a GALS environment.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092613","","Integrated circuit modeling;Mathematical model;Petri nets;Semantics;Switches;Synchronization;System recovery","Petri nets;formal verification;parallel processing;programming languages","GALS synthesis;GALS verification;circuit Petri net models;communication paradigm;computer programming language;globally asynchronous locally synchronous;parallel computing;synchronous implementations;verification environment;xMAS models","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"An effective triple patterning aware grid-based detailed routing approach","Zhiqing Liu; Chuangwen Liu; Young, E.F.Y.","Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Hong Kong, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1641","1646","Triple patterning lithography (TPL) is attracting more and more attention due to further scaling of the critical feature size. How fully the benefits of TPL can be utilized depends very much on both the decomposition and layout steps. However, it is non-trivial to perform detailed routing and layout decomposition simultaneously on a large-scale complicated circuit to achieve decomposability on one hand, and short wirelength, small number of stitches and small number of vias on the other hand. In our approach, routing and coloring are done iteratively but integrated closely to reduce the problem complexity. The routing step is able to detect and avoid native conflicts as much as possible. If any conflicts occur in the coloring step, the router will rip-up and re-route to get rid of them. This technique proves to be effective and efficient in improving the quality of the coloring assignment. Compared with previous works [1] on TPL using simultaneous routing and coloring, the number of stitches and the number of vias are reduced by 76.8% and 2.1% respectively while our running time is 36.6% less and the wirelength is very comparable.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092656","","Color;History;Image color analysis;Layout;Pins;Routing;Wires","integrated circuit layout;lithography;vias","large-scale complicated circuit;triple patterning aware grid-based detailed routing;triple patterning lithography;vias","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Simultaneous transistor pairing and placement for CMOS standard cells","Ang Lu; Hsueh-Ju Lu; En-Jang Jang; Yu-Po Lin; Chun-Hsiang Hung; Chun-Chih Chuang; Rung-Bin Lin","Comput. Sci. & Eng., Yuan Ze Univ., Chungli, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1647","1652","This paper presents an integer linear programming approach to transistor placement problem for CMOS standard cells with objectives of minimizing cell width, wiring density, wiring length, diffusion contour roughness, and misalignments of common ploy gates. Our approach considers transistor pairing and transistor placement simultaneously. It can achieve a smaller number of transistor chains than the well-known bipartite approach. About 31% of the 185 cells created by it have smaller widths and no cells whose widths are larger than their handcrafted counterparts.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092657","Transistor placement;standard cell;transistor folding;transistor pairing","Layout;Logic gates;Runtime;Standards;Transistors;Wires;Wiring","CMOS integrated circuits;integer programming;linear programming;transistor circuits","CMOS standard cells;bipartite approach;common ploy gates misalignments;diffusion contour roughness;integer linear programming;transistor pairing;transistor placement;wiring density;wiring length","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Improving MPSoC reliability through adapting runtime task schedule based on time-correlated fault behavior","Rozo Duque, L.A.; Monsalve Diaz, J.M.; Chengmo Yang","Electr. & Comput. Eng., Univ. of Delaware, Newark, DE, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","818","823","The increasing susceptibility of multicore systems to temperature variations, environmental issues and different aging effects has made system reliability a crucial concern. Unpredictability of all these factors makes fault behavior diverse in nature, which should be considered by the runtime task scheduler to improve overall system reliability. To achieve this goal, this paper proposes a fault tolerant approach to model core reliability at runtime and tune resource allocation accordingly. Given variations in fault duration, we propose a reliability model capable of tracking not only faults appeared in each core but also their correlation in time. Taking this model as an input, a runtime scheduling algorithm that allocates critical and vulnerable tasks to reliable cores is also proposed. Experimental results show that the proposed adaptive technique delivers up to 56% improvement in application execution time compared to other techniques.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092498","","Adaptation models;Fault tolerance;Fault tolerant systems;Resource management;Runtime;Schedules","fault tolerance;integrated circuit reliability;multiprocessing systems;resource allocation;scheduling;system-on-chip","MPSoC reliability;aging effects;environmental issues;fault duration;fault tolerant approach;multicore systems;resource allocation;runtime scheduling algorithm;runtime task schedule;temperature variations;time-correlated fault behavior","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Transparent linking of compiled software and synthesized hardware","Thomas, D.B.; Fleming, S.T.; Constantinides, G.A.; Ghica, D.R.","Dept. of Electr. & Electron. Eng., Imperial Coll. London, London, UK","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1084","1089","Modern heterogeneous devices contain tightly coupled CPU and FPGA logic, allowing low latency access to accelerators. However, designers of the system need to treat accelerated functions specially, with device specific code for instantiating, configuring, and executing accelerators. We present a system level linker, which allows functions in hardware and software to be linked together to create heterogeneous systems. The linker works with post-compilation and post-synthesis components, allowing the designer to transparently move functions between devices simply by linking in either hardware or software object files. The linker places no special emphasis on the software, allowing computation to be initiated from within hardware, with function calls to software to provide services such as file access. A strong type-system ensures that individual code artifacts can be written using the conventions of that domain (C, HLS, VHDL), while allowing direct and transparent linking.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092550","","Field programmable gate arrays;Hardware;IP networks;Joining processes;Protocols;Servers;Software","field programmable gate arrays;high level synthesis","FPGA logic;accelerators;compiled software;coupled CPU;device specific code;file access;heterogeneous systems;low latency access;modern heterogeneous devices;post-compilation;post-synthesis components;software object files;strong type-system;synthesized hardware;system level linker;transparent linking","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Worst-case communication time analysis of networks-on-chip with shared virtual channels","Rambo, E.A.; Ernst, R.","Inst. of Comput. & Network Eng., Tech. Univ. Braunschweig, Braunschweig, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","537","542","Network-on-Chip (NoC) based multi- and many-core architectures show high potential for use in real-time applications due to their superior efficiency. In real-time systems, it is necessary to guarantee that the application's timing requirements are met through the analysis of the worst-case behavior. A typical approach to guarantee real-time is the exclusive assignment of virtual channels to tasks or cores. Virtual channels, however, are a limited resource in NoCs. In future systems, there will be more tasks than virtual channels (VCs) in the network. In this paper, we propose a worst-case communication analysis of wormhole-switched best-effort NoCs (no special QoS mechanism) with SLIP arbitration and support to shared VCs. The approach is based on Compositional Performance Analysis, which enables non-symmetrical guarantees for the streams. The analysis is evaluated experimentally and compared with simulation and related work.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092446","","Analytical models;Interference;Ports (Computers);Real-time systems;Round robin;Switches;Time factors","multiprocessing systems;multiprocessor interconnection networks;network-on-chip;real-time systems;timing","NoC based many-core architectures;SLIP arbitration;compositional performance analysis;network-on-chip based multi-core architectures;nonsymmetrical guarantees;real-time systems;timing requirements;virtual channels;wormhole-switched best-effort NoC;worst-case communication analysis","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Comparison of multi-purpose cores of Keccak and AES","Yalla, P.; Homsirikamol, E.; Kaps, J.-P.","Dept. of Electr. & Comput. Eng., George Mason Univ., Fairfax, VA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","585","588","Most widely used security protocols, Internet Protocol Security (IPSec), Secure Socket Layer (SSL), and Transport Layer Security (TLS), provide several cryptographic services which in turn require multiple dedicated cryptographic algorithms. A single cryptographic primitive for all secret key functions utilizing different mode of operations can overcome this constraint. This paper investigates the possibility of using AES and Keccak as the underlying primitives for high-speed and resource constrained applications. Even though a plain AES implementation is typically much smaller and has a better throughput to area ratio than a plain Keccak, adding additional cryptographic services changes the results dramatically. Our multi-purpose Keccak outperforms our multi-purpose AES by a factor of 4 for throughput over area on average. This underlines the flexibility of the Keccak Sponge and Duplex functions. Our multi-purpose Keccak achieves a throughput of 23.2 Gbps in AE-mode (Keyak) on a Xilinx Virtex-7 and 28.7 Gbps on a Altera Stratix-IV. In order to study this further we also implemented two versions of a dedicated Keyak and dedicated AES-GCM. Our dedicated Keyak implementation outperforms our dedicated AES-GCM on average by a factor 6 in terms of throughput over area reaching a throughput of 28.9 Gbps and 4.1 Gbps respectively on a Xilinx Virtex-7.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092454","","Authentication;Clocks;Encryption;Random access memory;Throughput","cryptography;field programmable gate arrays","AE-mode;AES-GCM;Altera Stratix-IV;Keccak duplex functions;Keccak sponge functions;Xilinx Virtex-7;cryptographic services;multipurpose cores","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Extrax: Security extension to extract cache resident information for snoop-based external monitors","Jinyong Lee; Yongje Lee; Hyungon Moon; Ingoo Heo; Yunheung Paek","Dept. of Electr. & Comput. Eng., Seoul Nat. Univ., Seoul, South Korea","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","151","156","Advent of rootkits has urged researchers to conduct much research on defending the integrity of OS kernels. Even though recently proposed snoop-based monitors have shown to provide higher performance and security level compared to conventional hypervisor-based monitors, we discovered that the use of write-back caches in a system would seriously undermine the effectiveness of snoop-based monitors. To address the problem, we propose a special hardware unit called Extrax which makes use of existing hardware logic, core debugging interface, to extract necessary information for security monitoring. Being implemented to refine the debug information for security purposes, Extrax assists snoop-based monitors to detect attacks that exploit write-back caches. Experimental results show that our system can detect more advanced attacks, which the state-of-the-art snoop-based hardware monitors cannot capture, with moderate area overhead and power consumption.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092374","","Data structures;Hardware;Kernel;Monitoring;Program processors;Registers;Security","cache storage;operating system kernels;security of data","Extrax;OS kernels;cache resident information;core debugging interface;hardware logic;hardware unit;hypervisor-based monitors;snoop-based external monitors;write-back caches","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"An approximate voting scheme for reliable computing","Ke Chen; Lombardi, F.; Jie Han","Electr. & Comput. Eng., Northeastern Univ., Boston, MA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","293","296","This paper relies on the principles of inexact computing to alleviate the issues arising in static masking by voting for reliable computing. A scheme that utilizes approximate voting is proposed; it is referred to as inexact double modular redundancy (IDMR). IDMR does not resort to triplication, thus saving overhead due to modular replication; moreover, this scheme is adaptive in its operation, i.e., it allows a threshold to determine the validity of the module outputs. IDMR operates by initially establishing the difference between the values of the outputs of the two modules; only if the difference is below a preset threshold, then the voter calculates the average value of the two module outputs. An extensive analysis of the voting circuits and an application to image processing are presented.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092400","Approximate computing;Modular Redundancy;Reliable system;Voting","Complexity theory;Delays;PSNR;Redundancy;Tunneling magnetoresistance","image processing;reliability","IDMR;approximate voting scheme;image processing;inexact computing;inexact double modular redundancy;modular replication;module outputs;reliable computing;static masking;voting circuits","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Hardware-assisted code obfuscation for FPGA soft microprocessors","Kainth, M.; Krishnan, L.; Narayana, C.; Virupaksha, S.G.; Tessier, R.","Dept. of Electr. & Comput. Eng., Univ. of Massachusetts, Amherst, MA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","127","132","Soft microprocessors are vital components of many embedded FPGA systems. As the application domain for FPGAs expands, the security of the software used by soft processors increases in importance. Although software confidentiality approaches (e.g. encryption) are effective, code obfuscation is known to be an effective enhancement that further deters code understanding for attackers. The availability of specialization in FPGAs provides a unique opportunity for code obfuscation on a per-application basis with minimal hardware overhead. In this paper we describe a new technique to obfuscate soft microprocessor code which is located outside the FPGA chip in an unprotected area. Our approach provides customizable, data-dependent control flow modification to make it difficult for attackers to easily understand program behavior. The application of the approach to three benchmarks illustrates a control flow cyclomatic complexity increase of about 7× with a modest logic overhead for the soft processor.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092370","Soft microprocessor;code obfuscation","Complexity theory;Encryption;Field programmable gate arrays;Hardware;Software;Switches;Table lookup","encoding;field programmable gate arrays;hardware-software codesign;microprocessor chips;security of data","FPGA soft microprocessors;data dependent control flow modification;hardware assisted code obfuscation;many embedded FPGA system;minimal hardware overhead;software confidentiality;software security","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Interplay of loop unrolling and multidimensional memory partitioning in HLS","Cilardo, A.; Gallo, L.","Dept. of Electr. Eng. & Inf. Technol., Univ. of Naples Federico II, Naples, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","163","168","This paper deals with memory partitioning in the context of high-level synthesis for FPGA technologies. In particular, the work focuses on the area overhead caused by partitioning and sheds light on the interplay with a technique commonly used in HLS, i.e., loop unrolling. As a practical outcome, the study proposes a solution to reduce the area overhead by appropriately controlling the degree of loop unrolling. The experimental results confirm the significance of the analysis as well as the effectiveness of the proposed optimization technique.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092376","","Arrays;Kernel;Lattices;Memory management;Schedules;Switches;Zinc","field programmable gate arrays;network synthesis;optimisation","FPGA technologies;HLS;high-level synthesis;interplay;loop unrolling;multidimensional memory partitioning;optimization technique","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Adaptively tolerate power-gating-induced power/ground noise under process variations","Zhe Wang; Xuan Wang; Jiang Xu; Xiaowen Wu; Zhehui Wang; Peng Yang; Duong, L.H.K.; Haoran Li; Maeda, R.K.V.; Zhifei Wang","Hong Kong Univ. of Sci. & Technol., Hong Kong, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","483","488","Power gating is one of the most effective techniques to reduce the leakage power in multiprocessor system-on-chips (MPSoCs). However, the power-mode transition during the power gating period of an individual processing unit will introduce serious power/ground (P/G) noise to the neighboring processing units. As technology scales, the P/G noise problem becomes a severe reliability threat to MPSoCs. At the same time, the increasing manufacturing process variations also bring uncertainties to the P/G noise problem and make it difficult to predict and deal with. In order to address this problem, for the first time, this paper analyzes the power-gating-induced P/G noise in the presence of process variations, and proposes a hardware-software collaborated online method to adaptively protect processing units from P/G noise. Sensor network-on-chip (SENoC) is used to gather noise information and coordinate different system components. Meanwhile an online software-based algorithm is developed to effectively decide the noise impact range and arrange protections for affected processing units based on the collected information. We evaluate the proposed method through Monte Carlo simulations on a NoC-based MPSoC platform. The experimental results show that for a set of real applications, our method achieves on average 13.2% overall performance improvement and 13.3% system energy reduction compared with the traditional stop-go method.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092437","Multiprocessor system-on-chip;power gating;process variation;reliability;sensor network-on-chip","Manufacturing processes;Noise;Switching circuits;System-on-chip;Transistors;Voltage measurement;Wires","Monte Carlo methods;electric sensing devices;integrated circuit reliability;network-on-chip","Monte Carlo simulations;NoC-based MPSoC platform;P-G noise problem;SENoC;adaptively tolerate power-gating-induced power-ground noise information;hardware-software collaborated online method;individual processing unit protection;leakage power reduction;manufacturing process variations;multiprocessor system-on-chips;neighboring processing units;noise impact range;online software-based algorithm;performance improvement;power-mode transition;process variations;reliability threat;sensor network-on-chip;stop-go method;system energy reduction;technology scales","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"SODA: Software defined FPGA based accelerators for big data","Chao Wang; Xi Li; Xuehai Zhou","Sch. of Comput. Sci., Univ. of Sci. & Technol. of China, Suzhou, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","884","887","FPGA has been an emerging field in novel big data architectures and systems, due to its high efficiency and low power consumption. It enables the researchers to deploy massive accelerators within one single chip. In this paper, we present a software defined FPGA based accelerators for big data, named SODA, which could reconstruct and reorganize the acceleration engines according to the requirement of the various dataintensive applications. SODA decomposes large and complex applications into coarse grained single-purpose RTL code libraries that perform specialized tasks in out-of-order hardware. We built a prototyping system with constrained shortest path Finding (CSPF) case studies to evaluate SODA framework. SODA is able to achieve up to 43.75X speedup at 128 node application. Furthermore, hardware cost of the SODA framework demonstrates that it can achieve high speedup with moderate hardware utilization.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092510","Acceleratioin;Big data;FPGA;Software-defined","Computer architecture;Field programmable gate arrays;Hardware;Operating systems;Program processors;Programming","Big Data;field programmable gate arrays;libraries","Big Data architectures;CSPF;SODA;acceleration engine reconstruction;acceleration engine reorganization;constrained shortest path finding;data intensive applications;out-of-order hardware;single-purpose RTL code libraries;software defined FPGA based accelerators","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"An all-digital spike-based ultra-low-power IR-UWB dynamic average threshold crossing scheme for muscle force wireless transmission","Shahshahani, A.; Shahshahani, M.; Ros, P.M.; Bonanno, A.; Crepaldi, M.; Martina, M.; Demarchi, D.; Masera, G.","Dept. of Electron. & Telecommun., Politec. di Torino, Turin, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1479","1484","We introduce an Impulse Radio Ultra-Wide Band (IR-UWB) radio transmission scheme for miniaturized biomed-ical applications based on a dynamic and adaptive voltage thresholding of surface Electro Myo Graphy (sEMG) signals. The amplified sEMG signal is compared to a DAC-generated threshold computed from the previous 1-bit history by custom digital control logic running at 2kHz clock and implementing an ad-hoc algorithm (Dynamic Average Threshold Crossing, D-ATC). The resulting events and the associated digitized voltage level can be both asynchronously radiated through IR-UWB. Analyzes show that the scheme is robust w.r.t. the sEMG signal variability and correlates by ~96% with regard to raw muscle force information after signal is recomputed at the RX. This paper compares D-ATC with regard to a fixed threshold system and an Average Threshold Crossing (ATC) demonstrating improved robustness, and introduces the thresholding algorithm verified on a dataset of 190 sEMG recorded signals. The applied threshold resolution has been optimized to both minimize the size of transmitted data and to guarantee good correlation performance. The paper concludes with post-synthesis results of the D-ATC compact digital control logic in a 0.18μm CMOS process, demonstrating an extremely low power consumption at very low active area expenses.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092623","","Correlation;Force;Heuristic algorithms;Muscles;Standards;Threshold voltage;Wireless communication","CMOS logic circuits;biomedical communication;digital control;electromyography;medical signal processing;signal resolution;ultra wideband communication","CMOS process;D-ATC compact digital control logic;RX;ad hoc algorithm;adaptive voltage thresholding;biomedical application;digital spike-based ultra low-power IR-UWB dynamic average threshold crossing;dynamic voltage thresholding;impulse radio ultra-wide band radio transmission scheme;muscle force wireless transmission;power consumption;sEMG signal;size 0.18 mum;surface electromyography signal;threshold resolution","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A hybrid Quasi Monte Carlo method for yield aware analog circuit sizing tool","Afacan, E.; Berkol, G.; Pusane, A.E.; Dundar, G.; Baskaya, F.","Dept. of Electr. & Electron. Eng., Bogazici Univ., Istanbul, Turkey","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1225","1228","Efficient yield estimation methods are required by yield aware automatic sizing tools, where many iterative variability analyses are performed. Quasi Monte Carlo (QMC) is a popular approach, in which samples are generated more homogeneously, hence faster convergence is obtained compared to the conventional MC. However, since QMC is deterministic and has no natural variance, there is no convenient way to obtain estimation error bounds. To determine the confidence interval of the estimated yield, scrambled QMC, in which samples are randomly permuted, is run multiple times to obtain stochastic variance by sacrificing computational cost. To palliate this challenge, this paper proposes a hybrid method, where a single QMC is performed to determine infeasible solutions in terms of yield, which is followed by a few scrambled QMC analyses providing variance and confidence interval of the estimated yield. Yield optimization is performed considering the worst case of the current estimation, thus the optimizer guarantees that the solution will satisfy the confidence interval. Furthermore, a yield ranking mechanism is also developed to enforce the optimizer to search for more robust solutions.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092575","","Analog circuits;Monte Carlo methods;Optimization;Sociology;Standards;Yield estimation","Monte Carlo methods;analogue integrated circuits;integrated circuit yield","confidence interval;estimation error bounds;iterative variability analyses;quasi Monte Carlo;scrambled QMC;stochastic variance;yield aware analog circuit sizing tool;yield aware automatic sizing tools;yield estimation methods;yield optimization;yield ranking mechanism","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A pulsed-index technique for single-channel, low-power, dynamic signaling","Muzaffar, S.; Yoo, J.; Shabra, A.; Elfadel, I.A.M.","Inst. Center for Microsyst. (iMicro), Masdar Inst. of Sci. & Technol., Abu Dhabi, United Arab Emirates","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1485","1490","The most common operation of an IoT sensor is that of short activity bursts separated by long time intervals in sleep or listen modes. During the data bursts, sensed information has to be reliably communicated in real time without draining the energy resources of the sensor node. One way to save such resources is to efficiently code the data burst, use single-channel communication, and adopt ultra-low-power communication circuit techniques. Clock-data recovery (CDR) circuits are typically significant consumers of energy on traditional singlechannel communication protocols. In this paper, we present a novel single-channel protocol that does not require any CDR circuitry. The protocol is based on the novel concept of a pulsed index where data is encoded to minimize the number of ON bits, move them to the LSB end of the packet, and transmit the ON bit indices in the form of a pulse stream. The pulse count is equal to the index of the ON bit. We call this protocol Pulsed Index Communication (PIC). Beside the elimination of CDR, we show that the implementation of PIC is very area-efficient, low-power and highly tolerant of clocking differences between transmitter and receiver. We present both an FPGA and an ASIC implementation of the protocol and use them to illustrate the performance, reliability and power consumption features of PIC signaling. In particular, we show that for an ASIC implementation on 65nm technology, PIC can reduce area by more than 80% and power by more than 70% in comparison with a CDR-based serial bit transfer protocol.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092624","Dynamic Signaling;One-Wire;Pulsed Index Communication;Single-Wire","Clocks;Decoding;Encoding;Indexes;Protocols;Receivers;Wires","Internet of Things;application specific integrated circuits;clock and data recovery circuits;field programmable gate arrays;protocols;telecommunication channels","ASIC;FPGA;IoT sensor;PIC signaling;clock-data recovery circuits;energy resources;pulsed index communication;pulsed-index technique;receiver;sensor node;serial bit transfer protocol;single-channel communication protocols;size 65 nm;transmitter;ultra-low-power communication circuit techniques","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Run and Be Safe: Mixed-criticality scheduling with temporary processor speedup","Pengcheng Huang; Kumar, P.; Giannopoulou, G.; Thiele, L.","Comput. Eng. & Networks Lab., ETH Zurich, Zurich, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1329","1334","Mixed-Criticality systems are arising due to the push from several major industries including avionics and automotive, where functionalities with different safety criticality levels are integrated into a modern computing platform to reduce size, weight and energy. The state-of-the-art research has focused on protecting critical tasks under the threat of task overrun, which is achieved by terminating less critical tasks or degrading their services to free system resources to guarantee critical tasks. We take in this paper a different approach to protecting critical tasks by embracing rich features of modern computing platforms. In particular, we explore dynamic processor speedup to aid the scheduling of mixed-criticality systems. We show that speedup in situation of overrun can not only help to protect the timeliness of critical tasks, but also to improve the degraded services for less critical tasks. Furthermore, we show that speedup is even more attractive as it can help the system to recover faster to normal operation. Thus, speedup could only be temporarily required and incur low cost. The proposed techniques are validated by both theoretical analysis and experimental results with an industrial flight management system and extensive simulations.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092598","","Degradation;Dynamic scheduling;Job shop scheduling;Market research;Processor scheduling;Runtime;Safety","processor scheduling;safety-critical software","critical tasks protection;dynamic processor speedup;industrial flight management system;mixed-criticality scheduling;mixed-criticality systems;temporary processor speedup","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Formal verification of sequential Galois field arithmetic circuits using algebraic geometry","Xiaojun Sun; Kalla, P.; Pruss, T.; Enescu, F.","Electr. & Comput. Eng., Univ. of Utah, Salt Lake City, UT, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1623","1628","Sequential Galois field (F<sub>2k</sub>) arithmetic circuits take k-bit inputs and produce a k-bit result, after k-clock cycles of operation. Formal verification of sequential arithmetic circuits with large datapath size is beyond the capabilities of contemporary verification techniques. To address this problem, this paper describes a verification method based on algebraic geometry that: (i) implicitly unrolls the sequential arithmetic circuit over multiple (k) clock-cycles; and (ii) represents the function computed by the state-registers of the circuit, canonically, as a multi-variate word-level polynomial over F<sub>2k</sub>. Our approach employs the Gröbner basis theory over a specific elimination ideal. Moreover, an efficient implementation is described to identify the k-cycle computation performed by the circuit at word-level. We can verify up to 100-bit sequential Galois field multipliers, whereas conventional techniques fail beyond 23-bit circuits.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092653","","Boolean functions;Data structures;Logic gates;Manganese;Polynomials;Registers;Sequential circuits","Galois fields;digital arithmetic;formal verification;multiplying circuits;sequential circuits","Gröbner basis theory;algebraic geometry;datapath size;formal verification;implicit analysis;k-bit inputs;k-bit output;k-clock cycles;multivariate word-level polynomial;sequential Galois field arithmetic circuits;sequential Galois field multipliers;state-registers","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Mixed wire and surface-wave communication fabrics for decentralized on-chip multicasting","Karkar, A.; Kin-Fai Tong; Mak, T.; Yakovlev, A.","Sch. of Electr. & Electron. Eng., Newcastle Univ., Newcastle upon Tyne, UK","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","794","799","Network-on-chip (NoC) has emerged to tackle different on-chip challenges and has satisfied different demands in terms of high performance, economical and reliable interconnect implementation. However, a merely metal-based interconnect reaches performance bound with the relentless technology scaling. Especially, it displayed a bottleneck to meet the communication bandwidth demand for multicasting. This paper proposes a novel hybrid architecture, which improves the on-chip communication bandwidth significantly using mixed wires and surface wave interconnects (SWI) fabrics. In particular, the bandwidth of multicasting can be drastically improved. We introduce a decentralized arbitration method to fully utilize the slack-time scheduling with deadlock-free flow control. Evaluation results, based on a cycle-accurate and hardware-based simulation, demonstrate the effectiveness of the proposed architecture and methods. Compared to a wire-based NoC, the mixed fabric approach can achieve an improvement in power reduction and communication speed up to 63% and 12X, respectively. These results are achieved with almost negligible hardware overheads. This new paradigm efficiently addresses the emerged challenges for on-chip communications.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092494","","Fabrics;Integrated circuit interconnections;Power demand;Protocols;Surface impedance;Surface waves;System-on-chip","fabrics;integrated circuit interconnections;network-on-chip;scheduling","NoC;SWI fabric;communication speed;deadlock-free flow control;decentralized arbitration method;decentralized on-chip multicasting;hybrid architecture;metal-based interconnect;mixed wire fabric;network-on-chip;on-chip communication bandwidth;power reduction;slack-time scheduling;surface wave interconnect;surface-wave communication fabric;technology scaling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Rate-based vs delay-based control for DVFS in NoC","Casu, M.R.; Giaccone, P.","Dept. of Electron. & Telecommun., Politec. di Torino, Turin, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1096","1101","Minimization of power via DVFS in an NoC is possible, but may result in an intolerable increase of network delay. We examined two DVFS policies, a rate-based policy that scales down frequency and voltage to the minimum value that allows to sustain the injection rate without reaching saturation, and a delay-based policy in which a closed-loop control tunes frequency and voltage such that the NoC average delay tracks a target value. We evaluated the power-delay trade-off by means of network simulations and accurate power estimations after synthesis on a 28-nm FDSOI CMOS technology. Our results over synthetic and multimedia traffic patterns show that the first policy largely pays the better saving in power (20%-50% less than the second policy) with a large network delay increase (up to 3×). We then conclude that the delay-based policy offers a better power-delay trade-off.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092552","","Clocks;Delays;Frequency control;Multimedia communication;Power demand;Throughput;Voltage control","closed loop systems;network-on-chip","DVFS;FDSOI CMOS technology;NoC;closed-loop control;delay-based control;delay-based policy;multimedia traffic;network delay;network simulations;power-delay trade-off;rate-based control;rate-based policy;size 28 nm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A robust approach for process variation aware mask optimization","Jian Kuang; Wing-Kai Chow; Young, E.F.Y.","Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Shatin, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1591","1594","As the minimum feature size continues to shrink, whereas the wavelength of light used for lithography remains constant, Resolution Enhancement Techniques are widely used to optimize mask, so as to improve the subwavelength printability. Besides correcting for error between the printed image and target shape, a mask optimization method also needs to consider process variation. In this paper, a robust mask optimization approach is proposed to optimize the process window as well as the Edge Placement Error (EPE) of the printed image. Experiments results on the public benchmarks are encouraging.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092646","","Image edge detection;Image segmentation;Lithography;Optical imaging;Optimization;Resists;Semiconductor device modeling","error correction;image enhancement;image resolution;optimisation;proximity effect (lithography);shape recognition","EPE;edge placement error;error correction;printed image;process variation aware mask optimization;resolution enhancement technique;subwavelength printability improvement;target shape","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"ApproxANN: An approximate computing framework for artificial neural network","Qian Zhang; Ting Wang; Ye Tian; Feng Yuan; Qiang Xu","Dept. of Comput. Sci. & Eng., Chinese Univ. of Hong Kong, Hong Kong, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","701","706","Artificial Neural networks (ANNs) are one of the most well-established machine learning techniques and have a wide range of applications, such as Recognition, Mining and Synthesis (RMS). As many of these applications are inherently error-tolerant, in this work, we propose a novel approximate computing framework for ANN, namely ApproxANN. When compared to existing solutions, ApproxANN considers approximation for both computation and memory accesses, thereby achieving more energy savings. To be specific, ApproxANN characterizes the impact of neurons on the output quality in an effective and efficient manner, and judiciously determine how to approximate the computation and memory accesses of certain less critical neurons to achieve the maximum energy efficiency gain under a given quality constraint. Experimental results on various ANN applications with different datasets demonstrate the efficacy of the proposed solution.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092478","","Approximation methods;Artificial neural networks;Biological neural networks;Degradation;Energy consumption;Hardware;Neurons","neural nets;power aware computing","ApproxANN;approximate computing framework;artificial neural network;energy efficiency gain;quality constraint","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A ultra-low-energy convolution engine for fast brain-inspired vision in multicore clusters","Conti, F.; Benini, L.","Dept. of Electr., Electron. & Inf. Eng., Univ. of Bologna, Bologna, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","683","688","State-of-art brain-inspired computer vision algorithms such as Convolutional Neural Networks (CNNs) are reaching accuracy and performance rivaling that of humans; however, the gap in terms of energy consumption is still many degrees of magnitude wide. Many-core architectures using shared-memory clusters of power-optimized RISC processors have been proposed as a possible solution to help close this gap. In this work, we propose to augment these clusters with Hardware Convolution Engines (HWCEs): ultra-low energy coprocessors for accelerating convolutions, the main building block of many brain-inspired computer vision algorithms. Our synthesis results in ST 28nm FD-SOI technology show that the HWCE is capable of performing a convolution in the lowest-energy state spending as little as 35 pJ/pixel on average, with an optimum case of 6.5 pJ/pixel. Furthermore, we show that augmenting a cluster with a HWCE can lead to an average boost of 40x or more in energy efficiency in convolutional workloads.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092475","","Convolution;Engines;Kernel;Multicore processing;Program processors;Registers","computer vision;multiprocessing systems;neural nets","CNN;FD-SOI technology;HWCE;brain-inspired computer vision algorithms;computer vision;convolutional neural networks;fast brain-inspired vision;hardware convolution engines;multicore clusters;ultralow-energy convolution engine","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Dynamic reconfigurable puncturing for secure wireless communication","Liang Tang; Ambrose, J.A.; Kumar, A.; Parameswaran, S.","Dept. of Electr. & Comput. Eng., Nat. Univ. of Singapore, Singapore, Singapore","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","888","891","The ubiquity of wireless devices has created security concerns on the information being transferred. It is critical to protect the secret information in every layer of wireless communication to thwart any type of attacks. A dynamic reconfigurable puncturing based security mechanism, named RePunc, is proposed in this paper to provide an extra level of security at the physical layer. RePunc utilizes the puncturing feature of Forward Error Correction (FEC) to insert the secure information in the punctured positions of the standard information encoded data. The punctured patterns are dynamically changed and passed as a secret key from the sender to the receiver. An eavesdropper will not be able to detect the transmission of the secure information since the inserted secure information will be processed as channel noise by the eavesdropper's receiver. However, the rightful receiver will be able to successfully decode the secure packets by knowingly differentiating the secure information and the standard information before the FEC decoding. A case study of RePunc implementation for WiFi communication is presented in this paper, showing the extreme high security complexity with low hardware overhead.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092511","","Decoding;Hardware;IEEE 802.11 Standards;Random access memory;Receivers;Security","computer network security;decoding;forward error correction;private key cryptography;radio receivers;software radio;ubiquitous computing;wireless LAN;wireless channels","FEC decoding;RePunc security mechanism;Wi-Fi communication;channel noise;dynamic reconfigurable puncturing;eavesdropper receiver;forward error correction;high security complexity;low hardware overhead;secret information protection;secret key cryptography;secure wireless communication;wireless devices ubiquity","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"M-DTM: Migration-based dynamic thermal management for heterogeneous mobile multi-core processors","Young Geun Kim; Minyong Kim; Jae Min Kim; Sung Woo Chung","Dept. of Comput. & Radio Commun. Eng., Korea Univ., Seoul, South Korea","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1533","1538","Recently, mobile devices have employed heterogeneous multi-core processors which consist of highperformance big cores and low-power small cores. In heterogeneous mobile multi-core processors, the conventional DVFS (Dynamic Voltage and Frequency Scaling)-based DTM (Dynamic Thermal Management) is still adopted; it does not actively utilize the small cores to resolve thermal problem. In this paper, we propose M-DTM (Migration-based DTM) for heterogeneous mobile multi-core processors. In case of thermal emergency of the big cores, M-DTM migrates applications to the small cores instead of lowering the voltage and frequency of the big cores. In this way, M-DTM allows more time for the applications to run at the highest frequency of the big cores by cooling down the big cores more rapidly, compared to the conventional DTM. Through real measurement, we show that M-DTM improves performance by 10.6% and saves system-wide energy (not CPU energy) by 3.6%, on average, compared to the conventional DTM.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092632","","Mobile communication;Mobile handsets;Multicore processing;System-on-chip;Temperature sensors;Time-frequency analysis","multiprocessing systems;thermal management (packaging)","DVFS;M-DTM;dynamic voltage;frequency scaling;heterogeneous mobile multicore processors;migration-based DTM;migration-based dynamic thermal management;mobile devices;thermal emergency;thermal problem","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Energy minimization for fault tolerant scheduling of periodic fixed-priority applications on multiprocessor platforms","Qiushi Han; Ming Fan; Linwei Niu; Gang Quan","Dept. of Electr. & Comput. Eng., Florida Int. Univ., Miami, FL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","830","835","While technology scaling enables the mass integration of transistors into a single chip for performance enhancement, it also makes processors less reliable with ever-increasing failure rates. In this paper, we study the problem of energy minimization for scheduling periodic fixed-priority applications on multiprocessor platforms with fault tolerance requirements. We first introduce an efficient method to determine the checkpointing scheme that guarantees the schedulability of an application under the worst-case scenario, i.e. up to K faults occur, on a single processor. Based on this method, we then present a task allocation scheme aiming at minimizing energy consumption while ensuring the fault tolerance requirement of the system. We evaluate the efficiency and effectiveness of our approaches using extensive simulation studies.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092500","checkpointing;energy-aware;fault tolerance;fixed-priority;partitioning","Checkpointing;Complexity theory;Energy consumption;Fault tolerance;Fault tolerant systems;Program processors;Resource management","checkpointing;fault tolerant computing;minimisation;multiprocessing systems;power aware computing;processor scheduling;resource allocation","checkpointing scheme;energy minimization;fault tolerance requirement;fault tolerant scheduling;multiprocessor;periodic fixed priority application schedulability;task allocation scheme","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Power minimization for data center with guaranteed QoS","Shuo Liu; Homsi, S.; Ming Fan; Shaolei Ren; Gang Quan; Shangping Ren","Dept. of Electr. & Comput. Eng., Florida Int. Univ., Miami, FL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1347","1352","Data centers have been widely employed to offer reliable and agile on-demand web services. However, the dramatic increase of the operational cost, largely due to the power consumptions, has posed a significant challenge to the service providers as services expand in both scale and scope. In this paper, we study the problem of how to improve resource utilization and minimize power consumption in a data center with guaranteed quality-of-service (QoS). Different from a common approach that separates requests with different QoS levels on different servers, we devise an approach to pack requests of the same service - even with different QoS requirements - into the same server to improve resource usage. We also develop a novel method to improve the system utilization without compromising the QoS levels by removing potential failure requests. Experimental results show superiority of our approach over other widely applied approaches.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092601","","Mathematical model;Power demand;Quality of service;Resource management;Servers;Silicon;Time factors","Web services;computer centres;power consumption;quality of service;resource allocation","QoS;Web services;data center;power consumption minimization;power minimization;quality-of-service;resource utilization;system utilization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Comparative study of power-gating architectures for nonvolatile FinFET-SRAM using spintronics-based retention technology","Shuto, Y.; Yamamoto, S.; Sugahara, S.","Imaging Sci. & Eng. Lab., Tokyo Inst. of Technol., Yokohama, Japan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","866","871","Power-gating (PG) architectures employing nonvolatile state/data retention are expected to be a highly efficient energy reduction technique for high-performance CMOS logic systems. Recently, two types of PG architectures using nonvolatile retention have been proposed: One architecture is nonvolatile PG (NVPG) using nonvolatile bistable circuits such as nonvolatile SRAM (NV-SRAM) and nonvolatile flip-flop (NV-FF), in which nonvolatile retention is not utilized during the normal SRAM/FF operation mode and it is used only when there exist energetically meaningful shutdown periods given by breakeven time (BET). In contrast, the other architecture employs nonvolatile retention during the normal SRAM/FF operation mode. In this type of architecture, an even short standby period can be replaced by a shutdown period, and thus this architecture is also called normally-off (NOF) rather than PG. In this paper, these two PG architectures for a FinFET-based highperformance NV-SRAM cell employing spintronics-based nonvolatile retention were systematically analyzed using HSPICE with a magnetoresistive-device macromodel. The NVPG architecture shows effective reduction of energy dissipation without performance degradation, whereas the NOF architecture causes severe performance degradation and the energy efficiency of the NOF architecture cannot be superior to that of the NVPG architecture.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092506","FinFET;break-even time;nonvolatile SRAM;power-gating","Arrays;FinFETs;Microprocessors;Nonvolatile memory;Random access memory;Switches","MOSFET;SRAM chips;flip-flops","BET;HSPICE;NOF architecture;NV-FF;NV-SRAM;NVPG architecture;breakeven time;data retention;energy dissipation;energy efficiency;energy reduction technique;high-performance CMOS logic systems;magnetoresistive-device macromodel;nonvolatile FinFET-SRAM;nonvolatile PG architectures;nonvolatile bistable circuits;nonvolatile flip-flop;nonvolatile retention;nonvolatile state;normal SRAM/FF operation mode;performance degradation;power gating architectures;spintronics-based retention technology","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Detection of asymmetric aging-critical voltage conditions in analog power-down mode","Zwerger, M.; Graeb, H.","Inst. for Electron. Design Autom., Tech. Univ. Munchen, Munich, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1269","1272","In this work, a new verification method for the power-down mode of analog circuit blocks is presented. In power-down mode, matched transistors can be stressed with asymmetric voltages. This will cause time-dependent mismatch due to transistor aging. In order to avoid reliability problems, a new method for automatic detection of asymmetric power-down stress conditions is presented. Therefore, power-down voltage-matching rules are formulated. The method combines structural analysis and voltage propagation. Experimental results demonstrate the efficiency and effectiveness of the approach.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092586","","Aging;Analog circuits;Libraries;Logic gates;Pins;Reliability;Transistors","ageing;analogue integrated circuits;integrated circuit reliability;transistors","analog circuit blocks;analog power-down mode;asymmetric aging-critical voltage conditions detection;asymmetric power-down stress condition detection;matched transistors;power-down voltage-matching rules;reliability problem avoidance;structural analysis;time-dependent mismatch;transistor aging;voltage propagation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Read/write robustness estimation metrics for spin transfer torque (STT) MRAM cell","Vatajelu, E.I.; Rodriguez-Montanes, R.; Indaco, M.; Renovell, M.; Prinetto, P.; Figueras, J.","Dip. di Autom. e Inf., Politec. di Torino, Turin, Italy","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","447","452","The rapid development of low power, high density, high performance SoCs has pushed the embedded memories to their limits and opened the field to the development of emerging memory technologies. The Spin-Transfer-Torque Magnetic Random Access Memory (STT-MRAM) has emerged as a promising choice for embedded memories due to its reduced read/write latency and high CMOS integration capability. Under today aggressive technology scaling requirements, the STT-MRAM is affected by process variability making robustness evaluation an important concern. In this paper, we provide new metrics for robustness prediction of an STT-MRAM memory cell. Independent Robustness Margin metrics are defined for Read Operation and Write Operation based on the electrical characteristics of the memory cell and the fabrication induced variability. These metrics are used to estimate the extreme parameter variation causing the cell failure, Current Noise Margins and the Failure Probability of the STT-MRAM cell.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092431","Process Variability;Robustness;Robustness Margin Metrics;STT-MRAM","Magnetic tunneling;Magnetization;Measurement;Resistance;Robustness;Switches;Thermal stability","MRAM devices;embedded systems;estimation theory;probability","CMOS integration capability;STT-MRAM cell;STT-MRAM memory cell;cell failure;current noise margins;electrical characteristics;embedded memories;emerging memory technologies;extreme parameter variation;fabrication induced variability;failure probability;independent robustness margin metrics;process variability;read operation;reduced read-write latency;robustness prediction;spin-transfer-torque magnetic random access memory;write operation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Sufficient response time analysis considering dependencies between rate-dependent tasks","Feld, T.; Slomka, F.","Inst. of Embedded Syst./Real-Time Syst., Ulm Univ., Ulm, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","519","524","In automotive embedded real-time systems, such as the engine control unit (ECU), some tasks are activated whenever the engine arrives at a specific angular position. In consequence, the frequency at which this task is activated changes with the speed of the engine i. e. angular velocity. Additionally, these tasks have worst case execution times and deadlines that also depends on the angular velocity. Such tasks exhibit rate-dependent behaviour. In recently published works analytical methods for tasks with this rate-dependent behaviour were introduced. Though those methods do not consider dependencies between tasks. For instance one event might be displaced a certain angular position after an event of another task. In this paper, a sufficient analysis will be introduced, which considers those dependencies to improve the accuracy of existing methods.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092443","","Acceleration;Angular velocity;Computational modeling;Engines;Interference;Real-time systems;Time factors","automotive engineering;embedded systems;engines;mechanical engineering computing","analytical method;automotive embedded real-time systems;deadlines;engine;rate-dependent tasks;response time analysis;worst case execution times","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"An energy efficient backup scheme with low inrush current for nonvolatile SRAM in energy harvesting sensor nodes","Hehe Li; Yongpan Liu; Qinghang Zhao; Yizi Gu; Xiao Sheng; Guangyu Sun; Chao Zhang; Meng-Fan Chang; Rong Luo; Huazhong Yang","Dept. of Electron. Eng., Tsinghua Univ., Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","7","12","In modern energy harvesting sensor nodes, nonvolatile SRAM (nvSRAM) has been widely investigated as a promising on-chip memory architecture because of its zero standby power, resilience to power failures, and fast read/write operations. However, conventional approaches transfer all data from SRAM into NVM during the backup process. Thus, large on-chip energy storage capacitors are normally required. In addition, high peak inrush current is generated instantaneously, which has a negative impact on energy efficiency and circuit reliability. To mitigate these problems, we propose a novel holistic backup flow, which consists of a partial backup process and a run-time pre-writeback scheme for nvSRAM based caches. A statistics based dead-block predictor is employed to achieve a fast and low power partial backup process. We also present an adaptive pre-writeback point allocation strategy to further reduce the backup load. Simulation results show that, with our proposed backup scheme, energy storage capacitance is reduced by 34% and inrush current is reduced by 54% on average compared to the conventional full backup scheme.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092350","","Accuracy;Energy harvesting;Hardware;Niobium;Nonvolatile memory;Random access memory;Surges","SRAM chips;capacitor storage;electric sensing devices;energy conservation;energy harvesting;energy measurement;integrated circuit reliability;statistical analysis","NVM;adaptive pre-writeback point allocation strategy;circuit reliability;energy efficient backup scheme;energy harvesting sensor node;fast read-write operation;low inrush current;nonvolatile SRAM;nvSRAM based cache;on-chip energy storage capacitor;on-chip memory architecture;partial backup process;run-time pre-writeback scheme;statistics based dead-block predictor;zero standby power","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Software assisted non-volatile register reduction for energy harvesting based cyber-physical system","Mengying Zhao; Qingan Li; Mimi Xie; Yongpan Liu; Jingtong Hu; Xue, C.J.","Dept. of Comput. Sci., City Univ. of Hong Kong, Hong Kong, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","567","572","Wearable devices are important components as information collector in many cyber-physical systems. Energy harvesting instead of battery is a better power source for these wearable devices due to many advantages. However, harvested energy is naturally unstable and program execution will be interrupted frequently. Non-volatile processors demonstrate promising advantages to back up volatile state before the system energy is depleted. However, it also introduces non-negligible energy and area overhead. Since the chip size is a vital factor for wearable devices, in this work, we target non-volatile register reduction for application-specific systems. We propose to analyze the application program and determine efficient backup positions, by which the necessary non-volatile register file size can be significantly reduced. The evaluation results deliver an average of 62.9% reduction on non-volatile register file size for stack backup, with negligible storage overheads.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092451","","Biomedical monitoring;Energy harvesting;Nonvolatile memory;Program processors;Random access memory;Registers;Runtime","energy harvesting;power engineering computing","application-specific system;chip size;cyber-physical system;energy harvesting;information collector;nonvolatile processor;nonvolatile register file size reduction;software assisted nonvolatile register reduction;wearable device","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Platform-specific timing verification framework in model-based implementation","BaekGyu Kim; Lu Feng; Phan, L.T.X.; Sokolsky, O.; Insup Lee","Univ. of Pennsylvania, Philadelphia, PA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","235","240","In the model-based implementation methodology, the timed behavior of the software is typically modeled independently of the platform-specific timing semantics such as the delay due to scheduling or I/O handling. Although this approach helps to reduce the complexity of the model, it leads to timing gaps between the model and its implementation. This paper proposes a platform-specific timing verification framework that can be used to formally verify the timed behavior of an implementation that has been developed from a platform-independent model. We first describe a way to categorize the interactions among the software, a platform, and the environment in the form of implementation schemes. We then present an algorithm that systematically transforms a platform-independent model into a platform-specific model under a given implementation scheme. This transformation algorithm ensures that the timed behavior of the platform-specific model is close to that of the corresponding implementation. Our case study of an infusion pump system shows that the measured timing delay of the system is bounded by the formally verified bound of its platform-specific model.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092388","","Automata;Computational modeling;Delays;Semantics;Software;Synchronization","formal specification;program verification;scheduling;software metrics;timing","I/O handling;formal verification;infusion pump system;model complexity;model-based implementation methodology;platform-independent model;platform-specific model;platform-specific timing semantics;platform-specific timing verification framework;scheduling;timing delay","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Variation-aware evaluation of MPSoC task allocation and scheduling strategies using statistical model checking","Mingsong Chen; Daian Yue; Xiaoke Qin; Xin Fu; Mishra, P.","Shanghai Key Lab. of Trustworthy Comput., East China Normal Univ., Shanghai, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","199","204","To maximize the overall performance yield, variation-aware analysis is becoming a key step in Multiprocessor System-on-Chip (MP-SoC) Task Allocation and Scheduling (TAS). Although various approaches have been investigated to improve performance yields, most of them cannot perform quantitative comparison among existing TAS heuristics, which is important for MPSoC designers to make decisions. Based on the statistical model checker UPPAAL-SMC, we propose a framework that can automatically evaluate the performance yield of TAS strategies under time and power constraints with variations. Experimental results show that our approach can not only filter inferior strategies efficiently, but also support the automated tuning of architecture and constraint parameters to achieve the required performance yield.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092382","","Arrays;Data models;Gaussian distribution;Monitoring;Stochastic processes;Time factors;Tuning","decision making;processor scheduling;statistical analysis;system-on-chip","MPSoC;TAS;UPPAAL-SMC;automated tuning;decision making;filter inferior strategies;multiprocessor system-on-chip;power constraint;quantitative comparison;statistical model checking;task allocation-and-scheduling;time constraint;variation-aware evaluation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Impact of interconnect multiple-patterning variability on SRAMs","Karageorgos, I.; Stucchi, M.; Raghavan, P.; Ryckaert, J.; Tokei, Z.; Verkest, D.; Baert, R.; Sakhare, S.; Dehaene, W.","imec, Leuven, Belgium","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","609","612","The introduction of Multiple Patterning (MP) in sub-32nm technology nodes may pose severe variability problems in wire resistance and capacitance of IC circuits. In this paper we evaluate the impact of this variability on the performance of SRAM cell arrays based on the 10nm technology node, for a relevant range of process variation assumptions. The MP options we consider are the triple Litho-Etch (LE<sup>3</sup>) and the Self Aligned Double Patterning (SADP), together with Single Patterning Extreme-UV (EUV). In addition to the analysis of the worst-case variability scenario and the impact on SRAM performance, we propose an analytical formula for the estimation of SRAM read time penalty, using the RC variation of the bit line and the array size as input parameters. This formula, verified with SPICE simulations, allows a fast extraction of the statistical distribution of the read time penalty, using the Monte-Carlo method. Results on each patterning option are presented and compared.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092460","","Capacitance;Layout;Lithography;Resistance;SRAM cells;Wires","Monte Carlo methods;SRAM chips;etching;integrated circuit interconnections;lithography;statistical distributions","IC circuits;Monte-Carlo method;RC variation;SPICE simulations;SRAM cell arrays;array size;bit line;interconnect multiple-patterning variability;process variation assumptions;read time penalty;self aligned double patterning;single patterning extreme-UV;size 10 nm;size 32 nm;statistical distribution;triple litho-etch;variability problems;wire capacitance;wire resistance;worst-case variability scenario","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"FastTree: A hardware KD-tree construction acceleration engine for real-time ray tracing","Xingyu Liu; Yangdong Deng; Yufei Ni; Zonghui Li","Inst. of Microelectron., Tsinghua Univ., Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1595","1598","The ray tracing algorithm is well-known for its ability to generate photo-realistic rendering effects. Recent years have witnessed a renewed momentum in pushing it to real-time for better user experience. Today the construction of acceleration structures, e.g., kd-tree, has become the bottleneck of ray tracing. A dedicated hardware architecture, FastTree, was proposed for kd-tree construction by adopting a fully parallel construction algorithm. FastTree was validated by an FPGA prototype and evaluated as an ASIC implementation. Experiment result shows FastTree outperforms existing hardware construction engines by a factor of nearly 4X at a similar area and power budget.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092647","hardware acceleration;kd-tree;kd-tree construction;ray tracing;real-time ray tracing","Acceleration;Application specific integrated circuits;Engines;Field programmable gate arrays;Graphics;Hardware;Ray tracing","application specific integrated circuits;field programmable gate arrays;parallel algorithms;ray tracing;rendering (computer graphics)","ASIC;FPGA prototype;FastTree;hardware KD-tree construction acceleration engine;hardware architecture;parallel construction algorithm;photo-realistic rendering effects;real-time ray tracing algorithm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"FP-scheduling for mode-controlled dataflow: A case study","Lele, A.; Moreira, O.; van Berkel, K.","Eindhoven Univ. of Technol., Eindhoven, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1257","1260","Dual-Radio Simultaneous Access (DRSA) is an emerging topic in Software Defined Radio (SDR) in which two SDRs are running simultaneously on a shared hardware, typically a heterogeneous Multi-Processor System-on-Chip (MPSoC). Each SDR has a independent hard latency and/or throughput requirement and needs rigorous timing analysis. Moreover, SDRs are often modeled in enriched variants of dataflow to accommodate the growing dynamic execution of SDRs, making it a challenge to perform timing analysis on them. This paper considers the preemptive Fixed Priority Scheduling (FPS) of SDRs modeled in Mode-Controlled Dataflow. To the best of our knowledge this is the first attempt on static timing analysis of FPS for a (semi-)dynamic variant of synchronous dataflow. We propose a two-phase algorithm to determine the worst-case response time of an actor. We demonstrate our analysis results for a DRSA case study of two 4G-LTE receivers.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092583","","Interference;Ports (Computers);Program processors;Receivers;Schedules;Switches;Time factors","data flow analysis;software radio;telecommunication computing;telecommunication scheduling","4G-LTE receivers;DRSA;FP-scheduling;MPSoC;SDR;dual-radio simultaneous access;heterogeneous multiprocessor system-on-chip;independent hard latency;mode-controlled dataflow;preemptive fixed priority scheduling;software defined radio;static timing analysis;synchronous dataflow;two-phase algorithm","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Accelerating arithmetic kernels with coherent attached FPGA coprocessors","Giefers, H.; Polig, R.; Hagleitner, C.","IBM Res. - Zurich, Zurich, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1072","1077","The energy efficiency of computer systems can be increased by migrating computational kernels that are known to under-utilize the CPU to an FPGA based coprocessor. In contrast to traditional I/O-based coprocessors that require explicit data movement, coherently attached accelerators can operate on the same virtual address space than the host CPU. A shared memory organization enables widely accepted programming models and helps to deploy energy efficient accelerators in general purpose computing systems. In this paper we study an FFT accelerator on FPGA attached via the Coherent Accelerator Processor Interface (CAPI) to a POWER8 processor. Our results show that the coherent attached accelerator outperforms device driver based approaches in terms of latency. Hardware acceleration delivers a 5× gain in energy efficiency compared to an optimized parallel software FFT running on a 12-core CPU and improves single thread performance by more than 2×. We conclude that the integration of CAPI into heterogeneous programming frameworks such as OpenCL will facilitate latency critical operations and will further enhance programmability of hybrid systems.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092548","","Computer architecture;Coprocessors;Field programmable gate arrays;Hardware;Kernel;Programming","coprocessors;fast Fourier transforms;field programmable gate arrays;parallel processing;power aware computing;shared memory systems","12-core CPU;CAPI;CPU;FFT accelerator;FPGA based coprocessor;I/O-based coprocessors;OpenCL;POWER8 processor;arithmetic kernel acceleration;coherent accelerator processor interface;coherent attached FPGA coprocessors;computational kernels;computer system energy efficiency;device driver based approach;heterogeneous programming frameworks;hybrid system programmability;optimized parallel software FFT;programming models;shared memory organization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Lightweight authentication for secure automotive networks","Mundhenk, P.; Steinhorst, S.; Lukasiewycz, M.; Fahmy, S.A.; Chakraborty, S.","TUM CREATE, Singapore, Singapore","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","285","288","We propose a framework to bridge the gap between secure authentication in automotive networks and on the internet. Our proposed framework allows runtime key exchanges with minimal overhead for resource-constrained in-vehicle networks. It combines symmetric and asymmetric cryptography to establish secure communication and enable secure updates of keys and software throughout the lifetime of the vehicle. For this purpose, we tailor authentication protocols for devices and authorization protocols for streams to the automotive domain. As a result, our framework natively supports multicast and broadcast communication. We show that our lightweight framework is able to initiate secure message streams fast enough to meet the real-time requirements of automotive networks.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092398","","Authentication;Authorization;Automotive engineering;Encryption;Vehicles","Internet;authorisation;automobiles;computer network security;cryptographic protocols","Internet;asymmetric cryptography;authentication protocols;authorization protocols;broadcast communication;lightweight authentication;multicast communication;resource-constrained in-vehicle networks;runtime key exchanges;secure authentication;secure automotive networks;secure message streams","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"In-place memory mapping approach for optimized parallel hardware interleaver architectures","Reehman, S.U.; Chavet, C.; Coussy, P.; Sani, A.","Lab.-STICC Lab., Univ. de Bretagne Sud, Lorient, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","896","899","Due to their impressive error correction performances, turbo-codes or LDPC architectures are now widely used in communication systems and are one of the most critical parts of decoders. In order to achieve high throughput requirements these decoders are based on parallel architectures, which results in a major problem to be solved: parallel memory access conflicts. To solve these conflicts, different approaches have been proposed in state of the art resulting in a lot of different architectural solutions. In this article, we introduce a new class of memory mapping approach solving the conflicts with an optimized architecture based on in-place memory mapping for any application.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092513","architecture;error correction codes;interleaver;memory mapping","Decoding;Image color analysis;Memory architecture;Memory management;Parity check codes;Turbo codes","parallel architectures;storage management","in-place memory mapping;parallel hardware interleaver architectures","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"SAHARA: A security-aware hazard and risk analysis method","Macher, G.; Sporer, H.; Berlach, R.; Armengaud, E.; Kreiner, C.","Inst. for Tech. Inf., Graz Univ. of Technol., Graz, Austria","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","621","624","Safety and Security are two seemingly contradictory system features, which have challenged researchers for decades. Traditionally, these two features have been treated separately, but due to the increasing knowledge about their mutual impacts, similarities, and interdisciplinary values, they have become more important. Because systems (such as Car2x in the automotive industry) are increasingly interlaced, it is no longer acceptable to assume that safety systems are immune to security risks. Future automotive systems will require appropriate systematic approaches that will support security-aware safety development. Therefore, this paper presents a combined approach of the automotive HARA (hazard analysis and risk assessment) approach with the security domain STRIDE approach, and outlines the impacts of security issues on safety concepts at system level. We present an approach to classify the probability of security threats, which can be used to determine the appropriate number of countermeasures that need to be considered. Furthermore, we analyze the impact of these security threats on the safety analysis of automotive systems. This paper additionally describes how such a method has been developed based on the HARA approach, and how the safety-critical contributions of successful security attacks can be quantified and processed.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092463","HARA;ISO 26262;STRIDE;automotive;safety;security","Automotive engineering;Hazards;ISO standards;Risk management;Security","automotive engineering;hazards;road safety;safety-critical software;security of data","automotive HARA approach;automotive system;hazard analysis and risk assessment;safety analysis;safety-critical contribution;security attacks;security aware safety development;security domain STRIDE approach;security threat","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"DRAM or no-DRAM? Exploring linear solver architectures for image domain warping in 28 nm CMOS","Schaffner, M.; Gurkaynak, F.K.; Smolic, A.; Benini, L.","ETH Zurich, Zu&#x0308;rich, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","707","712","Solving large optimization problems within the energy and cost budget of mobile SoCs in real-time is a challenging task and motivates the development of specialized hardware accelerators. We present an evaluation of different linear solvers suitable for least-squares problems emanating from image processing applications such as image domain warping. In particular, we estimate implementation costs in 28 nm CMOS technology, with focus on trading on-chip memory vs. off-chip (DRAM) bandwidth. Our assessment shows large differences in circuit area, throughput and energy consumption and aims at providing a recommendation for selecting a suitable architecture. Our results emphasize that DRAM-free accelerators are an attractive choice in terms of power consumption and overall system complexity, even though they require more logic silicon area when compared to accelerators that make use of external DRAM.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092479","","Bandwidth;Estimation;Hardware;Memory management;Random access memory;System-on-chip","CMOS logic circuits;DRAM chips;least squares approximations","CMOS technology;DRAM bandwidth;DRAM-free accelerators;image domain warping;image processing applications;large optimization problems;least-squares problems;linear solvers;logic silicon area;mobile SoC;off-chip bandwidth;on-chip memory;size 28 nm;specialized hardware accelerators","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Fast optical simulation from a reduced set of impulse responses using SystemC-AMS","Teysseyre, F.; Navarro, D.; O'Connor, I.; Cascio, F.; Cenni, F.; Guillaume, O.","Inst. des Nanotechnol. de Lyon, Ecully, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","405","409","In this paper we propose a methodology to simulate the optical filtering system of a camera module with limited access to proprietary data. The target of the simulation is the virtual prototyping of the overall camera module for a fine tuning of the auto-focus mechanism. For the optical system modeling, the methodology is based on the usage of some point spread functions (PSFs). The use of the full set of PSFs is computationally costly and memory space consuming hence compromising the usability of the optical model in the full system virtual prototyping. To improve the model execution time, PSFs interpolation and free-space propagation techniques are used: they allow reducing the sampling space with minimal impact on the accuracy of the model (sharpness error less than 2%). The total speed-up gain with respect to the standard non-optimized model is provided by two contributors. First, the interpolation technique leads to a speed-up linked to the PSFs number reduction. Second, the caching of computationally intense processes enables speed-up scaling with the number of frames.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092423","Fresnel diffraction;SystemC AMS;free-space propagation;optics modeling;point spread function;virtual prototyping","Adaptive optics;Computational modeling;Interpolation;Lenses;Optical filters;Optical imaging","cameras;optical computing;optical filters;transient response;virtual prototyping","SystemC-AMS;autofocus mechanism;camera module;fast optical simulation;free-space propagation techniques;impulse responses;interpolation technique;model execution time;optical filtering system;optical system modeling;point spread functions;virtual prototyping","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Fast and accurate branch predictor simulation","Faravelon, A.; Fournel, N.; Petrot, F.","TIMA Lab., Univ. de Grenoble-Alpes, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","317","320","The complexity of embedded processors has raised dramatically, due to the addition of architectural add-ons which improve performances significantly. High level models used in system simulation usually ignore these additions as the major issue is functional correctness. However, accurate estimates of software execution is sometimes required, therefore we focus in this paper on one of theses architectural features, the branch predictor. Unfortunately, advanced branch predictors use large tables, so that models directly implementing these schemes slow down simulation dramatically. To limit the simulation overhead, we define a modeling approach that we demonstrate on a state of the art predictor. We implemented the model in a dynamic binary translation based instruction set simulator and measured an accuracy of prediction of about 95% for a run-time overhead of less than 5%.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092406","","Accuracy;Computational modeling;Computer architecture;Predictive models;Program processors;Rabbits;Radiation detectors","digital simulation;embedded systems;instruction sets;program compilers","architectural add-ons;branch predictor simulation;dynamic binary translation based instruction set simulator;embedded processor complexity;functional correctness;high level models;modeling approach;software execution;system simulation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Pre-simulation symbolic analysis of synchronization issues between discrete event and timed data flow models of computation","Andrade, L.; Maehne, T.; Vachoux, A.; Ben Aoun, C.; Pecheux, F.; Louerat, M.-M.","UPMC Univ. Paris 06, Paris, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1671","1676","The SystemC AMS extensions support heterogeneous modeling and make use of several Models of Computation (MoCs) that operate on different time scales in the Discrete Event (DE), Discrete Time (DT), and Continuous Time (CT) domains. The simulation of such heterogeneous models may raise synchronization problems that are hard to diagnose and to fix, especially when considering multi-rate data flow parts. In this paper, we show how to formally analyze the execution of Timed Data Flow (TDF) models including their interaction with the DE domain by converting the synchronization mechanics into a Coloured Petri Net (CPN) equivalent. The developed symbolic execution algorithm for the CPN allows to detect all DE-TDF synchronization issues before simulation and to propose appropriate sample delay settings for the TDF converter ports to make the system schedulable. The presented technique is validated with a case study including a vibration sensor model and its digital front end.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092661","Coloured Petri Net (CPN);Discrete Event (DE);Discrete Time (DT);Model of Computation (MoC);SystemC Analog/Mixed-Signal (AMS) extensions;Timed Data Flow (TDF);multi-domain simulation;synchronization","Computational modeling;Data models;Delays;Ports (Computers);Schedules;Synchronization;Tin","Petri nets;computerised instrumentation;discrete event simulation;embedded systems;sensors;symbol manipulation;synchronisation;vibrations","CPN;CT;DE-TDF synchronization issues;DT;MoC;SystemC AMS extensions;coloured Petri net equivalent;continuous time domains;digital front end;discrete event models of computation;discrete time domains;heterogeneous modeling;multirate data flow parts;presimulation symbolic analysis;symbolic execution algorithm;synchronization issues;timed data flow models;timed data flow models of computation;vibration sensor model","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"High performance single supply CMOS inverter level up shifter for multi-supply voltages domains","Garcia, J.C.; Montiel-Nelson, J.A.; Sosa, J.; Nooshabadi, S.","Univ. of Las Palmas de Gran Canaria, Las Palmas, Spain","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1273","1276","A single supply CMOS inverter level shifter (ssqc- ls) for upconverting signals from 0.4V-1V logic level range up to 1.1V power supply domain is introduced. For guaranteing a low energy consumption, the proposed shifter is based on topological modifications of the structure qc-level shifter reported in [1]. For 0.5V input square wave switching at 500MHz, the inverter level shifter ssqc-ls using 1.2V of power supply voltage achieves a 60% of Figure of Merit improvement in comparison against jy-ls [8] with a dual power supply voltage of 0.6V and 1.2V. Post-layout simulation results shown that ssqc-ls reaches a propagation delay of 0.75ns, an energy consumption of only 2.3pJ, and an energy- delay product of 1.73pJns for a capacitive loading condition of 950fF.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092587","","CMOS integrated circuits;Delays;Digital audio players;Energy consumption;Inverters;Power supplies;Transistors","CMOS integrated circuits;invertors;power consumption;power supply quality;switching convertors","capacitive loading;dual power supply voltage;frequency 500 MHz;high performance single supply CMOS inverter level up shifter;input square wave switching;inverter level shifter ssqc-ls;logic level range;low energy consumption;multisupply voltage domain;power supply domain;propagation delay;structure qc-level shifter;time 0.75 ns;upconverting signals;voltage 0.4 V to 1.2 V","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"MPIOV: Scaling hardware-based I/O virtualization for mixed-criticality embedded real-time systems using non transparent bridges to (Multi-Core) multi-processor systems","Munch, D.; Paulitsch, M.; Hanka, O.; Herkersdorf, A.","Airbus Group Innovations, Munich, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","579","584","Safety-critical systems consolidating multiple functionalities of different criticality (so-called mixed-criticality systems) require separation between these functionalities to assure safety and security properties. Performance-hungry and safety-critical applications (like a radar processing system steering an autonomous flying aircraft) may demand an embedded high-performance computing cluster of more than one (multi-core) processor. This paper presents the Multi-Processor I/O Virtualization (MPIOV) concept to enable hardware-based Input/Output (I/O) virtualization or sharing with separation among multiple (multi-core) processors in (mixed-criticality) embedded real-time systems, which usually do not have means for separation like an Input/Output Memory Management Unit (IOMMU). The concept uses a Non-Transparent Bridge (NTB) to connect each processing host to the management host, while checking the target address and source / origin ID to decide whether or not to block a transaction. It is a standardized, portable and non-proprietary platform-independent spatial separation solution that does not require an IOMMU in the processor. Furthermore, the concept sketches an approach for PCI Express (PCIe)-based systems to enable sharing of up to 2048 (virtual) functions per endpoint, while still being compatible to the plain PCIe standard. A practical evaluation demonstrates that the impact to performance degradation (transfer time, transfer rate) is negligible (about 0.01%) compared to a system without separation.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092453","IOMMU;IOMPU;hardware-based I/O virtualization;mixed-criticality systems;multi-core;multiprocessor;non-transparent bridge (NTB);real-time embedded systems;spatial separation","Aerospace electronics;Bridges;Memory management;Multicore processing;Real-time systems;Standards;Virtualization","multiprocessing systems;parallel processing;safety-critical software;virtualisation","IOMMU;MPIOV;NTB;PCI express;embedded high-performance computing cluster;hardware-based I-O virtualization;input-output memory management unit;mixed-criticality embedded real-time system;multiprocessor I/O virtualization;multiprocessor system;nontransparent bridge;safety-critical systems","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A basic linear algebra compiler for embedded processors","Kyrtatas, N.; Spampinato, D.G.; Puschel, M.","Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1054","1059","Many applications in signal processing, control, and graphics on embedded devices require efficient linear algebra computations. On general-purpose computers, program generators have proven useful to produce such code, or important building blocks, automatically. An example is LGen, a compiler for basic linear algebra computations of fixed size. In this work, we extend LGen towards the embedded domain using as example targets Intel Atom, ARM Cortex-A8, ARM Cortex-A9, and ARM1176 (Raspberry Pi). To efficiently support these processors we introduce support for the NEON vector ISA and a methodology for domain-specific load/store optimizations. Our experimental evaluation shows that the new version of LGen produces code that performs in many cases considerably better than well-established, commercial and non-commercial libraries (Intel MKL and IPP), software generators (Eigen and ATLAS), and compilers (icc, gcc, and clang).","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092545","","Arrays;Libraries;Linear algebra;Linux;Optimization;Program processors","embedded systems;linear algebra;program compilers;software libraries","ARM Cortex-A8;ARM Cortex-A9;ARM1176;Intel Atom;LGen;domain-specific load optimizations;domain-specific store optimizations;embedded processors;linear algebra compiler;noncommercial libraries;software generators","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Optimizing dynamic trace signal selection using machine learning and linear programming","Zhu, C.S.; Malik, S.","Princeton Univ., Princeton, NJ, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1289","1292","The success of post-silicon validation is limited by the low observability of the signals on the chip under debug. Trace buffers are used to enhance visibility of a subset of the internal signals during the chip's operation. These trace signals can be selected statically, i.e. the same trace signals are used through an entire debugging run, or dynamically where a different set of signals can be used in different parts of a debugging run. The focus of this work is on dynamic trace signal selection. Our technique uses machine learning for classification of different groups of inputs that are likely to trigger different faults, and a linear programming based optimization method for selecting the different sets of trace signals for different combinations of inputs and states. In contrast to existing methods, this technique is applicable to both transient and permanent faults.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092591","","Circuit faults;Debugging;Decision trees;Heuristic algorithms;Multiplexing;Registers;Transient analysis","learning (artificial intelligence);linear programming;observability;signal classification;signal processing","chip operation;dynamic trace signal selection optimization;internal signals;linear programming;linear programming based optimization method;machine learning;permanent faults;post-silicon validation;transient faults","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A hardware implementation of a radial basis function neural network using stochastic logic","Yuan Ji; Feng Ran; Cong Ma; Lilja, D.J.","Microelectron. R&D Center, Shanghai Univ., Shanghai, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","880","883","Hardware implementations of artificial neural networks typically require significant amounts of hardware resources. This paper proposes a novel radial basis function artificial neural network using stochastic computing elements, which greatly reduces the required hardware. The Gaussian function used for the radial basis function is implemented with a two-dimensional finite state machine. The norm between the input data and the center point is optimized using simple logic gates. Results from two pattern recognition case studies, the standard Iris flower and the MICR font benchmarks, show that the difference of the average mean squared error between the proposed stochastic network and the corresponding traditional deterministic network is only 1.3% when the stochastic stream length is 10kbits. The accuracy of the recognition rate varies depending on the stream length, which gives the designer tremendous flexibility to tradeoff speed, power, and accuracy. From the FPGA implementation results, the hardware resource requirement of the proposed stochastic hidden neuron is only a few percent of the hardware requirement of the corresponding deterministic hidden neuron. The proposed stochastic network can be expanded to larger scale networks for complex tasks with simple hardware architectures.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092509","2D-FSM (two-dimensional finite state machine);ANN (artificial neural network);Gaussian function;RBF (radial basis function);pattern recognition;stochastic computing","Clocks;Computer architecture;Hardware;Iris recognition;Logic gates;Neurons;Radial basis function networks","Gaussian processes;formal logic;mean square error methods;radial basis function networks","FPGA implementation;Gaussian function;artificial neural networks;average mean squared error;center point;finite state machine;hardware architectures;hardware implementation;hardware resources;input data;pattern recognition;radial basis function neural network;simple logic gates;stochastic computing elements;stochastic hidden neuron;stochastic logic;stochastic network;stochastic stream length","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"An online thermal-constrained task scheduler for 3D multi-core processors","Chien-Hui Liao; Wen, C.H.-P.; Chakrabarty, K.","Inst. of Commun. Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","351","356","Hotspots occur frequently in 3D multi-core processors (3D-MCPs) and they can adversely impact system reliability and lifetime. Moreover, frequent occurrences of hotspots lead to more dynamic voltage and frequency scaling (DVFS), resulting in degraded throughput. Therefore, a new thermal-constrained task scheduler based on thermal-pattern-aware voltage assignment (TPAVA) is proposed in this paper. By analyzing temperature profiles of different voltage assignments, TPAVA pre-emptively assigns different operating-voltage levels to cores for reducing temperature increase in 3D-MCPs. Moreover, the proposed task scheduler integrates a vertical-grouping voltage scaling (VGVS) strategy that considers thermal correlation in 3D-MCPs. Experimental results show that, compared with two previous methods, the proposed task scheduler can respectively lower hotspot occurrences by 47.13% and 53.91%, and improve throughput by 6.50% and 32.06%. As a result, TPAVA and VGVS are effectively for reducing occurrences of hotspots and optimizing throughput for 3D-MCPs under thermal constraints.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092413","","Heat sinks;Mathematical model;Power demand;Resource management;Three-dimensional displays;Throughput;Voltage control","multiprocessing systems;power aware computing;processor scheduling","3D multicore processors;3D-MCP;TPAVA;VGVS strategy;dynamic voltage and frequency scaling;hotspots;lifetime;online thermal-constrained task scheduler;operating-voltage levels;system reliability;temperature profile analysis;thermal correlation;thermal-pattern-aware voltage assignment;vertical-grouping voltage scaling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Clustering-based multi-touch algorithm framework for the tracking problem with a large number of points","Shih-Lun Huang; Sheng-Yi Hung; Chung-Ping Chen","Grad. Inst. of Electron. Eng., Nat. Taiwan Univ., Taipei, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","719","724","Microcontrollers (MCUs) are extensively used in consumer devices for specific purposes because they are tiny, cheap, and low-power. Any time-consuming algorithm and any large-size program are not suited for MCUs. Recently, we found that the conventional multi-touch algorithm becomes computationally expensive to handle the applications of large-sized touch panels. Although a more high-end MCU can obtain an improvement on speed, it would increase manufacturing cost and operating power consumption as well. In the whole multi-touch algorithm flow, point tracking is the most computationally expensive part. Fortunately, touch point tracking is similar to the pin-assignment problem in EDA. To accelerate tracking, we employ EDA techniques, such as clustering, to speed up our multi-touch algorithm. Besides, we prove that the tracking problem would be solved in O(n) time for practical cases and without losing its accuracy after clustering. Furthermore, we apply computational geometry techniques to develop an efficient clustering method. Experimental results show that clustering is efficient and effective. For the necessary requirement of large-area touch panels having 20 touch points, we can reduce the runtime by up to 70%. Besides, our multi-touch algorithm may support up to 80 touch points accompanied by a low-cost MCU.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092481","","Accuracy;Clustering algorithms;Clustering methods;Runtime;Sensors;Time complexity;Tracking","computational geometry;microcontrollers;pattern clustering;touch sensitive screens","EDA techniques;clustering-based multitouch algorithm framework;computational geometry techniques;consumer devices;high-end MCU;large-sized touch panels;manufacturing cost;microcontrollers;pin-assignment problem;power consumption;touch point tracking;tracking problem","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Adaptive on-the-fly application performance modeling for many cores","Kobbe, S.; Bauer, L.; Henkel, J.","Dept. of Embedded Syst. (CES), Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","730","735","Resource management for a many-core system entails allocating cores to applications and binding tasks of the applications to particular cores. Accurate on-the-fly estimates of different core allocations w.r.t. application performance are required before binding the tasks to cores for execution efficiency. We propose an adaptive on-the-fly application performance model that largely alleviates this increasingly important problem. It allows reacting to spontaneous workload variations and it considers topological properties of resources. Extensive evaluations show that the average estimation error is reduced from 14.7% to 4.5%, resulting in high quality of on-the-fly adaptive application mappings. Our work is a first milestone towards optimality of systems that exhibit a high degree of spontaneous workload variations.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092483","","Accuracy;Adaptation models;Computational modeling;Delays;Estimation;Resource management;Runtime","multiprocessing systems;performance evaluation;resource allocation","adaptive on-the-fly application performance modeling;application performance;binding tasks;core allocation;many-core system;on-the-fly adaptive application mappings;resource management;spontaneous workload variations","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Maximizing IO performance via conflict reduction for flash memory storage systems","Qiao Li; Liang Shi; Congming Gao; Kaijie Wu; Xue, C.J.; Qingfeng Zhuge; Sha, E.H.-M.","Coll. of Comput. Sci., Chongqing Univ., Chongqing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","904","907","Flash memory has been widely deployed during the recent years with the improvement of bit density and technology scaling. However, a significant performance degradation is also introduced with the development trend. The latency of IO requests on flash memory storage systems is composed of access conflict latency, data transfer latency, flash chip access latency and ECC encoding/decoding latency. Studies show that the access conflict latency, which is mainly induced by the slow transfer latency and access latency, has become the dominate part of the IO latency, especially for IO intensive applications. This paper proposes to reduce the flash access conflict latency through the reduction of the transfer and flash access latencies. A latency model is built to construct the relationship among the transfer latency and access latency based on the reliability characteristics of flash memory. Simulation experiments show that the proposed approach achieves significant performance improvement.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092515","","Ash;Data transfer;Decoding;Error correction codes;Parity check codes;Programming;Sensors","flash memories;public key cryptography","ECC encoding-decoding latency;IO performance;conflict reduction;data transfer latency;flash chip access latency;flash memory storage systems","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"An energy-efficient virtual channel power-gating mechanism for on-chip networks","Mirhosseini, A.; Sadrosadati, M.; Fakhrzadehgan, A.; Modarressi, M.; Sarbazi-Azad, H.","Dept. of Comput. Eng., Sharif Univ. of Technol., Tehran, Iran","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1527","1532","Power-gating is a promising method for reducing the leakage power of digital systems. In this paper, we propose a novel power-gating scheme for virtual channels in on-chip networks that uses an adaptive method to dynamically adjust the number of active VCs based on the on-chip traffic characteristics. Since virtual channels are used to provide higher throughput under high traffic loads, our method sets the number of virtual channel at each port selectively based on the workload demand, thereby do not negatively affect performance. Evaluation results show that by using this scheme, about 40% average reduction in static power consumption can be achieved with negligible performance overhead.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092631","","Measurement;Ports (Computers);Power demand;Resource management;System-on-chip;Throughput;Turning","energy conservation;network-on-chip;power consumption","active VC;adaptive method;digital system;energy-efficient virtual channel power-gating mechanism;leakage power reduction;on-chip networks;on-chip traffic characteristics;static power consumption;traffic load;virtual channel;workload demand","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A breakpoint-based silicon debug technique with cycle-granularity for handshake-based SoC","Hsin-Chen Chen; Cheng-Rong Wu; Li, K.S.-M.; Kuen-Jong Lee","Dept. of Electr. Eng., Nat. Cheng Kung Univ., Tainan, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1281","1284","The breakpoint-based silicon debug approach allows users to stop the normal (system) operations of the circuits under debug (CUDs), extract the internal states of the CUDs for examination, and then resume the normal operations for further debugging. However, most previous work on this approach adopts the transaction-level or handshake-level of granularity, i.e., the CUDs can be stopped only when a transaction or a handshake operation is completed. The granulations at these levels are often too coarse when a transaction or a handshake operation requires a large number of cycles to complete. In this paper, we present a novel debug mechanism, called the Protocol Agency Mechanism (PAM), which allows the breakpoint-based debug technique to be applied at the cycle- level granularity. The PAM can deal with transaction invalidation as well as protocol violation that may occur when a system is stopped and resumed. Experimental results show that the area overhead of the PAM is quite small and the performance impact on the system is negligible.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092589","","Clocks;IP networks;Interrupters;Protocols;System-on-chip;Transform coding;Transmitters","silicon;system-on-chip","CUD;PAM;Si;SoC;breakpoint-based debug technique;circuits under debug mechanism;cycle level granularity;handshake-level operation;normal operations;protocol agency mechanism;transaction-level operation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Opportunities for energy efficient computing: A study of inexact general purpose processors for high-performance and big-data applications","Duben, P.; Schlachter, J.; Parishkrati; Yenugula, S.; Augustine, J.; Enz, C.; Palem, K.; Palmer, T.N.","AOPP, Univ. of Oxford, Oxford, UK","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","764","769","In this paper, we demonstrate that disproportionate gains are possible through a simple devise for injecting inexactness or approximation into the hardware architecture of a computing system with a general purpose template including a complete memory hierarchy. The focus of the study is on energy savings possible through this approach in the context of large and challenging applications. We choose two such from different ends of the computing spectrum-the IGCM model for weather and climate modeling which embodies significant features of a high-performance computing workload, and the ubiquitous PageRank algorithm used in Internet search. In both cases, we are able to show in the affirmative that an inexact system outperforms its exact counterpart in terms of its efficiency quantified through the relative metric of operations per virtual Joule (OPVJ)-a relative metric that is not tied to particular hardware technology. As one example, the IGCM application can be used to achieve savings through inexactness of (almost) a factor of 3 in energy without compromising the quality of the forecast, quantified through the forecast error metric, in a noticeable manner. As another example finding, we show that in the case of PageRank, an inexact system is able to outperform its exact counterpart by close to a factor of 1.5 using the OPVJ metric.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092489","","Atmospheric modeling;Computational modeling;Hardware;Measurement;Meteorology;Numerical models;Predictive models","Big Data;Internet;microprocessor chips;parallel processing;power aware computing;ubiquitous computing","IGCM application;IGCM model;Internet search;OPVJ metric;PageRank;big-data applications;climate modeling;complete memory hierarchy;computing spectrum;computing system;energy efficient computing;forecast error metric;hardware architecture;high performance applications;high-performance computing workload;inexact general purpose processors;operations per virtual Joule;ubiquitous PageRank algorithm;weather modeling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"On-chip network-enabled many-core architectures for computational biology applications","Majumder, T.; Pande, P.P.; Kalyanaraman, A.","Dept. of Electr. Eng., Indian Inst. of Technol. Delhi, New Delhi, India","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","259","264","Computational molecular biology applications are at the heart of the backend processing in cyber-physical systems when applied to domains such as drug discovery, personalized medicine and genetic disease risk assessment. These applications are characterized by the preponderance of data and computational complexity, and yet require reasonably fast processing in order to have any meaningful impact. As such, hardware acceleration for these applications have generated a lot of research interest. In this paper, we discuss the superiority of Network-on-Chip (NoC)-enabled many-core platforms over other conventional platforms in both the quantum of speedup achieved and the amount of energy consumed. We hence posit that research in NoC-enabled platforms for CPS applications will be a major enabler of future scientific and medical breakthroughs.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092392","","Acceleration;Computer architecture;Field programmable gate arrays;Hardware;Kernel;Phylogeny;Topology","biology computing;multiprocessing systems;network-on-chip","NoC-enabled platforms;computational biology applications;computational molecular biology applications;cyber-physical systems;onchip network-enabled many-core architectures","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Efficient software implementation of ring-LWE encryption","de Clercq, R.; Roy, S.S.; Vercauteren, F.; Verbauwhede, I.","Dept. of Electr. Eng., KU Leuven, Leuven, Belgium","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","339","344","Present-day public-key cryptosystems such as RSA and Elliptic Curve Cryptography (ECC) will become insecure when quantum computers become a reality. This paper presents the new state of the art in efficient software implementations of a post-quantum secure public-key encryption scheme based on the ring-LWE problem. We use a 32-bit ARM Cortex-M4F microcontroller as the target platform. Our contribution includes optimization techniques for fast discrete Gaussian sampling and efficient polynomial multiplication. Our implementation beats all known software implementations of ring-LWE encryption by a factor of at least 7. We further show that our scheme beats ECC-based public-key encryption schemes by at least one order of magnitude. At medium-term security we require 121 166 cycles per encryption and 43 324 cycles per decryption, while at a long-term security we require 261 939 cycles per encryption and 96 520 cycles per decryption. Gaussian sampling is done at an average of 28.5 cycles per sample.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092411","discrete Gaussian sampling;number theoretic transform;post-quantum secure;public-key encryption;ring learning with errors (ring-LWE);software implementation","Encryption;Gaussian distribution;Indexes;Polynomials;Registers;Software;Table lookup","Gaussian processes;optimisation;public key cryptography;sampling methods","ARM Cortex-M4F microcontroller;ECC;RSA;decryption;elliptic curve cryptography;fast discrete Gaussian sampling;medium-term security;optimization techniques;polynomial multiplication;post-quantum secure public-key encryption scheme;public-key cryptosystems;quantum computers;ring-LWE encryption;software implementation;word length 32 bit","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Topology identification for smart cells in modular batteries","Steinhorst, S.; Lukasiewycz, M.","TUM CREATE, Singapore, Singapore","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1249","1252","This paper proposes an approach to automatically identifying the topological order of smart cells in modular batteries. Emerging smart cell architectures enable battery management without centralized control by coordination of activities via communication. When connecting smart cells in series to form a battery pack, the topological order of the cells is not known and it cannot be automatically identified using the available communication bus. This order, however, is of particular importance for several battery management functions, including temperature control and active cell balancing which relate properties of the cells and their location. Therefore, this paper presents a methodology to automatically identify a topological order on the smart cells in a battery pack using a hybrid communication approach, involving both the communication and the balancing layer of the smart cell architecture. A prototypie implementation on a development platform shows the feasibility and scalability of the approach.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092581","","Batteries;Computer architecture;Microcontrollers;Network topology;Scalability;System-on-chip;Topology","battery management systems;secondary cells;smart power grids;temperature control","active cell balancing;battery management functions;hybrid communication approach;lithium-ion batteries;modular battery pack;smart cell architecture;temperature control;topology identification","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Tackling the bottleneck of delay tables in 3D ultrasound imaging","Ibrahim, A.; Hager, P.; Bartolini, A.; Angiolini, F.; Arditi, M.; Benini, L.; De Micheli, G.","LSI, EPFL, Lausanne, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1683","1688","3D ultrasound imaging is quickly becoming a reference technique for high-quality, accurate, expressive diagnostic medical imaging. Unfortunately, its computation requirements are huge and, today, demand expensive, power-hungry, bulky processing resources. A key bottleneck is the receive beamforming operation, which requires the application of many permutations of fine-grained delays among the digitized received echoes. To apply these delays in the digital domain, in principle large tables (billions of coefficients) are needed, and the access bandwidth to these tables can reach multiple TB/s, meaning that their storage both on-chip and off-chip is impractical. However, smarter implementations of the delay generation function, including forgoing the tables altogether, are possible. In this paper we explore efficient strategies to compute the delay function that controls the reconstruction of the image, and present a feasibility analysis for an FPGA platform.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092663","","Computer architecture;Delays;Field programmable gate arrays;Imaging;Three-dimensional displays;Transducers;Ultrasonic imaging","array signal processing;biomedical ultrasonics;echo;field programmable gate arrays;image reconstruction;medical image processing","3D ultrasound imaging;FPGA platform;beamforming operation;bulky processing resource;delay smarter implementation;diagnostic medical imaging;digital domain;echo digitization;fine-grained delay table;generation function;image reconstruction;power-hungry","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"The federated scheduling of constrained-deadline sporadic DAG task systems","Baruah, S.","Univ. of North Carolina at Chapel Hill, Chapel Hill, NC, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1323","1328","In the federated approach to multiprocessor scheduling, a task is either restricted to execute upon a single processor (as in partitioned scheduling), or has exclusive access to any processor upon which it may execute. Earlier studies concerning the federated scheduling of task systems represented using the sporadic DAG model were restricted to implicit-deadline task systems; the research reported here extends this study to the consideration of task systems represented using the more general constrained-deadline sporadic DAG model.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092597","","Analytical models;Computational modeling;Partitioning algorithms;Schedules;Scheduling;Scheduling algorithms","directed graphs;processor scheduling","constrained-deadline sporadic DAG model;constrained-deadline sporadic DAG task systems;directed acyclic graph;federated approach;federated scheduling;implicit-deadline task systems;multiprocessor scheduling;task systems","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Schedulability bound for integrated modular avionics partitions","Jung-Eun Kim; Abdelzaher, T.; Lui Sha","Univ. of Illinois at Urbana-Champaign, Urbana, IL, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","37","42","In the avionics industry, as a hierarchical scheduling architecture Integrated Modular Avionics System has been widely adopted for its isolating capability. In practice, in an early development phase, a system developer does not know much about task execution times, but only task periods and IMA partition information. In such a case the schedulability bound for a task in a given partition tells a developer how much of the execution time the task can have to be schedulable. Once the developer knows the bound, then the developer can deal with any combination of execution times under the bound, which is safe in terms of schedulability. We formulate the problem as linear programming that is commonly used in the avionics industry for schedulability analysis, and compare the bound with other existing ones which are obtained with no period information.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092355","","Aerospace electronics;Industries;Job shop scheduling;Linear programming;Optimal scheduling;Real-time systems;Schedules","aerospace industry;avionics;linear programming;scheduling","IMA partition;avionics industry;hierarchical scheduling architecture;integrated modular avionics system;linear programming;schedulability bound","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Fast eye diagram analysis for high-speed CMOS circuits","Ahmadyan, S.N.; Chenjie Gu; Natarajan, S.; Chiprout, E.; Vasudevan, S.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1377","1382","We present an efficient technique for analyzing eye diagrams of high speed CMOS circuits in the presence of non-idealities like noise and jitter. Our method involves geometric manipulations of the eye diagram topology to find area within the eye contours. We introduce random tree based simulations as an approach to computing the desired area. We typically show 20× speedup in generating the eye diagram as compared to the state-of-the-art Monte Carlo simulation based eye diagram analysis. For the same number of samples, Monte Carlo produces an eye diagram that is 8.51% smaller than the ideal eye diagram. We generate an eye diagram that is 53.52% smaller than the ideal eye, showing a 47% improvement in quality.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092606","Eye diagram analysis;Nonlinear analog circuits;Random tree optimization;Signal Integrity","Eyelids;Integrated circuit modeling;Jitter;Monte Carlo methods;Noise;Semiconductor device modeling;Trajectory","CMOS integrated circuits;Monte Carlo methods;high-speed integrated circuits","Monte Carlo simulation;eye contours;eye diagram topology;fast eye diagram analysis;geometric manipulations;high-speed CMOS circuits;random tree based simulations","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A new approximate adder with low relative error and correct sign calculation","Junjun Hu; Weikang Qian","Joint Inst., Shanghai Jiao Tong Univ., Shanghai, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1449","1454","Conventional precise adders need long delay and large power consumption to obtain accurate results. However, in recognition of the error tolerance of some applications such as multimedia processing and machine learning, a few recent works proposed approximate adders that generate inaccurate results occasionally to reduce the delay and power consumption. However, existing approximate adders rarely control the relative error and the potential sign error of the calculation results. In this paper, we propose a novel approximate adder that exploits the generate signals for carry speculation. Furthermore, we introduce a very low-cost error reduction module to effectively control the maximal relative error and a low-overhead sign correction module to fix the sign errors. Compared to the conventional adders, our adder is up to 4.3x faster and saves 47% power for a 32bit addition. Compared to the existing approximate adders, our adder significantly reduces the maximal relative error and ensures correct sign calculation with comparable area, delay, and power consumption.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092618","","Adders;Bismuth;Delays;Error analysis;Generators;Power demand;Silicon","adders;error analysis","approximate adder;carry speculation;correct sign calculation;delay reduction;error reduction module;error tolerance recognition;low-overhead sign correction module;machine learning;multimedia processing;potential sign error;power consumption;relative error","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Initial transient response of oscillators with long settling time","Brachtendorf, H.G.; Bittner, K.","Univ. of Appl. Sci. of Upper Austria, Hagenberg, Austria","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1162","1167","The initial transient response of oscillators with high quality factor Q such as quartz crystal oscillators is orders of magnitudes larger than the period of oscillation. Therefore numerical solution by standard techniques of the underlying system of ordinary differential algebraic equations (DAEs) resulting from Kirchhoff's current and voltage laws is run time inefficient. In this paper numerical techniques for the calculation of the initial transient response and steady state solution are investigated. The efficiency results from reformulating the underlying system of ordinary DAEs by a suitable system of partial DAEs, known as multirate PDE, and from suitable finite difference time domain (FDTD) methods with small numerical dissipation of energy. Unlike Harmonic Balance the waveforms are free of spurious oscillations, caused by the non-compactness of the trigonometric polynomials.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092563","Hilbert transformation;initial transient response and steady state;multirate PDE method;optimal estimation of instantaneous frequency;oscillator simulation;quartz crystal oscillators;trigonometric BDF methods","Eigenvalues and eigenfunctions;Frequency estimation;Harmonic analysis;Mathematical model;Oscillators;Radio frequency;Steady-state","Q-factor;crystal oscillators;differential algebraic equations;finite difference time-domain analysis;polynomials;transient response","DAE;FDTD methods;Kirchhoff's current laws;Kirchhoff's voltage laws;differential algebraic equations;finite difference time domain methods;high quality factor Q;long settling time;multirate PDE;numerical dissipation;numerical techniques;oscillators transient response;quartz crystal oscillators;trigonometric polynomials","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Statistical library characterization using belief propagation across multiple technology nodes","Li Yu; Saxena, S.; Hess, C.; Elfadel, I.A.M.; Antoniadis, D.; Boning, D.","Massachusetts Inst. of Technol., Cambridge, MA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1383","1388","In this paper, we propose a novel flow to enable computationally efficient statistical characterization of delay and slew in standard cell libraries. The distinguishing feature of the proposed method is the usage of a limited combination of output capacitance, input slew rate and supply voltage for the extraction of statistical timing metrics of an individual logic gate. The efficiency of the proposed flow stems from the introduction of a novel, ultra-compact, nonlinear, analytical timing model, having only four universal regression parameters. This novel model facilitates the use of maximum-a-posteriori belief propagation to learn the prior parameter distribution for the parameters of the target technology from past characterizations of library cells belonging to various other technologies, including older ones. The framework then utilises Bayesian inference to extract the new timing model parameters using an ultra-small set of additional timing measurements from the target technology. The proposed method is validated and benchmarked on several production-level cell libraries including a state-of-the-art 14-nm technology node and a variation-aware, compact transistor model. For the same accuracy as the conventional lookup-table approach, this new method achieves at least 15x reduction in simulation runs.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092607","","Delays;Integrated circuit modeling;Libraries;Logic gates;Silicon compounds;Standards","Bayes methods;logic circuits;logic gates;maximum likelihood estimation;regression analysis","Bayesian inference;logic gate;lookup-table approach;maximum-a-posteriori belief propagation;multiple technology nodes;output capacitance;prior parameter distribution;production-level cell libraries;size 14 nm;statistical library characterization;statistical timing metrics;ultra-compact nonlinear analytical timing model;universal regression parameters;variation-aware compact transistor model","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Models for deterministic execution of real-time multiprocessor applications","Poplavko, P.; Socci, D.; Bourgos, P.; Bensalem, S.; Bozga, M.","VERIMAG, Univ. Grenoble Alpes, Grenoble, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1665","1670","With the proliferation of multi-cores in embedded real-time systems, many industrial applications are being (re-)targeted to multiprocessor platforms. However, exactly reproducible data values at the outputs as function of the data and timing of the inputs is less trivial to realize in multiprocessors, while it can be imperative for various practical reasons. Also for parallel platforms it is harder to evaluate the task utilization and ensure schedulability, especially for end-to-end communication timing constraints and aperiodic events. Based upon reactive system extensions of Kahn process networks, we propose a model of computation that employs synchronous events and event priority relations to ensure deterministic execution. For this model, we propose an online scheduling policy and establish a link to a well-developed scheduling theory. We also implement this model in publicly available prototype tools and evaluate them on state-of-the art multi-core hardware, with a streaming benchmark and an avionics case study.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092660","","Generators;Processor scheduling;Program processors;Real-time systems;Schedules;Semantics;Servers","avionics;multiprocessing systems;parallel processing;processor scheduling;real-time systems","Kahn process network;aperiodic events;avionics case study;deterministic execution;embedded real-time systems;end-to-end communication timing constraints;event priority relations;multicore hardware;online scheduling policy;parallel platforms;reactive system extension;real-time multiprocessor applications;schedulability;streaming benchmark;synchronous events;task utilization","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Joint affine transformation and loop pipelining for mapping nested loop on CGRAs","Shouyi Yin; Dajiang Liu; Leibo Liu; Shaojun Wei; Yike Guo","Inst. of Microelectron., Tsinghua Univ., Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","115","120","Coarse-Grained Reconfigurable Architectures (CGRAs) are the promising architectures with high performance, high power- efficiency and attractions of flexibility. The computation-intensive portions of application, i.e. loops, are often implemented on CGRAs for acceleration. The loop pipelining techniques are usually used to exploit the parallelism of loops. However, for nested loops, the existing loop pipelining methods often result in poor hardware utilization and low execution performance. To tackle this problem, this paper makes two contributions: 1) a pipelining-beneficial affine transformation method which can optimize the initiation interval (II) of nested loop and enable multiple loop pipelines merging; 2) a multi-pipeline merging method which can improve hardware utilization further. The experimental results show that our approach can improve the performance of nested loop by up to 56% on average, as compared to the state-of-the-art techniques.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092368","CGRA;affine transformation;loop pipelining;polyhedral model;reconfigurable computing","Merging;Pipeline processing;Pipelines;Registers;Routing;Strips","affine transforms;parallel architectures;pipeline processing;reconfigurable architectures","CGRA;acceleration;coarse-grained reconfigurable architectures;computation-intensive portions;hardware utilization;joint affine transformation;loop pipelining methods;mapping nested loop;multipipeline merging method;multiple loop pipelines;parallel computing architecture;pipelining-beneficial method","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Real-time capable CAN to AVB ethernet gateway using frame aggregation and scheduling","Herber, C.; Richter, A.; Wild, T.; Herkersdorf, A.","Inst. for Integrated Syst., Tech. Univ. Munchen, Munich, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","61","66","Ethernet is a key technology to satisfy the communication requirements of future automotive embedded systems. Audio/Video Bridging (AVB) Ethernet is a set of IEEE standards that allows synchronous and time-sensitive communication. It is the favored candidate for backbone and camera applications, but is not expected to replace Controller Area Network (CAN). Instead, both have to coexist in future architectures. No research has been conducted regarding CAN to AVB gateways, and approaches for similar protocols are either not fit or inefficient. In this paper, we present a CAN to AVB Ethernet gateway that allows efficient, real-time capable forwarding. We aggregate and schedule multiple CAN frames into a single AVB Ethernet frame to minimize bandwidth requirements. We evaluate static and dynamic scheduling approaches and determine optimal gateway configurations, showing that the necessary bandwidth reservation is reduced by 72% compared to similar approaches.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092359","Audio/Video Bridging;Controller Area Network;automotive electronics;gateway","Automotive engineering;Bandwidth;Delays;Logic gates;Payloads;Protocols;Real-time systems","automotive electronics;controller area networks;internetworking;local area networks;network servers;protocols;scheduling","CAN;Ethernet gateway;IEEE standards;audio/video bridging Ethernet;automotive embedded systems;controller area network;dynamic scheduling;frame aggregation;protocols;static scheduling;synchronous communication;time-sensitive communication","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"MatEx: Efficient transient and peak temperature computation for compact thermal models","Pagani, S.; Jian-Jia Chen; Shafique, M.; Henkel, J.","Dept. of Embedded Syst. (CES), Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1515","1520","In many core systems, run-time scheduling decisions, such as task migration, core activations/deactivations, voltage/frequency scaling, etc., are typically used to optimize the resource usages. Such run-time decisions change the power consumption, which can in turn result in transient temperatures much higher than any steady-state scenarios. Therefore, to be thermally safe, it is important to evaluate the transient peaks before making resource management decisions. This paper presents a method for computing these transient peaks in just a few milliseconds, which is suited for run-time usage. This technique works for any compact thermal model consisting in a system of first-order differential equations, for example, RC thermal networks. Instead of using regular numerical methods, our algorithm is based on analytically solving the differential equations using matrix exponentials and linear algebra. This results in a mathematical expression which can easily be analyzed and differentiated to compute the maximum transient temperatures. Moreover, our method can also be used to efficiently compute all transient temperatures for any given time resolution without accuracy losses. We implement our solution as an open-source tool called MatEx. Our experimental evaluations show that the execution time of MatEx for peak temperature computation can be bounded to no more than 2.5 ms for systems with 76 thermal nodes, and to no more than 26.6 ms for systems with 268 thermal nodes, which is three orders of magnitude faster than the state-of-the-art for the same settings.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092629","","Computational modeling;Differential equations;Mathematical model;Power demand;Steady-state;Thermal conductivity;Transient analysis","differential equations;matrix algebra;microprocessor chips;power aware computing","MatEx;compact thermal models;core activations;core deactivations;first-order differential equations;frequency scaling;linear algebra;many core systems;matrix exponentials;run-time scheduling decisions;task migration;transient and peak temperature computation;voltage scaling","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Formal consistency checking over specifications in natural languages","Rongjie Yan; Chih-Hong Cheng; Yesheng Chai","State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1677","1682","Early stages of system development involve outlining desired features such as functionality, availability, or usability. Specifications are derived from these features that concretize vague ideas presented in natural languages. The challenge for the verification and validation of specifications arises from the syntax and semantic gap between different representations and the need of automatic tools. In this paper, we present a requirement-consistency maintenance framework to produce consistent representations. The first part is the automatic translation from natural languages describing functionalities to formal logic with an abstraction of time. It extends pure syntactic parsing by adding semantic reasoning and the support of partitioning input and output variables. The second part is the use of synthesis techniques to examine if the requirements are consistent in terms of realizability. When the process fails, the formulas that cause the inconsistency are reported to locate the problem.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092662","","Biomedical monitoring;Cognition;Dictionaries;Grammar;Natural languages;Semantics;Syntactics","computational linguistics;formal logic;formal specification;formal verification;inference mechanisms;natural languages;program compilers","automatic translation;availability;formal consistency checking;formal logic;functionality;natural languages;requirement-consistency maintenance framework;semantic gap;semantic reasoning;specification validation;specification verification;syntactic parsing;synthesis techniques;system development;usability","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Event-driven and sensorless photovoltaic system reconfiguration for electric vehicles","Xue Lin; Yanzhi Wang; Pedram, M.; Jaemin Kim; Chang, N.","Univ. of Southern California, Los Angeles, CA, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","19","24","This work investigates the problem of increasing the electrical energy generation efficiency of photovoltaic (PV) systems on electrical vehicles (EVs). The PV cell modules of an onboard PV system are mounted on the rooftop, hood, trunk, and door panels of an EV to fully make use of the vehicle surface areas. However, due to the non-uniform distribution and rapid change of solar irradiance, an onboard PV system suffers from significant efficiency degradation. To address this problem, this work borrows the dynamic PV array reconfiguration architecture in previous work with the accommodation of the rapidly changing solar irradiance in the onboard scenario. Most importantly, this work differs from previous work in that (i) we propose an event-driven PV array reconfiguration framework replacing the periodic reconfiguration framework in previous work to reduce the computation and energy overhead of the PV array reconfiguration; (ii) we provide a sensorless (and also event-driven) PV array reconfiguration framework, which further reduces the cost of a vehicular PV system, by proposing a solar irradiance estimation algorithm for obtaining the instantaneous solar irradiance level on each PV cell module. Experimental results demonstrate significant performance enhancement and energy overhead reduction.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092352","","Arrays;Insulated gate bipolar transistors;Microprocessors;Power generation;Switches;Vehicles","building integrated photovoltaics;electric vehicles;roofs;solar cell arrays;solar radiation","EV door panel mounted onboard PV system;EV hood mounted onboard PV system;EV rooftop mounted onboard PV system;EV trunk mounted onboard PV system;PV cell module array;electric vehicle performance enhancement;electrical energy generation efficiency;energy overhead reduction;event-driven PV system reconfiguration;sensorless photovoltaic system reconfiguration;solar irradiance estimation algorithm;solar irradiance nonuniform distribution","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Reliable information extraction for single trace attacks","Banciu, V.; Oswald, E.; Whitnall, C.","Dept. of Comput. Sci., Univ. of Bristol, Bristol, UK","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","133","138","Side-channel attacks using only a single trace crucially rely on the capability of reliably extracting side-channel information (e.g. Hamming weights of intermediate target values) from traces. In particular, in original versions of simple power analysis (SPA) or algebraic side channel attacks (ASCA) it was assumed that an adversary can correctly extract the Hamming weight values for all the intermediates used in an attack. Recent developments in error tolerant SPA style attacks relax this unrealistic requirement on the information extraction and bring renewed interest to the topic of template building or training suitable machine learning classifiers. In this work we ask which classifiers or methods, if any, are most likely to return the true Hamming weight among their first (say s) ranked outputs. We experiment on two data sets with different leakage characteristics. Our experiments show that the most suitable classifiers to reach the required performance for pragmatic SPA attacks are Gaussian templates, Support Vector Machines and Random Forests, across the two data sets that we considered. We found no configuration that was able to satisfy the requirements of an error tolerant ASCA in case of complex leakage.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092371","","Correlation;Hamming weight;Pragmatics;Radio frequency;Support vector machines;Training;Training data","cryptography;learning (artificial intelligence);support vector machines","ASCA;Gaussian templates;Hamming weights;SVM;algebraic side channel attacks;complex leakage;data sets;error tolerant SPA style attacks;information extraction reliability;intermediate target values;leakage characteristics;machine learning classifiers;random forests;simple power analysis;single trace attacks;support vector machines;template building","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Power-efficient accelerator allocation in adaptive dark silicon many-core systems","Khan, M.U.K.; Shafique, M.; Henkel, J.","Dept. of Embedded Syst., Karlsruhe Inst. of Technol., Karlsruhe, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","916","919","Modern many-core systems in the dark silicon era face the predicament of underutilized resources of the chip due to power constraints. Therefore, hardware accelerators are becoming popular as they can overcome this problem by exercising a part of the program on dedicated custom logic in an energy efficient way. However, efficient accelerator usage poses numerous challenges, like adaptations for accelerator's sharing schedule on the many-core systems under run-time varying scenarios. In this work, we propose a power-efficient accelerator allocation scheme for adaptive many-core systems that maximally utilizes and dynamically allocates a shared accelerator to competing cores, such that deadlines of the executing applications are met and the total power consumption of the overall system is minimized. The experimental results demonstrate power minimization and high accelerator utilization for a many-core system.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092518","","Acceleration;Computer architecture;Hardware;Power demand;Resource management;Software;Time-frequency analysis","circuit CAD;elemental semiconductors;silicon","Si;adaptive dark silicon many-core systems;high accelerator;power consumption;power minimization;power-efficient accelerator allocation","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Ageing simulation of analogue circuits and systems using adaptive transient evaluation","Salfelder, F.; Hedrich, L.","Dept. of Comput. Sci., Goethe-Univ. Frankfurt a. M., Frankfurt, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1261","1264","Simulating ageing effects in analogue circuits requires both ageing models and a circuit simulator which is capable of a stress dependent, ageing and recovery aware model evaluation during long term transient simulation. Common approaches on reliability simulation often involve aged models, age precomputation, or lookup tables instead of integrated ageing simulation using memory aware ageing models. Long term transient ageing simulation enhances reliability simulation. This paper presents a framework to model and simulate ageing effects using an adaptive two-times evaluation scheme. This integrates full ageing effect models into behavioural device models. In addition, we introduce semantics for modelling stress levels and ageing parameters in hardware description languages. Our approach is a fully integrated simulation solution, enabling correct and efficient simulation of ageing systems over their lifetimes. We demonstrate how transistor level ageing effects critically affect the operation of a circuit. Our examples incorporate ageing monitors, redundant parts, and self-repair functionality into analogue systems.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092584","","Adaptation models;Aging;Computational modeling;Integrated circuit modeling;Reliability;Stress;Transient analysis","analogue circuits;circuit simulation;hardware description languages;stress analysis;transient analysis","adaptive transient evaluation;adaptive two-times evaluation scheme;ageing effect simulation;analogue circuit;behavioural device model;hardware description language;lookup table;memory aware ageing model;recovery aware model evaluation;self-repair functionality;stress levels modelling;transient ageing simulation;transistor level ageing effect","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Analysis of Ethernet-switch traffic shapers for in-vehicle networking applications","Thangamuthu, S.; Concer, N.; Cuijpers, P.J.L.; Lukkien, J.J.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","55","60","Switched Ethernet has been proposed as network technology for automotive and industrial applications. IEEE AVB is a collection of standards that specifies (among other elements) a set of network traffic shaping mechanisms (i.e., rules to regulate the traffic flow) to have guaranteed Quality of Service for Audio/Video traffic. However, in-vehicle control applications like advanced driver-assistance systems require much lower latencies than provided by this standard. Within the context of IEEE TSN (Time Sensitive Networking), three new traffic shaping mechanisms are considered, named Burst Limiting, Time Aware and Peristaltic shaper respectively. In this paper we explain and compare these shapers, we examine their worst case end-to-end latencies analytically and we investigate their behavior through a simulation of a particular setup. We show that the shapers hardly satisfy the requirements for 100Mbps Ethernet, but can come close under further restrictions. We also show the impact the shapers have on AVB traffic.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092358","Ethernet switching;IEEE 802.1AVB;IEEE 802.1TSN;In Vehicle Networks","Delays;Interference;Ports (Computers);Schedules;Standards;Streaming media;Synchronization","IEEE standards;local area networks;on-board communications;quality of service;telecommunication switching;telecommunication traffic","Ethernet-switch traffic shaper analysis;IEEE AVB;IEEE TSN;audio-video bridging;audio-video traffic;automotive application;burst limiting;end-to-end latency;in-vehicle networking application;industrial application;peristaltic shaper mechanism;quality of service;time aware mechanism;time sensitive networking","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Online binding of applications to multiple clock domains in shared FPGA-based systems","Samie, F.; Bauer, L.; Chih-Ming Hsieh; Henkel, J.","Dept. of Embedded Syst. (CES), Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","25","30","Modern FPGA-based platforms provide multiple clock domains and their frequencies can be changed at runtime by using PLLs and clock multiplexers. This is especially beneficial for platforms that run several applications simultaneously (e.g. modern wireless sensor nodes that are shared by multiple users), as different processing modules may be fed by different clock frequencies at different time windows. However, since the number of clock domains on a platform is limited, several processing modules need to share the same clock domain. In this paper, we study the problem of binding multiple applications to multiple clock domains, such that the latest finishing time of any application (i.e. the makespan) is minimized. We present an Integer Linear Programming (ILP) formulation and then propose a novel algorithm that (i) quickly identifies those applications that are dominated by others (and thus can be ignored without losing optimality) and that (ii) uses the ascending property of the optimal binding to reduce the search space. The experimental results show up to 17% makespan reduction compared to state-of-the-art. The overhead when executing on a low-power SmartFusion2 SoC equipped with an ARM Cortex-M3 core is on average 8.9 ms, i.e. our algorithm is suitable for runtime decisions.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092353","","Clocks;Field programmable gate arrays;Hardware;Phase locked loops;Runtime;Time-frequency analysis","clocks;field programmable gate arrays;integer programming;linear programming;low-power electronics;multiplexing equipment;phase locked loops;system-on-chip","ARM Cortex-M3 core;ILP formulation;PLL;ascending property;clock frequencies;clock multiplexers;integer linear programming formulation;low-power SmartFusion2 SoC;makespan reduction;modern wireless sensor nodes;multiple clock domains;multiple users;online binding;optimal binding;processing modules;runtime decisions;shared FPGA-based systems","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A deblocking filter hardware architecture for the high efficiency video coding standard","Diniz, C.M.; Shafique, M.; Dalcin, F.V.; Bampi, S.; Henkel, J.","Inf. Inst., Fed. Univ. of Rio Grande do Sul (UFRGS), Porto Alegre, Brazil","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1509","1514","The new deblocking filter (DF) tool of the next generation High Efficiency Video Coding (HEVC) standard is one of the most time consuming algorithms in video decoding. In order to achieve real-time performance at low-power consumption, we developed a hardware accelerator for this filter. This paper proposes a high throughput hardware architecture for HEVC deblocking filter employing hardware reuse to accelerate filtering decision units with a low area cost. Our architecture achieves either higher or equivalent throughput (4096×2048 @ 60 fps) with 5X-6X lower area compared to state-of-the-art deblocking filter architectures.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092628","Deblocking Filter;HEVC coding;Hardware Architecture","Clocks;Computer architecture;Decoding;Encoding;Field programmable gate arrays;Filtering;Hardware","decoding;filtering theory;video coding","HEVC deblocking filter;deblocking filter tool;hardware accelerator;hardware reuse;next generation HEVC standard;next generation high efficiency video coding standard;video decoding","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Memristor based computation-in-memory architecture for data-intensive applications","Hamdioui, S.; Lei Xie; Hoang Anh Du Nguyen; Taouil, M.; Bertels, K.; Corporaal, H.; Hailong Jiao; Catthoor, F.; Wouters, D.; Eike, L.; van Lunteren, J.","Comput. Eng., Delft Univ. of Technol., Delft, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1718","1725","One of the most critical challenges for today's and future data-intensive and big-data problems is data storage and analysis. This paper first highlights some challenges of the new born Big Data paradigm and shows that the increase of the data size has already surpassed the capabilities of today's computation architectures suffering from the limited bandwidth, programmability overhead, energy inefficiency, and limited scalability. Thereafter, the paper introduces a new memristor-based architecture for data-intensive applications. The potential of such an architecture in solving data-intensive problems is illustrated by showing its capability to increase the computation efficiency, solving the communication bottleneck, reducing the leakage currents, etc. Finally, the paper discusses why memristor technology is very suitable for the realization of such an architecture; using memristors to implement dual functions (storage and logic) is illustrated.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092668","","Adders;CMOS integrated circuits;Computer integrated manufacturing;Computers;Memory management;Memristors","data handling;memory architecture;memristors","big data paradigm;computation architectures;data analysis;data intensive applications;data size;data storage;energy inefficiency;limited bandwidth;limited scalability;memristor based computation-in-memory architecture;programmability","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Towards a meta-language for the concurrency concern in DSLs","Deantoni, J.; Diallo, I.P.; Teodorov, C.; Champeau, J.; Combemale, B.","Univ. of Nice Sophia Antipolis, Nice, France","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","313","316","Concurrency is of primary interest in the development of complex software-intensive systems, as well as the deployment on modern platforms. Furthermore, Domain-Specific Languages (DSLs) are increasingly used in industrial processes to separate and abstract the various concerns of complex systems. However, reifying the definition of the DSL concurrency remains a challenge. This not only prevents leveraging the concurrency concern of a particular domain or platform, but it also hinders: a) the development of a complete understanding of the DSL semantics; b) the effectiveness of concurrency-aware analysis techniques; c) the analysis of the deployment on parallel architectures. In this paper, we introduce the key ideas leading toward MoCCML, a dedicated meta-language for formally specifying the concurrency concern within the definition of a DSL. The concurrency constraints can reflect the knowledge in a particular domain, but also the constraints of a particular platform. MoCCML comes with a complete language workbench to help a DSL designer in the definition of the concurrency directly within the concepts of the DSL itself, and a generic workbench to simulate and analyze any model conforming to this DSL. MoCCML is illustrated on the definition of an lightweight extension of SDF (Synchronous Data Flow [1]).","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092405","","Analytical models;Automata;Computational modeling;Concurrent computing;DSL;Semantics;Syntactics","concurrency (computers);formal specification;parallel architectures;production engineering computing;specification languages","DSL semantics;MoCCML;SDF;complex software-intensive systems;concurrency concern;concurrency constraints;concurrency-aware analysis techniques;dedicated meta-language;domain-specific languages;formal specification;industrial processes;parallel architectures;synchronous data flow","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"HLC: Software-based half-level-cell flash memory","Han-Yi Lin; Jen-Wei Hsieh","Nat. Taiwan Univ., Taipei, Taiwan","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","936","941","In recent years, flash memory has been widely used in embedded systems, portable devices, and high-performance storage products due to its non-volatility, shock resistance, low power consumption, and high performance natures. To reduce the product cost, multi-level-cell flash memory (MLC) has been proposed; compared with the traditional single-level-cell flash memory (SLC) that only stores one bit of data per cell, each MLC cell can store two or more bits of data. Thus MLC can achieve a larger capacity and reduce the cost per unit. However, MLC also suffers from the degradation in both performance and reliability. In this paper, we try to enhance the reliability and reduce the product cost of flash-memory based storage devices from a totally different perspective. We propose a half-level-cell (HLC) management scheme to manage and reuse the worn-out space in solid-state drives (SSDs); through our management scheme, the system can treat two corrupted pages as a normal page without sacrificing performance and reliability. To the best of our knowledge, this is the first research that reclaims free space by reviving the corrupted pages. The experiment results show that the lifetime of SSD can be extended by 48.54% for the trace of general users applications with our proposed HLC management scheme.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092523","","Ash;Decoding;Error correction codes;Memory management;Particle separators;Performance evaluation;Reliability","embedded systems;flash memories;integrated circuit reliability;software engineering","HLC management scheme;MLC cell;SLC;SSDs;embedded systems;flash-memory based storage devices;high-performance storage products;low power consumption;multilevel-cell flash memory;product cost reduction;reliability;shock resistance;single-level-cell flash memory;software-based half-level-cell flash memory;solid-state drives","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Memory fast-forward: A low cost special function unit to enhance energy efficiency in GPU for big data processing","Eunhyeok Park; Junwhan Ahn; Sungpack Hong; Sungjoo Yoo; Sunggu Lee","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1341","1346","Big data processing, e.g., graph computation and MapReduce, is characterized by massive parallelism in computation and a large amount of fine-grained random memory accesses often with structural localities due to graph-like data dependency. Recently, GPU is gaining more and more attention for servers due to its capability of parallel computation. However, the current GPU architecture is not well suited to big data workloads due to the limited capability of handling a large number of memory requests. In this paper, we present a special function unit, called memory fast-forward (MFF) unit, to address this problem. Our proposed MFF unit provides two key functions. First, it supports pointer chasing which enables computation threads to issue as many memory requests as possible to increase the potential of coalescing memory requests. Second, it coalesces memory requests bound for the same cache block, often due to structural locality, thereby reducing memory traffics. Both pointer chasing and memory request coalescing contribute to reducing memory stall time as well as improving the real utilization of memory bandwidth, by removing duplicate memory traffics, thereby improving performance and energy efficiency. Our experiments with graph computation algorithms and real graphs show that the proposed MFF unit can improve the energy efficiency of GPU in graph computation by average 54.6% at a negligible area cost.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092600","","Arrays;Big data;Graphics processing units;Instruction sets;Memory management;Registers","Big Data;cache storage;graphics processing units;parallel processing;power aware computing","GPU;MFF unit;big data processing;cache block;coalescing memory requests;computation threads;energy efficiency;graph computation algorithms;memory fast-forward unit;memory stall reduction;memory traffic reduction;parallel computation;pointer chasing;structural locality","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A symbolic system synthesis approach for hard real-time systems based on coordinated SMT-solving","Biewer, A.; Andres, B.; Gladigau, J.; Schaub, T.; Haubelt, C.","Corp. Sector Res., Robert Bosch GmbH, Schwieberdingen, Germany","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","357","362","We propose an SMT-based system synthesis approach where the logic solver performs static binding and routing while the background theory solver computes global time-triggered schedules. In contrast to previous work, we assign additional time to the logic solver in order to refine the binding and routing such that the background theory solver is more likely to find a feasible schedule within a reasonable amount of time. We show by experiments that this coordination of the two solvers results in a considerable reduction of the overall synthesis time.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092414","","Computer architecture;Encoding;Ports (Computers);Processor scheduling;Real-time systems;Routing;Schedules","computability;network routing;network synthesis;real-time systems","background theory solver;coordinated SMT-solving;global time-triggered schedules;hard real-time systems;logic solver;satisfiability modulo theories;static binding;static routing;symbolic system synthesis approach;synthesis time","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Big-data streaming applications scheduling with online learning and concept drift detection","Kanoun, K.; Van Der Schaar, M.","Embedded Syst. Lab. (ESL), EPFL, Lausanne, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1547","1550","Several techniques have been proposed to adapt Big-Data streaming applications to resource constraints. These techniques are mostly implemented at the application layer and make simplistic assumptions about the system resources and they are often agnostic to the system capabilities. Moreover, they often assume that the data streams characteristics and their processing needs are stationary, which is not true in practice. In fact, data streams are highly dynamic and may also experience concept drift, thereby requiring continuous online adaptation of the throughput and quality to each processing task. Hence, existing solutions for Big-Data streaming applications are often too conservative or too aggressive. To address these limitations, we propose an online energy-efficient scheduler which maximizes the QoS (i.e., throughput and output quality) of Big-Data streaming applications under energy and resources constraints. Our scheduler uses online adaptive reinforcement learning techniques and requires no offline information. Moreover, our scheduler is able to detect concept drifts and to smoothly adapt the scheduling strategy. Our experiments realized on a chain of tasks modeling real-life streaming application demonstrate that our scheduler is able to learn the scheduling policy and to adapt it such that it maximizes the targeted QoS given energy constraint as the Big-Data characteristics are dynamically changing.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092635","","Data mining;Dynamic scheduling;Heuristic algorithms;Learning (artificial intelligence);Quality of service;Throughput","Big Data;learning (artificial intelligence);quality of service;scheduling","QoS;application layer;big-data streaming applications scheduling;concept drift;concept drift detection;continuous online adaptation;data streams characteristics;online adaptive reinforcement learning techniques;online energy-efficient scheduler;resource constraints;scheduling policy","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A ultra-low-power FPGA based on monolithically integrated RRAMs","Gaillardon, P.-E.; Xifan Tang; Sandrini, J.; Thammasack, M.; Omam, S.R.; Sacchetto, D.; Leblebici, Y.; De Micheli, G.","Swiss Fed. Inst. of Technol., Lausanne, Switzerland","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","1203","1208","Field Programmable Gate Arrays (FPGAs) rely heavily on complex routing architectures. The routing structures use programmable switches and account for a significant share in the total area, delay and power consumption numbers. With the ability of being monolithically integrated with CMOS chips, Resistive Random Access Memories (RRAMs) enable high-performance routing architectures through the replacement of Static Random Access Memory (SRAM)-based programming switches. Exploiting the very low on-resistance state achievable by RRAMs as well as the improved tolerance to power supply reduction, RRAM-based routing multiplexers can be used to significantly reduce the power consumption of FPGA systems with no performance compromises. By evaluating the opportunities of ultra-low-power RRAM-based FPGAs at the system level, we see an improvement of 12%, 26% and 81% in area, delay and power consumption at a mature technology node.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092570","","CMOS integrated circuits;Delays;Field programmable gate arrays;Multiplexing;Random access memory;Routing;Table lookup","CMOS memory circuits;SRAM chips;field programmable gate arrays;low-power electronics;monolithic integrated circuits;network routing;resistive RAM;switches","CMOS chips;FPGA system power consumption;RRAM-based routing multiplexers;SRAM-based programming switches;complex routing architectures;field programmable gate arrays;high-performance routing architectures;monolithically integrated RRAM;power consumption numbers;power supply reduction;programmable switches;resistive random access memories;routing structures;static random access memory-based programming switches;total area;total delay;ultralow-power RRAM-based FPGAs","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Path selection based acceleration of conditionals in CGRAs","Radhika, S.H.R.; Shrivastava, A.; Hamzeh, M.","Arizona State Univ., Tempe, AZ, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","121","126","Coarse Grain Reconfigurable Arrays (CGRAs) are promising accelerators capable of achieving high performance at low power consumption. While CGRAs can efficiently accelerate loop kernels, accelerating loops with control flow (loops with if-then-else structures) is quite challenging. Existing techniques use predication to handle control flow execution - in which they execute operations from both the paths, but commit only the result of operations from the path taken by branch at run time. However, this results in inefficient resource usage and therefore poor mapping and lower acceleration. The state-of-the-art dual issue scheme fetches instructions from both the paths, but executes only the ones from the correct path but this scheme has an overhead in instruction fetch bandwidth. In this paper, we propose a solution in which after resolving the branching condition, we fetch and execute instructions only from the path taken by branch. Experimental results show that our solution achieves 34.6% better performance and 52.1% lower energy consumption on an average compared to state of the art dual issue scheme.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092369","","Acceleration;Delays;Field programmable gate arrays;Hardware;Kernel;Registers;Resource management","power aware computing;programmable logic arrays;reconfigurable architectures","CGRA;branching condition;control flow execution;dual issue scheme;inefficient resource usage;instruction fetch bandwidth;loop kernel acceleration;low power consumption;path selection based conditional acceleration","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A robust authentication methodology using physically unclonable functions in DRAM arrays","Hashemian, M.S.; Singh, B.; Wolff, F.; Weyer, D.; Clay, S.; Papachristou, C.","Dept. of EECS, Case Western Reserve Univ., Cleveland, OH, USA","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","647","652","The high availability of DRAM in either embedded or stand-alone form make it a target for counterfeit attacks. In this paper, we propose a robust authentication methodology against counterfeiting. The authentication is performed by exploiting the intrinsic process variation in write reliability of DRAM cells. Extensive Monte Carlo simulations performed in HSPICE show that the proposed authentication methodology provides high uniqueness of 50.01% average inter-die Hamming distance and good robustness under temporal fluctuations in supply voltage, temperature, and ageing effect over a 10-year lifetime.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092469","","Aging;Authentication;Capacitors;Delays;High definition video;Random access memory;Robustness","DRAM chips;copy protection","DRAM arrays;ageing effect;counterfeit attack;intrinsic process variation;physically unclonable function;robust authentication method;supply voltage fluctuation;temperature fluctuation;write reliability","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"A small non-volatile write buffer to reduce storage writes in smartphones","Mungyu Son; Sungkwang Lee; Kyungho Kim; Sungjoo Yoo; Sunggu Lee","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","713","718","Storage write behavior in mobile devices, e.g., smartphones, is characterized by frequent overwrites of small data. In our work, we first demonstrate a small non-volatile write buffer is effective in coalescing such overwrites to reduce storage writes. We also present how to make the best use of write buffer resource the size of which is limited by the requirement of small form factor. We present two new methods, shadow tag and SQLite-aware buffer management both of which aim at identifying hot storage data to keep in the write buffer. We also investigate the storage behavior of multiple mobile applications and show that their interference can reduce the effectiveness of write buffer. In order to resolve this problem, we propose a new dynamic buffer allocation method. We did experiments with real mobile applications running on a smartphone and a Flash memory-based storage system and obtained average 56.2% and 50.2% reduction in storage writes in single and multiple application runs, respectively.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092480","","Buffer storage;Databases;Flash memories;Mobile communication;Nonvolatile memory;Smart phones","flash memories;mobile computing;smart phones;storage allocation","SQLite-aware buffer management;dynamic buffer allocation method;flash memory-based storage system;hot storage data identification;mobile devices;multiple mobile applications;nonvolatile write buffer;shadow tag;smartphones;storage write behavior;write buffer resource","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Accelerating complex brain-model simulations on GPU platforms","Nguyen, H.A.D.; Al-Ars, Z.; Smaragdos, G.; Strydis, C.","Lab. of Comput. Eng. Fac. of EE, Delft Univ. of Technol., Delft, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","974","979","The Inferior Olive (IO) in the brain, in conjunction with the cerebellum, is responsible for crucial sensorimotor-integration functions in humans. In this paper, we simulate a computationally challenging IO neuron model consisting of three compartments per neuron in a network arrangement on GPU platforms. Several GPU platforms of the two latest NVIDIA GPU architectures (Fermi, Kepler) have been used to simulate large-scale IO-neuron networks. These networks have been ported on 4 diverse GPU platforms and implementation has been optimized, scoring 3x speedups compared to its unoptimized version. The effect of GPU L1-cache and thread block size as well as the impact of numerical precision of the application on performance have been evaluated and best configurations have been chosen. In effect, a maximum speedup of 160x has been achieved with respect to a reference CPU platform.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092530","","Brain modeling;Computational modeling;Computer architecture;Graphics processing units;Instruction sets;Mathematical model;Nerve fibers","brain;graphics processing units;medical computing;parallel architectures","Fermi architecture;GPU L1-cache;GPU platforms;Kepler architecture;NVIDIA GPU architectures;cerebellum;complex brain-model simulations;inferior olive;large-scale IO-neuron network simulation;network arrangement;numerical precision;performance evaluation;reference CPU platform;sensorimotor-integration functions;thread block size","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"Enabling vertical wormhole switching in 3D NoC-Bus hybrid systems","Changlin Chen; Enachescu, M.; Cotofana, S.D.","Comput. Eng., Delft Univ. of Technol., Delft, Netherlands","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2015","20150423","2015","","","507","512","In Networks-on-Chip (NoC) systems Wormhole Switching (WS) enables lower packet transmission latency and requires less silicon real estate than the Packet Switching (PS). However, enabling vertical WS in conventional 3D NoC-Bus hybrid systems requires a large amount of TSVs, which have low yield in state of the art 3D stacking technology. In this paper, we alleviate this issue by introducing a Bus Virtual Channel (VC) Allocation (BVA) mechanism, which assigns to at most one cross layer packet a free input VC in its target router before injecting it into the bus. In this way, a routing path is reserved by the head flit, and the rest of the packet flits can be WS transmitted through the vertical buses. Given that VC allocation is performed only once per packet per hop BVA can be performed in such a way that it doesn't become a system bottleneck. We evaluated our proposal with both synthetic and real application traffics and the experimental results indicate that when vertical WS is implemented, the bus critical path length is reduced by at least 31% and the average packet transmission latency is reduced by at least 22%, when compared with conventional pipelined bus or TDMA bus based systems. Moreover, the area cost and power consumption of the output buffer incident to the bus are reduced by 47% and 43%, respectively.","","978-3-9815-3704-8","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7092441","3D NoC-Bus hybrid system;Bus virtual channel allocation;Pipelined bus;Wormhole Switching","Data communication;Delays;Resource management;Silicon;Three-dimensional displays;Through-silicon vias;Time division multiple access","channel allocation;multiprocessor interconnection networks;network routing;network-on-chip;system buses","3D NoC-bus hybrid systems;3D stacking technology;BVA mechanism;NoC systems;TSV;VC allocation;bus critical path length;bus virtual channel allocation mechanism;cross layer packet;head flit;networks-on-chip systems;packet flits;packet switching;packet transmission latency;power consumption;routing path;silicon real estate;target router;vertical buses;wormhole switching","","0","","","","","9-13 March 2015","","IEEE","IEEE Conference Publications"
"State of the art verification methodologies in 2015","Crone, A.; Bringmann, O.; Chevallaz, C.; Dickman, B.; Esen, V.; Rohleder, M.","","Design, Automation & Test in Europe Conference & Exhibition (DATE), 2011","20110505","2011","","","1","1","Summary form only given. In the last few years, the industry has seen acceleration in the evolution of verification methodologies. While the industry focus has been on enabling a standard based approach to help today's challenges, one can wonder what is needed to prepare us self for the further verification challenges. The expert panelist will discuss the many aspects of verification methodologies, the requirements and predictions for verification methodologies needed 4-5 years from now on.","1530-1591","978-1-61284-208-0","","10.1109/DATE.2011.5763215","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5763215","","","formal verification","State of the art verification methodologies","","0","","","","","14-18 March 2011","","IEEE","IEEE Conference Publications"
