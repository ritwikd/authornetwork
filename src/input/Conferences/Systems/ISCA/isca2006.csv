"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&queryText%3DComputer+Architecture%2C+2006.+ISCA+%2706.",2015/06/23 15:54:42
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN","ISBN","EISBN","DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"33rd International Symposium on Computer Architecture - Cover","","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","c1","c1","Presents the front cover of the proceedings.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.2","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635926","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"Cooperative Caching for Chip Multiprocessors","Jichuan Chang; Sohi, G.S.","Dept. of Comput. Sci., Wisconsin Univ., Madison, WI","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","264","276","This paper presents CMP cooperative caching, a unified framework to manage a CMP's aggregate on-chip cache resources. Cooperative caching combines the strengths of private and shared cache organizations by forming an aggregate ""shared"" cache through cooperation among private caches. Locally active data are attracted to the private caches by their accessing processors to reduce remote on-chip references, while globally active data are cooperatively identified and kept in the aggregate cache to reduce off-chip accesses. Examples of cooperation include cache-to-cache transfers of clean data, replication-aware data replacement, and global replacement of inactive data. These policies can be implemented by modifying an existing cache replacement policy and cache coherence protocol, or by the new implementation of a directory-based protocol presented in this paper. Our evaluation using full-system simulation shows that cooperative caching achieves an off-chip miss rate similar to that of a shared cache, and a local cache hit rate similar to that of using private caches. Cooperative caching performs robustly over a range of system/cache sizes and memory latencies. For an 8-core CMP with 1MB L2 cache per core, the best cooperative caching scheme improves the performance of multithreaded commercial workloads by 5-11% compared with a shared cache and 4-38% compared with private caches. For a 4-core CMP running multiprogrammed SPEC2000 workloads, cooperative caching is on average 11% and 6% faster than shared and private cache organizations, respectively","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.17","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635958","","Access protocols;Added delay;Aggregates;Cooperative caching;Costs;Proposals;Resource management;Robustness;Wire","cache storage;microprocessor chips;multi-threading;multiprocessing systems;protocols","CMP cooperative caching;accessing processors;cache coherence protocol;cache organizations;cache replacement policy;cache-to-cache transfers;chip multiprocessors;directory-based protocol;memory latency;multiprogrammed SPEC2000 workloads;multithreaded commercial workloads;off-chip miss rate;on-chip cache resources;on-chip references;private caches;replication-aware data replacement","","54","15","35","","","0-0 0","","IEEE","IEEE Conference Publications"
"Bulk Disambiguation of Speculative Threads in Multiprocessors","Ceze, L.; Tuck, J.; Torrellas, J.; Torrellas, J.","Illinois Univ., Urbana-Champaign, IL","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","227","238","Transactional memory (TM), thread-level speculation (TLS), and checkpointed multiprocessors are three popular architectural techniques based on the execution of multiple, cooperating speculative threads. In these environments, correctly maintaining data dependences across threads requires mechanisms for disambiguating addresses across threads, invalidating stale cache state, and making committed state visible. These mechanisms are both conceptually involved and hard to implement. In this paper, we present bulk, a novel approach to simplify these mechanisms. The idea is to hash-encode a thread's access information in a concise signature, and then support in hardware signature operations that efficiently process sets of addresses. Such operations implement the mechanisms described. Bulk operations are inexact but correct, and provide substantial conceptual and implementation simplicity. We evaluate Bulk in the context of TLS using SPECint2000 codes and TM using multithreaded Java workloads. Despite its simplicity, Bulk has competitive performance with more complex schemes. We also find that signature configuration is a key design parameter","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.13","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635955","","Access protocols;Hardware;Java;Multithreading;US Department of Energy;Yarn","Java;checkpointing;file organisation;multi-threading;multiprocessing systems","SPECint2000 codes;bulk disambiguation;bulk operations;checkpointed multiprocessors;hardware signature operations;hash-encode;multithreaded Java;speculative threads;thread-level speculation;transactional memory","","51","10","27","","","0-0 0","","IEEE","IEEE Conference Publications"
"Ensemble-level Power Management for Dense Blade Servers","Ranganathan, P.; Leech, P.; Irwin, D.; Chase, J.","Hewlett Packard, Palo Alto, CA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","66","77","One of the key challenges for high-density servers (e.g., blades) is the increased costs in addressing the power and heat density associated with compaction. Prior approaches have mainly focused on reducing the heat generated at the level of an individual server. In contrast, this paper proposes power efficiencies at a larger scale by leveraging statistical properties of concurrent resource usage across a collection of systems (""ensemble""). Specifically, we discuss an implementation of this approach at the blade enclosure level to monitor and manage the power across the individual blades in a chassis. Our approach requires low-cost hardware modifications and relatively simple software support. We evaluate our architecture through both prototyping and simulation. For workloads representing 132 servers from nine different enterprise deployments, we show significant power budget reductions at performances comparable to conventional systems","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.20","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635941","","Blades;Compaction;Computer architecture;Costs;Energy management;Hardware;Monitoring;Power system management;Software prototyping;Virtual prototyping","cooling;low-power electronics;network servers;thermal management (packaging)","concurrent resource usage;dense blade servers;ensemble-level power management","","59","12","22","","","0-0 0","","IEEE","IEEE Conference Publications"
"Reducing Startup Time in Co-Designed Virtual Machines","Hu, S.; Smith, J.E.","Dept. of Comput. Sci., Wisconsin Univ., Madison, WI","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","277","288","A co-designed virtual machine allows designers to implement a processor via a combination of hardware and software. Dynamic binary translation converts code written for a conventional (legacy) ISA into optimized code for an underlying implementation-specific ISA. Because translation is done dynamically, an important consideration in such systems is the startup time for performing the initial translations. Beginning with a previously proposed co-designed VM that implements the x86 ISA, we study runtime binary translation overhead effects. The co-designed x86 virtual machine is based on an adaptive translation system that uses a basic block translator for initial emulation and a superblock translator for hotspot optimization. We analyze and model VM startup performance via simulation. We observe that non-hotspot emulation via basic block translation is the major part of the startup overhead. To reduce startup translation overhead, we follow the co-designed hardware/software philosophy and propose hardware assists to dramatically accelerate basic block translations. By combining hardware assists with balanced translation strategies, the co-designed translation system reduces runtime overhead significantly and demonstrates very competitive startup performance when compared with conventional processors running a set of Windows application benchmarks","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.33","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635959","","Acceleration;Adaptive systems;Analytical models;Emulation;Hardware;Instruction sets;Performance analysis;Runtime;Virtual machining;Virtual manufacturing","hardware-software codesign;optimising compilers;program interpreters;virtual machines","Windows application benchmarks;adaptive translation system;basic block translator;codesigned virtual machines;dynamic binary translation;hotspot optimization;optimized code;runtime binary translation;runtime overhead;startup translation overhead;superblock translator","","1","","28","","","0-0 0","","IEEE","IEEE Conference Publications"
"Flexible Snooping: Adaptive Forwarding and Filtering of Snoops in Embedded-Ring Multiprocessors","Strauss, K.; Xiaowei Shen; Torrellas, J.","Dept. of Comput. Sci., Illinois Univ., Urbana-Champaign, IL","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","327","338","A simple and low-cost approach to supporting snoopy cache coherence is to logically embed a unidirectional ring in the network of a multiprocessor, and use it to transfer snoop messages. Other messages can use any link in the network. While this scheme works for any network topology, a naive implementation may result in long response times or in many snoop messages and snoop operations. To address this problem, this paper proposes flexible snooping algorithms, a family of adaptive forwarding and filtering snooping algorithms. In these algorithms, a node receiving a snoop request may either forward it to another node and then perform the snoop, or snoop and then forward it, or simply forward it without snooping. The resulting design space offers trade-offs in number of snoop operations and messages, response time, and energy consumption. Our analysis using SPLASH-2, SPECjbb, and SPECweb workloads finds several snooping algorithms that are more cost-effective than current ones. Specifically, our choice for a high-performance snooping algorithm is faster than the currently fastest algorithm while consuming 9-17% less energy; our choice for an energy-efficient algorithm is only 3-6% slower than the previous one while consuming 36-42% less energy","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.21","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635963","","Adaptive filters;Algorithm design and analysis;Broadcasting;Computer science;Delay;Energy consumption;Filtering algorithms;Hardware;Network topology;Protocols","cache storage;multiprocessing systems;multiprocessor interconnection networks;telecommunication network topology","SPECjbb;SPECweb workloads;SPLASH-2;adaptive forwarding;embedded-ring multiprocessors;flexible snooping algorithms;high-performance snooping algorithm;network topology;snoop messages;snoopy cache coherence","","4","1","26","","","0-0 0","","IEEE","IEEE Conference Publications"
"Author index","","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","391","391","The author index contains an entry for each author and coauthor included in the proceedings record.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.11","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635969","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"Computer architecture research and future microprocessors: Where do we go from here?","Patt, Y.","University of Texas at Austin","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","2","2","The document was not made available for publication as part of the conference proceedings.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.15","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635935","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"33rd International Symposium on Computer Architecture - Table of contents","","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","v","ix","Presents the table of contents of the proceedings.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.3","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635929","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"SODA: A Low-power Architecture For Software Radio","Yuan Lin; Hyunseok Lee; Woh, M.; Harel, Y.; Mahlke, S.; Mudge, T.; Chakrabarti, C.; Flautner, K.","Adv. Comput. Archit. Lab., Michigan Univ., Ann Arbor, MI","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","89","101","The physical layer of most wireless protocols is traditionally implemented in custom hardware to satisfy the heavy computational requirements while keeping power consumption to a minimum. These implementations are time consuming to design and difficult to verify. A programmable hardware platform capable of supporting software implementations of the physical layer, or software defined radio, has a number of advantages. These include support for multiple protocols, faster time-to-market, higher chip volumes, and support for late implementation changes. The challenge is to achieve this without sacrificing power. In this paper, we present a design study for a fully programmable architecture, SODA, that supports software defined radio - a high-end signal processing application. Our design achieves high performance, energy efficiency, and programmability through a combination of features that include single-instruction multiple-data (SIMD) parallelism, and hardware optimized for 16bit computations. The basic processing element is an asymmetric processor consisting of a scalar and SIMD pipeline, and a set of distributed scratchpad memories that are fully managed in software. Results show that a four processor design is capable of meeting the throughput requirements of the W-CDMA and 802.11a protocols, while operating within the strict power constraints of a mobile terminal","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.37","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635943","","Computer architecture;Energy consumption;Hardware;Physical layer;Physics computing;Signal design;Signal processing;Software radio;Time to market;Wireless application protocol","parallel architectures;pipeline processing;software radio","SIMD parallelism;SIMD pipeline;asymmetric processor;distributed scratchpad memories;fully programmable architecture;high-end signal processing;low-power architecture;scalar pipeline;single-instruction multiple-data parallelism;software radio","","23","","26","","","0-0 0","","IEEE","IEEE Conference Publications"
"TRAP-Array: A Disk Array Architecture Providing Timely Recovery to Any Point-in-time","Qing Yang; Weijun Xiao; Jin Ren","Dept. of Electr. & Comput. Eng., Rhode Island Univ., Kingston, RI","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","289","301","RAID architectures have been used for more than two decades to recover data upon disk failures. Disk failure is just one of the many causes of damaged data. Data can be damaged by virus attacks, user errors, defective software/firmware, hardware faults, and site failures. The risk of these types of data damage is far greater than disk failure with today's mature disk technology and networked information services. It has therefore become increasingly important for today's disk array to be able to recover data to any point in time when such a failure occurs. This paper presents a new disk array architecture that provides timely recovery to any point-in-time, referred to as TRAP-array. TRAP-array stores not only the data stripe upon a write to the array, but also the time-stamped exclusive-ORs of successive writes to each data block. By leveraging the exclusive-OR operations that are performed upon each block write in today's RAID4/5 controllers, TRAP does not incur noticeable performance overhead. More importantly, TRAP is able to recover data very quickly to any point-in-time upon data damage by tracing back the sequence and history of exclusive-ORs resulting from writes. What is interesting is that TRAP architecture is amazingly space-efficient. We have implemented a prototype TRAP architecture using software at block device level and carried out extensive performance measurements using TPC-C benchmark running on Oracle and Postgress databases, TPC-W running on MySQL database, and file system benchmarks running on Linux and Windows systems. Our experiments demonstrated that TRAP is not only able to recover data to any point-in-time very quickly upon a failure but it also uses less storage space than traditional daily differential backup/snapshot. Compared to the state-of-the-art continuous data protection technologies, TRAP saves disk storage space by one to two orders of magnitude with a simple and a fast encoding algorithm. From an architecture point of view, T- - RAP-array opens up another dimension for storage arrays. It is orthogonal and complementary to RAID in the sense that RAID protects data in the dimension along an array of physical disks while TRAP protects data in the dimension along the time sequence","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.44","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635960","","Computer architecture;Computer errors;Databases;Hardware;History;Microprogramming;Protection;Software performance;Software prototyping;Space technology","RAID;back-up procedures;security of data;system recovery","Linux;MySQL database;Oracle database;Postgress databases;RAID architectures;TPC-C benchmark;TRAP architecture;TRAP-array;Windows systems;data damage;data protection technology;defective software/firmware;disk array architecture;disk failures;disk storage space;disk technology;file system benchmarks;hardware faults;networked information services;site failures;user errors;virus attacks","","8","16","55","","","0-0 0","","IEEE","IEEE Conference Publications"
"Interconnection Networks for Scalable Quantum Computers","Isailovic, N.; Patel, Y.; Whitney, M.; Kubiatowicz, J.","Comput. Sci. Div., California Univ., Berkeley, CA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","366","377","We show that the problem of communication in a quantum computer reduces to constructing reliable quantum channels by distributing high-fidelity EPR pairs. We develop analytical models of the latency, bandwidth, error rate and resource utilization of such channels, and show that 100s of qubits must be distributed to accommodate a single data communication. Next, we show that a grid of teleportation nodes forms a good substrate on which to distribute EPR pairs. We also explore the control requirements for such a network. Finally, we propose a specific routing architecture and simulate the quantum Fourier transform to demonstrate the impact of resource contention","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.24","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635967","","Analytical models;Bandwidth;Computer network reliability;Computer networks;Delay;Distributed computing;Multiprocessor interconnection networks;Paramagnetic resonance;Quantum computing;Telecommunication network reliability","Fourier transforms;data communication;multiprocessor interconnection networks;quantum communication;quantum computing;resource allocation;telecommunication network routing;teleportation","EPR pairs;data communication;interconnection networks;quantum Fourier transform;quantum channels;qubits;resource contention;resource utilization;routing architecture;scalable quantum computers;teleportation nodes","","2","","30","","","0-0 0","","IEEE","IEEE Conference Publications"
"Memory Model = Instruction Reordering + Store Atomicity","Arvind; Maessen, J.-W.","MIT CSAIL, Cambridge, MA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","29","40","We present a novel framework for defining memory models in terms of two properties: thread-local instruction reordering axioms and store atomicity, which describes inter-thread communication via memory. Most memory models have the store atomicity property, and it is this property that is enforced by cache coherence protocols. A memory model with store atomicity is serializable; there is a unique global interleaving of all operations which respects the reordering rules. Our framework uses partially ordered execution graphs; one graph represents many instruction interleavings with identical behaviors. The major contribution of this framework is a procedure for enumerating program behaviors in any memory model with store atomicity. Using this framework, we show that address aliasing speculation introduces new program behaviors; we argue that these new behaviors should be permitted by the memory model specification. We also show how to extend our model to capture the behavior of non-atomic memory models such as SPARCreg TSO","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.26","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635938","","Coherence;Computer architecture;Gold;History;Interleaved codes;Laboratories;Power system modeling;Protocols;Sun;Yarn","graph theory;multi-threading;storage allocation","interthread communication;memory model;partially ordered execution graphs;store atomicity;thread-local instruction reordering","","4","","29","","","0-0 0","","IEEE","IEEE Conference Publications"
"Slackened Memory Dependence Enforcement: Combining Opportunistic Forwarding with Decoupled Verification","Garg, A.; Rashid, M.W.; Huang, M.","Dept. of Electr. & Comput. Eng., Rochester Univ., NY","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","142","154","An efficient mechanism to track and enforce memory dependences is crucial to an out-of-order microprocessor. The conventional approach of using cross-checked load queue and store queue, while very effective in earlier processor incarnations, suffers from scalability problems in modern high-frequency designs that rely on buffering many in-flight instructions to exploit instruction-level parallelism. In this paper, we make a case for a very different approach to dynamic memory disambiguation. We move away from the conventional exact disambiguation strategy and adopt an opportunistic method: we allow loads and stores to access an L0 cache as they are issued out of program order, hoping that with such a laissez-faire approach, most loads actually obtain the right value. To guarantee correctness, they execute a second time in program order to access the non-speculative L1 cache. A discrepancy between the two executions triggers a replay. Such a design completely eliminates the necessity of real-time violation detection and thus avoids the conventional approach's complexity and the associated scalability issue. We show that even a simplistic design can provide similar performance level achieved with a conventional queue-based approach with optimistically-sized queues. When simple, optional optimizations are applied, the performance level is close to that achieved with ideally-sized queues","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.36","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635948","","Application software;Buffer storage;Coherence;Delay;Design optimization;Logic;Microarchitecture;Microprocessors;Out of order;Scalability","cache storage","cache storage;decoupled verification;dynamic memory disambiguation;opportunistic forwarding;slackened memory dependence enforcement","","4","","25","","","0-0 0","","IEEE","IEEE Conference Publications"
"Techniques for Multicore Thermal Management: Classification and New Exploration","Donald, J.; Martonosi, M.","Dept. of Electr. Eng., Princeton Univ.","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","78","88","Power density continues to increase exponentially with each new technology generation, posing a major challenge for thermal management in modern processors. Much past work has examined microarchitectural policies for reducing total chip power, but these techniques alone are insufficient if not aimed at mitigating individual hotspots. The industry's trend has been toward multicore architectures, which provide additional opportunities for dynamic thermal management. This paper explores various thermal management techniques that exploit the distributed nature of multicore processors. We classify these techniques in terms of core throttling policy, whether that policy is applied locally to a core or to the processor as a whole, and process migration policies. We use Turandot and a HotSpot-based thermal simulator to simulate a variety of workloads under thermal duress on a 4-core PowerPCtrade processor. Using benchmarks from the SPEC 2000 suite we characterize workloads in terms of instruction throughput as well as their effective duty cycles. Among a variety of options we find that distributed control-theoretic DVFS alone improves throughput by 2.5times under our test conditions. Our final design involves a PI-based core thermal controller and an outer control loop to decide process migrations. This policy avoids all thermal emergencies and yields an average of 2.6times speedup over the baseline across all workloads","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.39","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635942","","Control systems;Cooling;Hardware;Multicore processing;Operating systems;Rapid thermal processing;Robust control;Taxonomy;Thermal management;Throughput","PI control;computer power supplies;low-power electronics;microprocessor chips;thermal variables control","HotSpot-based thermal simulator;Turandot;core throttling policy;multicore processors;multicore thermal management;outer control loop;pi-based core thermal controller;process migration policies","","107","5","38","","","0-0 0","","IEEE","IEEE Conference Publications"
"Conditional Memory Ordering","von Praun, C.; Cain, H.W.; Jong-Deok Choi; Kyung Dong Ryu","IBM TJ Watson Res. Center, Yorktown Heights, NY","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","41","52","Conventional relaxed memory ordering techniques follow a proactive model: at a synchronization point, a processor makes its own updates to memory available to other processors by executing a memory barrier instruction, ensuring that recent writes have been ordered with respect to other processors in the system. We show that this model leads to superfluous memory barriers in programs with acquire-release style synchronization, and present a combined hardware/software synchronization mechanism called conditional memory ordering (CMO) that reduces memory ordering overhead. CMO is demonstrated on a lock algorithm that identifies those dynamic lock/unlock operations for which memory ordering is unnecessary, and speculatively omits the associated memory ordering instructions. When ordering is required, this algorithm relies on a hardware mechanism for initiating a memory ordering operation on another processor. Based on evaluation using a software-only CMO prototype, we show that CMO avoids memory ordering operations for the vast majority of dynamic acquire and release operations across a set of multithreaded Java workloads, leading to significant speedups for many. However, performance improvements in the software prototype are hindered by the high cost of remote memory ordering. Using empirical data, we construct an analytical model demonstrating the benefits of a combined hardware-software implementation","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.16","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635939","","Analytical models;Costs;Frequency synchronization;Hardware;Java;Lead;Multiprocessing systems;Process control;Software performance;Software prototyping","Java;multi-threading;storage management;synchronisation","conditional memory ordering;hardware-software synchronization;multithreaded Java workloads","","2","","35","","","0-0 0","","IEEE","IEEE Conference Publications"
"Interconnect-Aware Coherence Protocols for Chip Multiprocessors","Liqun Cheng; Muralimanohar, N.; Ramani, K.; Balasubramonian, R.; Carter, J.B.","Sch. of Comput., Utah Univ.","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","339","351","Improvements in semiconductor technology have made it possible to include multiple processor cores on a single die. Chip multiprocessors (CMP) are an attractive choice for future billion transistor architectures due to their low design complexity, high clock frequency, and high throughput. In a typical CMP architecture, the L2 cache is shared by multiple cores and data coherence is maintained among private L1s. Coherence operations entail frequent communication over global on-chip wires. In future technologies, communication between different L1s will have a significant impact on overall processor performance and power consumption. On-chip wires can be designed to have different latency, bandwidth, and energy properties. Likewise, coherence protocol messages have different latency and bandwidth needs. We propose an interconnect composed of wires with varying latency, bandwidth, and energy characteristics, and advocate intelligently mapping coherence operations to the appropriate wires. In this paper, we present a comprehensive list of techniques that allow coherence protocols to exploit a heterogeneous interconnect and evaluate a subset of these techniques to show their performance and power-efficiency potential. Most of the proposed techniques can be implemented with a minimum complexity overhead","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.23","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635964","","Bandwidth;Clocks;Computer architecture;Delay;Energy consumption;Frequency;Integrated circuit interconnections;Protocols;Throughput;Wires","bandwidth allocation;cache storage;communication complexity;microprocessor chips;multiprocessor interconnection networks;protocols","chip multiprocessors;clock frequency;complexity overhead;data coherence;interconnect-aware coherence protocols;on-chip wires;semiconductor technology;transistor architectures","","10","1","43","","","0-0 0","","IEEE","IEEE Conference Publications"
"The future of virtualization technology","Herrod, S.","VMWare","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","352","352","The document was not made available for publication as part of the conference proceedings.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.42","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635965","","","","","","1","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"list-reviewer","","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","xiv","xiv","The conference offers a note of thanks and lists its reviewers.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.34","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635933","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"Tolerating Dependences Between Large Speculative Threads Via Sub-Threads","Colohan, C.B.; Ailamaki, A.; Steffan, J.G.; Mowry, T.C.","Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","216","226","Thread-level speculation (TLS) has proven to be a promising method of extracting parallelism from both integer and scientific workloads, targeting speculative threads that range in size from hundreds to several thousand dynamic instructions and have minimal dependences between them. Recent work has shown that TLS can offer compelling performance improvements for database workloads, but only when targeting much larger speculative threads of more than 50,000 dynamic instructions per thread, with many frequent data dependences between them. To support such large and dependent speculative threads, hardware must be able to buffer the additional speculative state, and must also address the more challenging problem of tolerating the resulting cross-thread data dependences. In this paper we present hardware support for large speculative threads that integrates several previous proposals for TLS hardware. We also introduce support for sub-threads; a mechanism for tolerating cross-thread data dependences by checkpointing speculative execution. When speculation fails due to a violated data dependence, with sub-threads the failed thread need only rewind to the checkpoint of the appropriate sub-thread rather than rewinding to the start of execution; this significantly reduces the cost of mis-speculation. We evaluate our hardware support for large and dependent speculative threads in the database domain and find that the transaction response time for three of the five transactions from TPC-C (on a simulated 4-processor chip-multiprocessor) speedup by a factor of 1.9 to 2.9","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.43","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635954","","Checkpointing;Computer aided instruction;Computer science;Concurrent computing;Delay;Hardware;Parallel processing;Proposals;Transaction databases;Yarn","checkpointing;multi-threading;parallel architectures;transaction processing","TLS hardware;TPC-C;checkpointing speculative execution;cross-thread data dependences;database workloads;frequent data dependences;speculative threads;subthreads;thread-level speculation;transaction response time","","4","","30","","","0-0 0","","IEEE","IEEE Conference Publications"
"Message from the General Chair","","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","x","x","Presents the welcome message from the conference proceedings.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.27","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635930","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"Chisel: A Storage-efficient, Collision-free Hash-based Network Processing Architecture","Hasan, J.; Cadambi, S.; Jakkula, V.; Chakradhar, S.","Sch. of Electr. & Comput. Eng., Purdue Univ., West Lafayette, IN","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","203","215","Longest prefix matching (LPM) is a fundamental part of various network processing tasks. Previously proposed approaches for LPM result in prohibitive cost and power dissipation (TCAMs) or in large memory requirements and long lookup latencies (tries), when considering future line-rates, table sizes and key lengths (e.g., IPv6). Hash-based approaches appear to be an excellent candidate for LPM with the possibility of low power, compact storage, and O(1) latencies. However, there are two key problems that hinder their practical deployment as LPM solutions. First, naive hash tables incur collisions and resolve them using chaining, adversely affecting worst-case lookup-rate guarantees that routers must provide. Second, hash functions cannot directly operate on wildcard bits, a requirement for LPM, and current solutions require either considerably complex hardware or large storage space. In this paper we propose a novel architecture which successfully addresses for the first time, both key problems in hash based LPM - making the following contributions: (1) We architect an LPM solution based upon a recently-proposed, collision-free hashing scheme called Bloomier filter, by eliminating its false positives in a storage efficient way. (2) We propose a novel scheme called prefix collapsing, which provides support for wildcard bits with small additional storage and reduced hardware complexity. (3) We exploit prefix collapsing and key characteristics found in real update traces to support fast and incremental updates, a feature generally not available in collision-free hashing schemes","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.14","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635953","Bloom Filters;Hash Tables;IP Lookup;Longest Prefix Matching.;Packet Classification","Bandwidth;Costs;Delay;Filters;Hardware;Internet;Laboratories;National electric code;Power dissipation;Tree data structures","IP networks;information filters;storage management;table lookup;telecommunication network routing;tree data structures","Bloomier filter;Chisel;IP lookup;TCAM;collision-free hashing scheme;collision-free hashing schemes;hardware complexity;hash functions;hash tables;hash-based network processing architecture;longest prefix matching;lookup latency;packet classification;power dissipation;prefix collapsing;tries","","17","","26","","","0-0 0","","IEEE","IEEE Conference Publications"
"33rd International Symposium on Computer Architecture - Title Page","","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","i","iii","The following topics are dealt with: interconnection networks; memory models; power management; thermal management; multicore; memory access issues; cache design; security processors; network processors; multithreading; dataflow; cache coherence; and quantum computing","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.4","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635927","","","cache storage;data flow computing;multi-threading;multiprocessor interconnection networks;quantum computing;thermal management (packaging)","cache coherence;cache design;dataflow;interconnection network;memory access;memory model;multicore;multithreading;network processor;power management;quantum computing;security processor;thermal management","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"An Integrated Framework for Dependable and Revivable Architectures Using Multicore Processors","Weidong Shi; Lee, H.-H.S.; Falk, Laura; Ghosh, M.","Sch. of Electr. & Comput. Eng., Georgia Inst. of Technol., Atlanta, GA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","102","113","This paper presents a high-availability system architecture called INDRA $an integrated framework for dependable and revivable architecture that enhances a multicore processor (or CMP) with novel security and fault recovery mechanisms. INDRA represents the first effort to create remote attack immune, self-healing network services using the emerging multicore processors. By exploring the property of a tightly-coupled multicore system, INDRA pioneers several concepts. It creates a hardware insulation, establishes finegrained fault monitoring, exploits monitoring/backup concurrency, and facilitates fast recovery services with minimal performance impact. In addition, INDRA's fault/exploit monitoring is implemented in software rather than in hardware logic, thereby providing better flexibility and upgradability. To provide efficient service recovery and thus improve service availability, we propose a novel delta state backup and recovery on-demand mechanism in INDRA that substantially outperforms conventional checkpointing schemes. We demonstrate and evaluate INDRA's capability and performance using real network services and a cycle-level architecture simulator. As indicated by our performance results, INDRA is highly effective in establishing a more dependable system with high service availability using emerging multicore processors","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.8","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635944","","Availability;Computer architecture;Computer science;Computer security;Concurrent computing;Educational institutions;Hardware;Insulation;Multicore processing;Remote monitoring","computer architecture;fault tolerant computing;microprocessor chips;reliability;security of data;system recovery","delta state backup;dependable architecture;fault recovery;fault/exploit monitoring;finegrained fault monitoring;hardware insulation;high-availability system architecture;monitoring/backup concurrency;multicore processors;recovery on-demand;remote attack immunity;revivable architecture;security;self-healing network services","","1","","33","","","0-0 0","","IEEE","IEEE Conference Publications"
"The end of scaling? Revolutions in technology and microarchitecture as we pass the 90 nanometer node","Emma, P.","IBM T. J. Watson Research Center","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","128","128","The document was not made available for publication as part of the conference proceedings.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.41","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635946","","","","","","1","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"A Gracefully Degrading and Energy-Efficient Modular Router Architecture for On-Chip Networks","Jongman Kim; Nicopoulos, C.; Dongkook Park; Narayanan, V.; Yousif, M.S.; Das, C.R.","Dept. of Comput. Sci. & Eng., Pennsylvania State Univ., University Park, PA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","4","15","Packet-based on-chip networks are increasingly being adopted in complex system-on-chip (SoC) designs supporting numerous homogeneous and heterogeneous functional blocks. These network-on-chip (NoC) architectures are required to not only provide ultra-low latency, but also occupy a small footprint and consume as little energy as possible. Further, reliability is rapidly becoming a major challenge in deep sub-micron technologies due to the increased prominence of permanent faults resulting from accelerated aging effects and manufacturing/testing challenges. Towards the goal of designing low-latency, energy-efficient and reliable on-chip communication networks, we propose a novel fine-grained modular router architecture. The proposed architecture employs decoupled parallel arbiters and uses smaller crossbars for row and column connections to reduce output port contention probabilities as compared to existing designs. Furthermore, the router employs a new switch allocation technique known as ""mirroring effect"" to reduce arbitration depth and increase concurrency. In addition, the modular design permits graceful degradation of the network in the event of permanent faults and also helps to reduce the dynamic power consumption. Our simulation results indicate that in an 8 times 8 mesh network, the proposed architecture reduces packet latency by 4-40% and power consumption by 6-20% as compared to two existing router architectures. Evaluation using a combined performance, energy and fault-tolerance metric indicates that the proposed architecture provides 35-50% overall improvement compared to the two earlier routers","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.6","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635936","","Accelerated aging;Degradation;Delay;Energy consumption;Energy efficiency;Manufacturing;Network-on-a-chip;Switches;System-on-a-chip;Telecommunication network reliability","asynchronous circuits;integrated circuit reliability;low-power electronics;network-on-chip;parallel architectures;telecommunication network routing","NoC architectures;SoC;circuit reliability;decoupled parallel arbiters;energy-efficient modular router architecture;gracefully degrading router architecture;mirroring effect;network-on-chip;on-chip networks;switch allocation;system-on-chip","","2","1","29","","","0-0 0","","IEEE","IEEE Conference Publications"
"Officers","","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","xii","xii","Provides a listing of current society officers.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.30","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635932","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"A Scalable Architecture For High-Throughput Regular-Expression Pattern Matching","Brodie, B.C.; Cytron, R.K.; Taylor, D.E.","Exegy, Inc., St. Louis, MO","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","191","202","We present and evaluate an architecture for high-throughput pattern matching of regular expressions. Our approach matches multiple patterns concurrently, responds rapidly to changes in the pattern set, and is well suited for synthesis in an ASIC or FPGA. Our approach is based on a new and easily pipelined state-machine representation that uses encoding and compression techniques to improve density. We have written a compiler that translates a set of regular expressions and optimizes their deployment in the structures used by our architecture. We analyze our approach in terms of its throughput, density, and efficiency. We present experimental results from an implementation in a commodity FPGA, showing better throughput and density than the best known approaches","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.7","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635952","","Application specific integrated circuits;Computer architecture;Computer networks;Encoding;Field programmable gate arrays;Filters;Optimizing compilers;Pattern matching;Postal services;Throughput","optimising compilers;parallel architectures;pattern matching;pattern recognition equipment;pipeline processing;program interpreters","ASIC;FPGA;compiler;compression techniques;encoding;high-throughput pattern matching;pipelined state-machine representation;scalable architecture","","44","7","19","","","0-0 0","","IEEE","IEEE Conference Publications"
"Program Demultiplexing: Data-flow based Speculative Parallelization of Methods in Sequential Programs","Balakrishnan, S.; Sohi, G.S.","Dept. of Comput. Sci., Wisconsin Univ., Madison, WI","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","302","313","We present program demultiplexing (PD), an execution paradigm that creates concurrency in sequential programs by ""demultiplexing"" methods (functions or subroutines). Call sites of a demultiplexed method in the program are associated with handlers that allow the method to be separated from the sequential program and executed on an auxiliary processor. The demultiplexed execution of a method (and its handler) is speculative and occurs when the inputs of the method are (speculatively) available, which is typically far in advance of when the method is actually called in the sequential execution. A trigger, composed of predicates that are based on program counters and memory write addresses, launches the speculative execution of the method on another processor. Our implementation of PD is based on a full-system execution-based chip multi-processor simulator with software to generate triggers and handlers from an x86-program binary. We evaluate eight integer benchmarks from the SPEC2000 suite - programs written in C with no explicit concurrency and/or motivation to create concurrency - and achieve a harmonic mean speedup of 1.8x with our implementation of PD","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.31","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635961","","Algorithms;Application software;Computer aided instruction;Concurrent computing;Counting circuits;Demultiplexing;Multicore processing;Parallel processing;Turning;Yarn","data flow computing;multiprocessing programs;parallel programming;storage allocation","SPEC2000;auxiliary processor;concurrency program;data-flow based speculative parallelization;full-system execution-based chip multiprocessor simulator;memory write addresses;program counters;program demultiplexing;sequential programs;x86-program binary","","14","","50","","","0-0 0","","IEEE","IEEE Conference Publications"
"Quantum Memory Hierarchies: Efficient Designs to Match Available Parallelism in Quantum Computing","Thaker, D.D.; Metodi, T.S.; Cross, A.W.; Chuang, I.L.; Chong, F.T.","Univ. of California, Davis, CA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","378","390","The assumption of maximum parallelism support for the successful realization of scalable quantum computers has led to homogeneous, ""sea-of-qubits"" architectures. The resulting architectures overcome the primary challenges of reliability and scalability at the cost of physically unacceptable system area. We find that by exploiting the natural serialization at both the application and the physical microarchitecture level of a quantum computer, we can reduce the area requirement while improving performance. In particular we present a scalable quantum architecture design that employs specialization of the system into memory and computational regions, each individually optimized to match hardware support to the available parallelism. Through careful application and system analysis, we find that our new architecture can yield up to a factor of thirteen savings in area due to specialization. In addition, by providing a memory hierarchy design for quantum computers, we can increase time performance by a factor of eight. This result brings us closer to the realization of a quantum processor that can solve meaningful problems","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.32","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635968","","Application software;Computer architecture;Concurrent computing;Costs;Design optimization;Microarchitecture;Parallel processing;Physics computing;Quantum computing;Scalability","parallel architectures;parallel memories;quantum computing","memory hierarchy design;microarchitecture level;quantum computing;quantum memory hierarchy;sea-of-qubits architectures;system analysis","","4","","37","","","0-0 0","","IEEE","IEEE Conference Publications"
"Spatial Memory Streaming","Somogyi, S.; Wenisch, T.F.; Ailamaki, A.; Falsafi, B.; Moshovos, A.","Comput. Archit. Lab., Carnegie Mellon Univ., Pittsburgh, PA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","252","263","Prior research indicates that there is much spatial variation in applications' memory access patterns. Modern memory systems, however, use small fixed-size cache blocks and as such cannot exploit the variation. Increasing the block size would not only prohibitively increase pin and interconnect bandwidth demands, but also increase the likelihood of false sharing in shared-memory multiprocessors. In this paper, we show that memory accesses in commercial workloads often exhibit repetitive layouts that span large memory regions (e.g., several kB), and these accesses recur in patterns that are predictable through code-based correlation. We propose spatial memory streaming, a practical on-chip hardware technique that identifies code-correlated spatial access patterns and streams predicted blocks to the primary cache ahead of demand misses. Using cycle-accurate full-system multiprocessor simulation of commercial and scientific applications, we demonstrate that spatial memory streaming can on average predict 58% of LI and 65% of off-chip misses, for a mean performance improvement of 37% and at best 307%","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.38","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635957","","Application software;Bandwidth;Computer architecture;Data structures;Decision support systems;Delay;Hardware;Prefetching;System performance;Technological innovation","cache storage;shared memory systems;spatial data structures","cache blocks;code-correlated spatial access patterns;cycle-accurate full-system multiprocessor simulation;demand misses;memory access patterns;onchip hardware technique;shared-memory multiprocessors;spatial memory streaming","","18","4","32","","","0-0 0","","IEEE","IEEE Conference Publications"
"Design and Management of 3D Chip Multiprocessors Using Network-in-Memory","Feihul Li; Nicopoulos, C.; Richardson, T.; Yuan Xie; Narayanan, V.; Kandemir, M.","Dept. of CSE, Pennsylvania State Univ., University Park, PA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","130","141","Long interconnects are becoming an increasingly important problem from both power and performance perspectives. This motivates designers to adopt on-chip network-based communication infrastructures and three-dimensional (3D) designs where multiple device layers are stacked together. Considering the trends towards increasing use of chip multiprocessing, it is timely to consider 3D chip multiprocessor design and memory networking issues, especially in the context of data management in large L2 caches. The overall goal of this paper is to study the challenges for L2 design and management in 3D chip multiprocessors. Our first contribution is to propose a router architecture and a topology design that makes use of a network architecture embedded into the L2 cache memory. Our second contribution is to demonstrate, through extensive experiments, that a 3D L2 memory architecture generates much better results than the conventional two-dimensional (2D) designs under different number of layers and vertical (inter-wafer) connections. In particular, our experiments show that a 3D architecture with no dynamic data migration generates better performance than a 2D architecture that employs data migration. This also helps reduce power consumption in L2 due to a reduced number of data movements","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.18","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635947","","Cache memory;Computer architecture;Context;Delay;Energy consumption;Integrated circuit interconnections;Memory management;Microprocessors;Network topology;Network-on-a-chip","cache storage;integrated circuit design;microprocessor chips;multiprocessing systems;network routing;network topology;parallel architectures","3D chip multiprocessor design;L2 cache design;data management;network-in-memory;router architecture;topology design","","20","6","39","","","0-0 0","","IEEE","IEEE Conference Publications"
"Architectural Semantics for Practical Transactional Memory","McDonald, A.; Jaewoong Chung; Carlstrom, B.D.; Minh, C.C.; Chafi, H.; Kozyrakis, C.; Olukotun, K.","Comput. Syst. Lab., Stanford Univ., CA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","53","65","Transactional memory (TM) simplifies parallel programming by allowing for parallel execution of atomic tasks. Thus far, TM systems have focused on implementing transactional state buffering and conflict resolution. Missing is a robust hardware/software interface, not limited to simplistic instructions defining transaction boundaries. Without rich semantics, current TM systems cannot support basic features of modern programming languages and operating systems such as transparent library calls, conditional synchronization, system calls, I/O, and runtime exceptions. This paper presents a comprehensive instruction set architecture (ISA) for TM systems. Our proposal introduces three key mechanisms: two-phase commit; support for software handlers on commit, violation, and abort; and full support for open- and closed-nested transactions with independent rollback. These mechanisms provide a flexible interface to implement programming language and operating system functionality. We also show that these mechanisms are practical to implement at the ISA and microarchitecture level for various TM systems. Using an execution-driven simulation, we demonstrate both the functionality (e.g., I/O and conditional scheduling within transactions) and performance potential (2.2times improvement for SPECjbb2000) of the proposed mechanisms. Overall, this paper establishes a rich and efficient interface to foster both hardware and software research on transactional memory","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.9","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635940","","Computer architecture;Computer languages;Hardware;Instruction sets;Operating systems;Parallel programming;Proposals;Robustness;Runtime library;Software libraries","instruction sets;parallel programming","architectural semantics;instruction set architecture;microarchitecture;parallel programming;practical transactional memory","","18","25","37","","","0-0 0","","IEEE","IEEE Conference Publications"
"Distributed Arithmetic on a Quantum Multicomputer","Van Meter, R.; Nemoto, K.; Munro, W.J.; Itoh, Kohei M.","Keio Univ., Kanagawa","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","354","365","We evaluate the performance of quantum arithmetic algorithms run on a distributed quantum computer (a quantum multicomputer). We vary the node capacity and I/O capabilities, and the network topology. The tradeoff of choosing between gates executed remotely, through ""tele-ported gates"" on entangled pairs of qubits (telegate), versus exchanging the relevant qubits via quantum teleportation, then executing the algorithm using local gates (tele-data), is examined. We show that the teledata approach performs better, and that carry-ripple adders perform well when the teleportation block is decomposed so that the key quantum operations can be parallelized. A node size of only a few logical qubits performs adequately provided that the nodes have two transceiver qubits. A linear network topology performs acceptably for a broad range of system sizes and performance parameters. We therefore recommend pursuing small, high-I/O bandwidth nodes and a simple network. Such a machine will run Shor's algorithm for factoring large numbers efficiently","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.19","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635966","","Adders;Arithmetic;Bandwidth;Circuits;Computer architecture;Distributed computing;Network topology;Performance analysis;Quantum computing;Teleportation","distributed arithmetic;performance evaluation;quantum communication;quantum computing;telecommunication network topology;teleportation","I/O capability;carry-ripple adders;distributed arithmetic;distributed quantum computer;high-I/O bandwidth nodes;linear network topology;node capacity;quantum arithmetic algorithms;quantum multicomputer;quantum teleportation;teleportation block;transceiver qubits","","4","","62","","","0-0 0","","IEEE","IEEE Conference Publications"
"Improving Cost, Performance, and Security of Memory Encryption and Authentication","Chenyu Yan; Rogers, B.; Englender, D.; Solihin, D.; Prvulovic, M.","Coll. of Comput., Georgia Inst. of Technol.","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","179","190","Protection from hardware attacks such as snoopers and mod chips has been receiving increasing attention in computer architecture. This paper presents a new combined memory encryption/authentication scheme. Our new split counters for counter-mode encryption simultaneously eliminate counter overflow problems and reduce per-block counter size, and we also dramatically improve authentication performance and security by using the Galois/counter mode of operation (GCM), which leverages counter-mode encryption to reduce authentication latency and overlap it with memory accesses. Our results indicate that the split-counter scheme has a negligible overhead even with a small (32KB) counter cache and using only eight counter bits per data block. The combined encryption/authentication scheme has an IPC overhead of 5% on average across SPEC CPU 2000 benchmarks, which is a significant improvement over the 20% overhead of existing encryption/authentication schemes","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.22","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635951","","Authentication;Computer architecture;Costs;Counting circuits;Cryptography;Data security;Delay;Hardware;Information security;Protection","Galois fields;cache storage;cryptography;memory architecture;message authentication","Galois counter mode of operation;IPC overhead;SPEC CPU 2000 benchmarks;authentication latency;computer architecture;counter-mode encryption;memory accesses;memory encryption;mod chips;snoopers;split counters","","0","3","21","","","0-0 0","","IEEE","IEEE Conference Publications"
"Message from the Program Chair","","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","xi","xi","Presents the welcome message from the conference proceedings.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.28","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635931","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"A Case for MLP-Aware Cache Replacement","Qureshi, M.K.; Lynch, D.N.; Mutlu, O.; Patt, Y.N.","Dept. of Electr. & Comput. Eng., Texas Univ., Austin, TX","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","167","178","Performance loss due to long-latency memory accesses can be reduced by servicing multiple memory accesses concurrently. The notion of generating and servicing long-latency cache misses in parallel is called memory level parallelism (MLP). MLP is not uniform across cache misses - some misses occur in isolation while some occur in parallel with other misses. Isolated misses are more costly on performance than parallel misses. However, traditional cache replacement is not aware of the MLP-dependent cost differential between different misses. Cache replacement, if made MLP-aware, can improve performance by reducing the number of performance-critical isolated misses. This paper makes two key contributions. First, it proposes a framework for MLP-aware cache replacement by using a runtime technique to compute the MLP-based cost for each cache miss. It then describes a simple cache replacement mechanism that takes both MLP-based cost and recency into account. Second, it proposes a novel, low-hardware overhead mechanism called sampling based adaptive replacement (SBAR), to dynamically choose between an MLP-aware and a traditional replacement policy, depending on which one is more effective at reducing the number of memory related stalls. Evaluations with the SPEC CPU2000 benchmarks show that MLP-aware cache replacement can improve performance by as much as 23%","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.5","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635950","","Computer aided software engineering;Costs;Parallel processing;Performance loss;Prefetching;Runtime;Sampling methods;System performance","cache storage;parallel memories;parallel processing","MLP-aware cache replacement;SPEC CPU2000 benchmarks;cache misses;memory level parallelism;multiple memory accesses;runtime technique;sampling based adaptive replacement","","35","2","25","","","0-0 0","","IEEE","IEEE Conference Publications"
"Guidelines for SIGARCH Sponsored Conferences","Patterson, D.A.","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","xvii","xvii","At the business meeting on April 20, 1994 it was voted that SIGARCH adopt this set of guidelines to aid program chairs on matters of policy at SIGARCH sponsored conferences (e.g., ISCA, ASPLOS, and so on). Amendments to the guidelines would be voted on at SIGARCH business meetings. There are several options in these guidelines, so the program chair will report which options were selected in the chair's message that appears in the proceedings. To ensure that the guidelines are part of a tradition that is not forgotten, ACM will include them as part of the conference proceedings of the International Symposium on Computer Architecture (and thereby appear in Computer Architecture News once a year).","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.35","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635934","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"Learning-Based SMT Processor Resource Distribution via Hill-Climbing","Seungryul Choi; Yeung, D.","Dept. of Comput. Sci., Maryland Univ.","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","239","251","The key to high performance in simultaneous multithreaded (SMT) processors lies in optimizing the distribution of shared resources to active threads. Existing resource distribution techniques optimize performance only indirectly. They infer potential performance bottlenecks by observing indicators, like instruction occupancy or cache miss counts, and take actions to try to alleviate them. While the corrective actions are designed to improve performance, their actual performance impact is not known since end performance is never monitored. Consequently, potential performance gains are lost whenever the corrective actions do not effectively address the actual bottlenecks occurring in the pipeline. We propose a different approach to SMT resource distribution that optimizes end performance directly. Our approach observes the impact that resource distribution decisions have on performance at runtime, and feeds this information back to the resource distribution mechanisms to improve future decisions. By evaluating many different resource distributions, our approach tries to learn the best distribution over time. Because we perform learning on-line, learning time is crucial. We develop a hill-climbing algorithm that efficiently learns the best distribution of resources by following the performance gradient within the resource distribution space. This paper conducts an in-depth investigation of learning-based SMT resource distribution. First, we compare existing resource distribution techniques to an ideal learning-based technique that performs learning off-line. This limit study shows learning-based techniques can provide up to 19.2% gain over ICOUNT, 18.0% gain over FLUSH, and 7.6% gain over DCRA across 21 multithreaded workloads. Then, we present an on-line learning algorithm based on hill-climbing. Our evaluation shows hill-climbing provides a 12.4% gain over ICOUNT, 11.3% gain over FLUSH, and 2.4% gain over DCRA across a larger set of 42 multiprogrammed workloads","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.25","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635956","","Computer science;Hardware;Monitoring;Multithreading;Performance gain;Pipelines;Resource management;Runtime;Surface-mount technology;Yarn","learning (artificial intelligence);multi-threading;multiprocessing programs;multiprocessing systems;performance evaluation;pipeline processing;resource allocation","SMT processor resource distribution;active threads;cache miss counts;hill-climbing;instruction occupancy;multiprogrammed workloads;multithreaded workloads;online learning algorithm;performance gradient;shared resources;simultaneous multithreaded processors","","4","","20","","","0-0 0","","IEEE","IEEE Conference Publications"
"33rd International Symposium on Computer Architecture - Copyright","","","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","iv","iv","Copyright and Reprint Permissions: Abstracting is permitted with credit to the source. Libraries may photocopy beyond the limits of US copyright law, for private use of patrons, those articles in this volume that carry a code at the bottom of the first page, provided that the per-copy fee indicated in the code is paid through the Copyright Clearance Center. The papers in this book comprise the proceedings of the meeting mentioned on the cover and title page. They reflect the authors' opinions and, in the interests of timely dissemination, are published as presented and without change. Their inclusion in this publication does not necessarily constitute endorsement by the editors or the Institute of Electrical and Electronics Engineers, Inc.","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.1","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635928","","","","","","0","","","","","17-21 June 2006","","IEEE","IEEE Conference Publications"
"Area-Performance Trade-offs in Tiled Dataflow Architectures","Swanson, S.; Putnam, A.; Mercaldi, M.; Michelson, K.; Petersen, A.; Schwerin, A.; Eggers, S.J.; Oskin, M.","Comput. Sci. & Eng., Washington Univ.","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","314","326","Tiled architectures, such as RAW, SmartMemories, TRIPS, and WaveScalar, promise to address several issues facing conventional processors, including complexity, wire-delay, and performance. The basic premise of these architectures is that larger, higher-performance implementations can be constructed by replicating the basic tile across the chip. This paper explores the area-performance trade-offs when designing one such tiled architecture, WaveScalar. We use a synthesizable RTL model and cycle-level simulator to perform an area/performance pareto analysis of over 200 WaveScalar processor designs ranging in size from 19mm<sup>2</sup> to 575mm<sup>2</sup> and having a 22 FO4 cycle time. We demonstrate that, for multi-threaded workloads, WaveScalar performance scales almost ideally from 19 to 101mm <sup>2</sup> when optimized for area efficiency and from 44 to 202mm<sup>2</sup> when optimized for peak performance. Our analysis reveals that WaveScalar's hierarchical interconnect plays an important role in overall scalability, and that WaveScalar achieves the same (or higher) performance in substantially less area than either an aggressive out-of-order superscalar or Sun's Niagara CMP processor","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.10","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635962","ASIC;Dataflow computing;RTL;WaveScalar","Computer architecture;Computer science;Data communication;Fabrication;Hardware design languages;Microarchitecture;Process design;Space technology;Tiles;Wire","Pareto analysis;data flow computing;multi-threading;parallel architectures","ASIC;CMP processor;RAW;SmartMemories;TRIPS;WaveScalar;area-performance trade-offs;cycle-level simulator;dataflow computing;pareto analysis;synthesizable RTL model;tiled dataflow architectures","","5","1","33","","","0-0 0","","IEEE","IEEE Conference Publications"
"Multiple Instruction Stream Processor","Hankins, R.A.; Chinya, G.N.; Collins, J.D.; Wang, P.H.; Rakvic, R.; Hong Wang; Shen, J.P.","Corporate Technol. Group, Intel Corp., Santa Clara, CA","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","114","127","Microprocessor design is undergoing a major paradigm shift towards multi-core designs, since performance gains come from exploiting thread-level parallelism in the software. To support this trend, we present a novel processor architecture called the multiple instruction stream processing (MISP) architecture. MISP introduces the sequencer as a new category of architectural resource, and defines a canonical set of instructions to support user-level inter-sequencer signaling and asynchronous control transfer. MISP allows an application program to directly manage user-level threads without OS intervention. By supporting the classic cache-coherent shared-memory programming model, MISP does not require a radical shift in the multithreaded programming paradigm. This paper describes the design and evaluation of the MISP architecture for the IA-32 family of microprocessors. Using a research prototype MISP processor built on an IA-32-based multiprocessor system equipped with special firmware, we demonstrate the feasibility of implementing the MISP architecture. We then examine the utility of MISP by (1) assessing the key architectural tradeoffs of the MISP architecture design and (2) showing how legacy multithreaded applications can be migrated to MISP with relative ease","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.29","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635945","","Application software;Computer architecture;Microprocessors;Microprogramming;Multiprocessing systems;Performance gain;Process design;Prototypes;Software performance;Yarn","cache storage;microprocessor chips;multi-threading;parallel architectures;shared memory systems","asynchronous control transfer;cache-coherent shared-memory programming;microprocessor design;multiple instruction stream processor;multithreaded programming;user-level intersequencer signaling","","5","1","27","","","0-0 0","","IEEE","IEEE Conference Publications"
"Balanced Cache: Reducing Conflict Misses of Direct-Mapped Caches","Chuanjun Zhang","Dept. of Comput. Sci. & Electr. Eng., Missouri Univ., Kansas, MO","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","155","166","Level one cache normally resides on a processor's critical path, which determines the clock frequency. Direct-mapped caches exhibit fast access time but poor hit rates compared with same sized set-associative caches due to non-uniform accesses to the cache sets, which generate more conflict misses in some sets while other sets are underutilized. We propose a technique to reduce the miss rate of direct mapped caches through balancing the accesses to cache sets. We increase the decoder length and thus reduce the accesses to heavily used sets without dynamically detecting the cache set usage information. We introduce a replacement policy to direct-mapped cache design and increase the access to the underutilized cache sets with the help of programmable decoders. On average, the proposed balanced cache, or B-cache, achieves 64.5% and 37.8% miss rate reductions on all 26 SPEC2K benchmarks for the instruction and data caches, respectively. This translates into an average IPC improvement of 5.9%. The B-cache consumes 10.5% more power per access but exhibits 2% total memory access related energy saving due to the miss rate reductions and hence the reduction to applications' execution time. Compared with previous techniques that aim at reducing the miss rate of direct-mapped caches, our technique requires only one cycle to access all cache hits and has the same access time of a direct-mapped cache","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.12","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635949","","Bridges;Cities and towns;Clocks;Computer science;Decoding;Delay;Frequency;High performance computing;History;Multiplexing","cache storage;memory architecture","balanced cache;conflict miss reduction;direct-mapped caches;programmable decoders","","1","1","30","","","0-0 0","","IEEE","IEEE Conference Publications"
"The BlackWidow High-Radix Clos Network","Scott, S.; Abts, D.; Kim, J.; Dally, W.J.","Cray Inc., Chippewa Falls, WI","Computer Architecture, 2006. ISCA '06. 33rd International Symposium on","20060710","2006","","","16","28","This paper describes the radix-64 folded-Clos network of the Cray BlackWidow scalable vector multiprocessor. We describe the BlackWidow network which scales to 32Kprocessors with a worst-case diameter of seven hops, and the underlying high-radix router micro architecture and its implementation. By using a high-radix router with many narrow channels we are able to take advantage of the higher pin density and faster signaling rates available in modern ASIC technology. The BlackWidow router is an 800 MHz ASIC with 64 18.75Gb/s bidirectional ports for an aggregate off-chip bandwidth of 2.4Tb/s. Each port consists of three 6.25Gb/s differential signals in each direction. The router supports deterministic and adaptive packet routing with separate buffering for request and reply virtual channels. The router is organized hierarchically (Kim et al., 2005) as an 8times8 array of tiles which simplifies arbitration by avoiding long wires in the arbiters. Each tile of the array contains a router port, its associated buffering, and an 8times8 router subswitch. The router ASIC is implemented in a 90nm CMOS standard cell ASIC technology and went from concept to tapeout in 17 months","1063-6897","0-7695-2608-X","","10.1109/ISCA.2006.40","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1635937","","Application specific integrated circuits;Bandwidth;Costs;Delay;Microarchitecture;Multiprocessor interconnection networks;Network topology;Switches;Synchronization;Tiles","CMOS integrated circuits;application specific integrated circuits;multiprocessing systems;multistage interconnection networks;telecommunication network routing","800 MHz;BlackWidow high-radix Clos network;CMOS standard cell ASIC;Cray BlackWidow scalable vector multiprocessor;adaptive packet routing;deterministic packet routing;high-radix router micro architecture","","36","2","23","","","0-0 0","","IEEE","IEEE Conference Publications"
