"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&queryText%3DEmbedded+Software+.LB.EMSOFT.RB.%2C+2014+International+Conference+on",2015/06/23 15:14:43
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN","ISBN","EISBN","DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Infinite horizon safety controller synthesis through disjunctive polyhedral abstract interpretation","Ravanbakhsh, H.; Sankaranarayanan, S.","Univ. of Colorado, Boulder, CO, USA","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","This paper presents a controller synthesis approach using disjunctive polyhedral abstract interpretation. Our approach synthesizes infinite time-horizon controllers for safety properties with discrete-time, linear plant model and a switching feedback controller that is suitable for time-triggered implementations. The core idea behind our approach is to perform an abstract interpretation over disjunctions of convex polyhedra to identify states that are potentially uncontrollable. Complementing this set yields the set of controllable states, starting from which, the safety property can be guaranteed by an appropriate controller feedback function. Since, a straightforward disjunctive domain is computationally inefficient, we present an abstract domain based on a state partitioning scheme that allows us to efficiently control the complexity of the intermediate representations. Next, we focus on the automatic generation of controller implementation from the abstract interpretation results. We show that a balanced tree approach can yield efficient controller code with guarantees on the worst-case execution time. Finally, we evaluate our approach on a suite of benchmarks, comparing different instantiations with related synthesis tools. The evaluation shows that our approach can successfully synthesize controller implementations for small to medium sized benchmarks.","","","","10.1145/2656045.2656060","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986123","Abstract Interpretation;Controller Synthesis;Hybrid Systems;Safety;Switched Systems","Abstracts;Computational modeling;Lattices;Safety;Semantics;Switches","control engineering computing;control system synthesis;discrete time systems;feedback;infinite horizon;program diagnostics;switching systems (control);trees (mathematics)","automatic controller generation;balanced tree approach;controller code;controller feedback function;convex polyhedra;discrete-time linear plant model;disjunctive polyhedral abstract interpretation;infinite time-horizon safety controller synthesis approach;medium sized benchmarks;safety properties;small sized benchmarks;state partitioning scheme;switching feedback controller;time-triggered implementations;worst-case execution time","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Embedded software reliability for unreliable hardware","Jian-Jia Chen; Shafique, M.","Dept. of Inf., Tech. Univ. Dortmund, Dortmund, Germany","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","1","While advancements in chip manufacturing technology has accelerated the growth of embedded systems, it has revealed serious reliability and robustness challenges at various abstraction levels that threaten the applicability of scaled technologies [2, 3]. These reliability threats arise from multiple sources, and may result in faults in the hardware. Further-more, these faults in the hardware may have catastrophic effects on the correctness of software execution [9, 11, 14]. This is particularly the case for real-time and timing-critical embedded systems involved in safety-, and mission-critical systems [13]. This occurs because traditional software abstraction layers make the fundamental assumption that the underlying hardware platform is error-free, and completely reliable. This is, however, no longer the case. In order to mitigate various reliability threats, besides hardware-level techniques, it is critical to develop and design resiliency at various layers of the embedded software stack [2, 3].","","","","10.1145/2656045.2661649","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986112","","Embedded software;Embedded systems;Hardware;Real-time systems;Software reliability","embedded systems;program diagnostics;safety-critical software;software reliability","catastrophic effects;chip manufacturing technology;embedded software reliability;embedded software stack;hardware-level techniques;mission-critical systems;real-time embedded systems;reliability threats;safety-critical systems;scaled technologies;software abstraction layers;software execution correctness;timing-critical embedded systems;unreliable hardware","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Refinement calculus of reactive systems","Preoteasa, V.; Tripakis, S.","Aalto Univ., Aalto, Finland","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Refinement calculus is a powerful and expressive tool for reasoning about sequential programs in a compositional manner. In this paper we present an extension of refinement calculus for reactive systems. Refinement calculus is based on monotonic predicate transformers, which transform sets of post-states into sets of pre-states. To model reactive systems, we introduce monotonic property transformers, which transform sets of output infinite sequences into sets of input infinite sequences. We show how to model in this semantics refinement, sequential composition, demonic choice, and other semantic properties of reactive systems. We also show how such transformers can be defined by various formalisms such as linear temporal logic formulas (suitable for specifications) and symbolic transition systems (suitable for implementations). Finally, we show how this framework generalizes previous work on relational interfaces to systems with infinite behaviors and liveness properties.","","","","10.1145/2656045.2656068","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986110","","Boolean algebra;Calculus;Input variables;Lattices;Semantics;Syntactics;Transforms","reasoning about programs;refinement calculus;temporal logic","demonic choice;input infinite sequences;linear temporal logic formulas;monotonic predicate transformers;monotonic property transformers;reactive systems;reasoning about sequential programs;refinement calculus;relational interfaces;semantics refinement;sequential composition;symbolic transition systems;transform sets","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"SiPTA: Signal processing for trace-based anomaly detection","Zeinali Zadeh, M.M.; Salem, M.; Kumar, N.; Cutulenco, G.; Fischmeister, S.","Univ. of Waterloo, Waterloo, ON, Canada","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Given a set of historic good traces, trace-based anomaly detection deals with the problem of determining whether or not a specific trace represents a normal execution scenario. Most current approaches mainly focus on application areas outside of the embedded systems domain and thus do not take advantage of the intrinsic properties of this domain. This work introduces SiPTA, a novel technique for offline trace-based anomaly detection that utilizes the intrinsic feature of periodicity found in embedded systems. SiPTA uses signal processing as the underlying processing algorithm. The paper describes a generic framework for mapping execution traces to channels and signals for further processing. The classification stage of SiPTA uses a comprehensive set of metrics adapted from standard signal processing. The system is particularly useful for embedded systems, and the paper demonstrates this by comparing SiPTA with state-of-the-art approaches based on Markov Model and Neural Networks. The paper shows the technical feasibility and viability of SiPTA through multiple case studies using traces from a field-tested hexacopter, a mobile phone platform, and a car infotainment unit. In the experiments, our approach outperformed every other tested method.","","","","10.1145/2656045.2656071","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986114","","Feature extraction;Hidden Markov models;Indexes;Measurement;Signal processing algorithms;Time series analysis;Training","embedded systems;signal classification","Markov Model;SiPTA;car infotainment unit;embedded system domain;execution trace mapping;field-tested hexacopter;mobile phone platform;neural networks;normal execution scenario;offline trace-based anomaly detection;signal processing for trace-based anomaly detection","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Automated software testing of memory performance in embedded GPUs","Chattopadhyay, S.; Eles, P.; Peng, Z.","","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Embedded and real-time software is often constrained by several temporal requirements. Therefore, it is important to design embedded software that meets the required performance goal. The inception of embedded graphics processing units (GPUs) brings fresh hope in developing high-performance embedded software which were previously not suitable for embedded platforms. Whereas GPUs use massive parallelism to obtain high throughput, the overall performance of an application running on embedded GPUs is often limited by memory performance. Therefore, a crucial problem lies in automatically detecting the inefficiency of such software developed for embedded GPUs. In this paper, we propose GUPT, a novel test generation framework that systematically explores and detects poor memory performance of applications running on embedded GPUs. In particular, we systematically combine static analysis with dynamic test generation to expose likely execution scenarios with poor memory performance. Each test case in our generated test suite reports a potential memory-performance issue, along with the detailed information to reproduce the same. We have implemented our test generation framework using GPGPU-Sim, a cycle-accurate simulator and the LLVM compiler infrastructure. We have evaluated our framework for several open-source programs. Our experiments suggest the efficacy of our framework by exposing numerous memory-performance issues in a reasonable time. We also show the usage of our framework in improving the performance of programs for embedded GPUs.","","","","10.1145/2656045.2656047","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986125","","Abstracts;Graphics processing units;Instruction sets;Kernel;Random access memory;Schedules;System-on-chip","embedded systems;graphics processing units;parallel processing;program compilers;program diagnostics;program testing;public domain software","GPGPU-Sim;GUPT;LLVM compiler infrastructure;automated software testing;cycle-accurate simulator;dynamic test generation;embedded GPU;embedded graphics processing units;high-performance embedded software;memory-performance issues;open-source programs;real-time software;static analysis;temporal requirements;test generation framework","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Energy efficient DVFS scheduling for mixed-criticality systems","Pengcheng Huang; Kumar, P.; Giannopoulou, G.; Thiele, L.","Comput. Eng. & Networks Lab., ETH Zurich, Zurich, Switzerland","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Consolidating functionalities with different safety requirements into a common platform gives rise to mixed-criticality systems. The state-of-the-art research has focused on providing heterogeneous timing guarantees for tasks of varying criticality levels. This is achieved by dropping less critical tasks when critical tasks overrun. However, with drastically increased computing requirements and the often battery-operated nature of mixed-criticality systems, energy minimization for such systems is also becoming crucial. In fact, this has already been possible since many modern processors are equipped with the capacity of dynamic voltage and frequency scaling (DVFS), where processor frequency can be reduced at runtime to save energy. We present in this paper the first results known to date on applying DVFS to mixed-criticality systems. We show that DVFS can be used to help critical tasks to meet deadlines by speeding up the processor when they overrun. This will further allow the system to reserve less time budgets for task overrun. Thus, more slack can be explored to reduce the processor frequency to save energy for scenarios when tasks do not overrun. Since overrun is rare, such a strategy can greatly reduce the expected energy consumption for mixed-criticality systems. For solving the energy minimization problem, we formulate a convex program by integrating DVFS with a well-known mixed-criticality scheduling technique - EDF-VD. Furthermore, we present analytical results on this problem and propose an optimal algorithm to solve it. With both theoretical and experimental results, we demonstrate energy savings and various tradeoffs.","","","","10.1145/2656045.2656057","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986119","Criticality;Energy;Mixed;Real-time;Scheduling;Voltage and Frequency Scaling","Dynamic scheduling;Energy consumption;Minimization;Program processors;Runtime;Safety;Timing","convex programming;power aware computing;processor scheduling","EDF-VD;battery-operated mixed-criticality systems;computing requirements;convex program;dynamic voltage and frequency scaling;energy efficient DVFS scheduling;energy minimization;expected energy consumption;heterogeneous timing guarantees;mixed-criticality scheduling technique;optimal algorithm;processor frequency;task criticality levels","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"P-YDS algorithm: An optimal extension of YDS algorithm to minimize expected energy for real-time jobs","Kumar, P.; Thiele, L.","Comput. Eng. & Networks Lab., ETH Zurich, Zurich, Switzerland","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","The YDS algorithm computes a schedule on a DVS-enabled resource to meet deadlines of all jobs and optimally minimize the total energy consumption. The algorithm requires that an exact execution time of each job be known. For settings where execution times are variable or uncertain, stochastic scheduling has been proposed to preferentially accelerate less probable phases of jobs to reduce the expected energy consumption. However, an analogue to the YDS algorithm for the stochastic setting has not been optimally solved. In this paper, we propose the p-YDS algorithm to minimize the expected energy consumption for a set of jobs with arbitrary arrival times, deadlines, and execution times. We then derive the competitive ratio of the YDS algorithm w.r.t. the p-YDS algorithm, for the metric of expected energy consumption. By comparing two optimal algorithms, this ratio specifies the worst-case energy cost of being agnostic to the variability in the execution time of jobs.","","","","10.1145/2656045.2656065","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986120","","Algorithm design and analysis;Energy consumption;Interference;Processor scheduling;Program processors;Real-time systems;Schedules","power aware computing;real-time systems;stochastic processes","DVS-enabled resource;energy minimization;expected energy consumption;p-YDS algorithm;real-time jobs;stochastic scheduling;worst-case energy cost","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Extending typical worst-case analysis using response-time dependencies to bound deadline misses","Hammadeh, Z.A.H.; Quinton, S.; Ernst, R.","Inst. of Comput. & Network Eng. (IDA), Tech. Univ. Braunschweig, Braunschweig, Germany","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Weakly-hard time constraints have been proposed for applications where occasional deadline misses are permitted. Recently, a new approach called Typical Worst-Case Analysis (TWCA) has been introduced which exploits similar constraints to bound response times of systems with sporadic overload. In this paper, we extend that approach for static priority preemptive and non-preemptive scheduling to determine the maximum number of deadline misses for a given deadline. The approach is based on an optimization problem which trades off higher priority interference versus miss count. We formally derive a lattice structure for the possible combinations that lays the ground for an integer linear programming (ILP) formulation. The ILP solution is evaluated showing effectiveness of the approach and far better results than previous TWCA.","","","","10.1145/2656045.2656059","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986118","","Analytical models;Computational modeling;Equations;Interference;Mathematical model;Optimization;Time factors","integer programming;linear programming;performance evaluation;scheduling","ILP formulation;TWCA;bounded deadline misses;bounded response times;high-priority interference;integer linear programming formulation;lattice structure;miss count;optimization problem;response-time dependencies;sporadic overload;static nonpreemptive scheduling;static priority preemptive scheduling;typical worst-case analysis;weakly-hard time constraints","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"CPSGrader: Synthesizing temporal logic testers for auto-grading an embedded systems laboratory","Juniwal, G.; Donze, A.; Jensen, J.C.; Seshia, S.A.","","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","We consider the problem of designing an automatic grader for a laboratory in the area of cyber-physical systems. The goal of this laboratory is to program a robot for specified navigation tasks. Given a candidate student solution (control program for the robot), our grader first checks whether the robot performs the task correctly under a representative set of environment conditions. If it does not, the grader automatically generates feedback hinting at possible errors in the program. The auto-grader is based on a novel notion of constrained parameterized tests based on signal temporal logic (STL) that capture symptoms pointing to success or causes of failure in traces obtained from a realistic simulator. We define and solve the problem of synthesizing constraints on a parameterized test such that it is consistent with a set of reference solutions with and without the desired symptom. The usefulness of our grader is demonstrated using a large data set obtained from an on-campus laboratory-based course at UC Berkeley.","","","","10.1145/2656045.2656053","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986132","","Collision avoidance;Cost accounting;Laboratories;Robot kinematics;Robot sensing systems","courseware;educational courses;embedded systems;robot programming;temporal logic","CPSGrader;UC Berkeley;auto-grading;automatic feedback hinting generation;automatic grader;constrained parameterized tests;cyber-physical systems;embedded system laboratory;navigation tasks;on-campus laboratory-based course;realistic simulator;robot programming;signal temporal STL logic;temporal logic testers","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Parallel many-core avionics systems","Panic, M.; Quinones, E.; Zavkov, P.G.; Hernandez, C.; Abella, J.; Cazorla, F.J.","Univ. Politec. de Catalunya, Barcelona, Spain","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Integrated Modular Avionics (IMA) enables incremental qualification by encapsulating avionics applications into software partitions (SWPs), as defined by the ARINC 653 standard. SWPs, when running on top of single-core processors, provide robust time partitioning as a means to isolate SWPs timing behavior from each other. However, when moving towards parallel execution in many-core processors, the simultaneous accesses to shared hardware and software resources influence the timing behavior of SWPs, defying the purpose of time partitioning to provide isolation among ap-plications. In this paper, we extend the concept of SWP by introducing parallel software partitions (pSWP) specification that describes the behavior of SWPs required when running in a many-core to enable incremental qualification. pSWP are supported by a new hardware feature called guaranteed resource partition (GRP) that defines an execution environment in which SWPs run and that controls interferences in the accesses to shared hardware resources among SWPs such that time composability can be guaranteed.","","","","10.1145/2656045.2656063","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986134","","Aerospace electronics;Hardware;Process control;Program processors;Real-time systems;Timing","avionics;multiprocessing systems;software standards","ARINC 653 standard;GRP;IMA;SWP run;SWP timing behavior isolation;application isolation;avionics application encapsulation;execution environment;guaranteed resource partition;incremental qualification;integrated modular avionics;interference control;many-core processors;pSWP specification;parallel execution;parallel many-core avionics systems;parallel software partitions;robust time partitioning;simultaneous shared hardware source access;simultaneous shared software resource access;single-core processors;time composability","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Real-time multi-core virtual machine scheduling in Xen","Sisu Xi; Meng Xu; Chenyang Lu; Phan, L.T.X.; Gill, C.; Sokolsky, O.; Insup Lee","Cuber-Phys. Syst. Lab., Washington Univ. in St. Louis, St. Louis, MO, USA","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Recent years have witnessed two major trends in the development of complex real-time embedded systems. First, to reduce cost and enhance flexibility, multiple systems are sharing common computing platforms via virtualization technology, instead of being deployed separately on physically isolated hosts. Second, multicore processors are increasingly being used in real-time systems. The integration of real-time systems as virtual machines (VMs) atop common multicore platforms raises significant new research challenges in meeting the real-time performance requirements of multiple systems. This paper advances the state of the art in real-time virtualization by designing and implementing RT-Xen 2.0, a new real-time multicore VM scheduling framework in the popular Xen virtual machine monitor (VMM). RT-Xen 2.0 realizes a suite of real-time VM scheduling policies spanning the design space. We implement both global and partitioned VM schedulers; each scheduler can be configured to support dynamic or static priorities and to run VMs as periodic or deferrable servers. We present a comprehensive experimental evaluation that provides important insights into real-time scheduling on virtualized multicore platforms: (1) both global and partitioned VM scheduling can be implemented in the VMM at moderate overhead; (2) at the VMM level, while compositional scheduling theory shows partitioned EDF (pEDF) is better than global EDF (gEDF) in providing schedulability guarantees, in our experiments their performance is reversed in terms of the fraction of workloads that meet their deadlines on virtualized multicore platforms; (3) at the guest OS level, pEDF requests a smaller total VCPU bandwidth than gEDF based on compositional scheduling analysis, and therefore using pEDF at the guest OS level leads to more schedulable workloads in our experiments; (4) a combination of pEDF in the guest OS and gEDF in the VMM - configured with deferrable server - leads to the highest fraction of schedulab- e task sets compared to other real-time VM scheduling policies; and (5) on a platform with a shared last-level cache, the benefits of global scheduling outweigh the cache penalty incurred by VM migration.","","","","10.1145/2656045.2656061","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986113","Based Methods;CEGAR;Falsification;Hybrid Systems;Multiple Shooting;Simulation","Abstracts;Analytical models;Concrete;Mathematical model;Measurement;Numerical models;Trajectory","cache storage;embedded systems;multiprocessing systems;processor scheduling;virtual machines;virtualisation","RT-Xen 2.0 design;RT-Xen 2.0 implementation;VM migration;VMM level;Xen virtual machine monitor;cache penalty;common multicore platforms;complex real-time embedded system development;compositional scheduling analysis;compositional scheduling theory;computing platform sharing;computing platforms;cost reduction;deferrable servers;dynamic priorities;flexibility enhancement;gEDF;global EDF;global VM schedulers;global scheduling;guest OS level;moderate overhead;multicore processors;multiple systems;pEDF;partitioned EDF;partitioned VM schedulers;periodic servers;real-time VM scheduling policies;real-time multicore VM scheduling framework;real-time multicore virtual machine scheduling;real-time performance requirements;real-time virtualization;schedulable task sets;schedulable workloads;shared last-level cache;static priorities;total VCPU bandwidth;virtualization technology;virtualized multicore platforms","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Supporting read/write applications in embedded real-time systems via suspension-aware analysis","Guangmo Tong; Cong Liu","Dept. of Comput. Sci., Univ. of Texas at Dallas, Dallas, TX, USA","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","In many embedded real-time systems, applications often interact with I/O devices via read/write operations, which may incur considerable suspension delays. Unfortunately, prior analysis methods for validating timing correctness in embedded systems become quite pessimistic when suspension delays are present. In this paper, we consider the problem of supporting two common types of I/O applications in a multiprocessor system, that is, write-only applications and read-write applications. For the write-only application model, we present a much improved analysis technique that results in only O(m) suspension-related utilization loss, where m is the number of processors. For the second application model, we present a flexible I/O placement strategy and a corresponding new scheduling algorithm, which can completely circumvent the negative impact due to read- and write-induced suspension delays. We illustrate the feasibility of the proposed I/O-placement-based schedule via a case study implementation. Furthermore, experiments presented herein show that the improvement with respect to system utilization over prior methods is often significant.","","","","10.1145/2656045.2656072","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986129","I/O;intensive applications;scheduling algorithm;timing validation","Computational modeling;Program processors;Real-time systems;Schedules;Silicon;Suspensions;Writing","computational complexity;embedded systems;multiprocessing systems;real-time systems","I-O applications;I-O devices;I-O-placement-based schedule;O(m) suspension-related utilization loss;embedded real-time systems;flexible I-O placement strategy;multiprocessor system;read-write applications;read-write-induced suspension delays;suspension-aware analysis;write-induced suspension delays;write-only applications","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Computing maximum blocking times with explicit path analysis under non-local flow bounds","Kleinsorge, J.C.; Marwedel, P.","Tech. Univ. Dortmund, Dortmund, Germany","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Worst-case time (WCET) analyses for single tasks are well established and their results ultimately serve the purpose of providing execution time parameters for schedulability analyses. Besides WCET analysis, an important problem is maximum blocking time (MBT) analysis which is essential in deferred preemption schedules for the selection of preemption points. Among the most pressing problems in this context is the need for good path analyses, which are a fundamental bottleneck for selecting these points. Current state of the art relies on ILP-based or severely constrained explicit path analyses, both of which are unsatisfactory in general. In this paper, we propose a general explicit path analysis to compute maximum blocking times, specifically for scheduling policies with deferred preemption. The proposal improves the current state of the art significantly for both WCET and MBT analysis, as it is efficient, accurate, easily extensible and computes path lengths between all program points, without imposing any artificial constraints, and under a general flow bound model, unmatched by other existing explicit path analyses, while significantly outperforming the ILP-based approach. To the best of the authors' knowledge, no explicit path analysis for MBT has been proposed yet.","","","","10.1145/2656045.2656051","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986117","Path Analysis;Static Analysis;Worst;case Execution Time","Accuracy;Analytical models;Computational modeling;Context;Kernel;Mathematical model;Timing","program diagnostics;scheduling","ILP-based approach;ILP-based explicit path analyses;MBT analysis;WCET analysis;artificial constraints;constrained explicit path analyses;execution time parameters;maximum blocking time analysis;nonlocal flow bounds;schedulability analyses;worst-case time analysis","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Schedulability analysis of global memory-predictable scheduling","Alhammad, A.; Pellizzoni, R.","","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","The use of multicore CPUs in real-time systems poses significant challenges in estimating their temporal behavior. A factor that has a large impact on this issue is the contention for access to main memory among multiple cores. To overcome this problem, an execution model called PREM has been previously introduced to co-schedule CPU execution and accesses to main memory without relying on hardware arbiters. In this paper, we provide a global schedulbil-ity analysis for this predictable execution model, and we prove its correctness. We also evaluate the effectiveness of the proposed solution with extensive simulations. The results show a significant advantage of the proposed solution when compared to contention execution in which tasks access main memory unpredictably.","","","","10.1145/2656045.2656070","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986128","","Hardware;Interference;Multicore processing;Processor scheduling;Real-time systems;Schedules;Scheduling","multiprocessing systems;processor scheduling;real-time systems","PREM;contention execution;coschedule CPU execution;global memory-predictable scheduling;global schedulability analysis;multicore CPUs;predictable execution model;real-time systems;schedulability analysis;temporal behavior","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Task mapping in heterogeneous embedded systems for fast completion time","Husheng Zhou; Cong Liu","Dept. of Comput. Sci., Univ. of Texas at Dallas, Dallas, TX, USA","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Graphics processing units are being widely used in embedded systems as they can achieve high performance and energy efficiency. In such systems, the problem of computation and data mapping for multiple applications while minimizing the completion time is quite challenging due to a large size of the policy space, including heterogeneous application characteristics, complex application structure, data communication costs, and data partitioning. To achieve fast competition time, a fine-grain mapping framework that explores a set of critical factors is needed for heterogeneous embedded systems. In this paper, we consider this mapping problem by presenting a theoretical framework that yields an optimal integer programming solution. Moreover, based upon several interesting measurements-based case studies, we design three practical mapping algorithms with low time complexity, each of which explores a specific set of factors that may affect the completion time performance. We evaluated the proposed algorithms by implementing them on a real heterogeneous system and using a large set of popular benchmarks for evaluation. Experimental results demonstrate that our proposed algorithms can achieve up to 30% faster completion time compared to the state-of-the-art mapping techniques, and can perform consistently well across different workloads.","","","","10.1145/2656045.2656074","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986130","GPU;heterogeneousus scheduling","Algorithm design and analysis;Central Processing Unit;Embedded systems;Graphics processing units;Kernel;Partitioning algorithms","computational complexity;embedded systems;graphics processing units;integer programming;performance evaluation;power aware computing;task analysis","completion time minimization;completion time performance;complex application structure;data communication costs;data mapping;data partitioning;energy efficiency;fine-grain mapping framework;graphics processing units;heterogeneous application characteristics;heterogeneous embedded systems;optimal integer programming solution;policy space;practical mapping algorithms;task mapping;time complexity","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Blaming in component-based real-time systems","Gossier, G.; Astefanoaei, L.","INRIA, Montbonnot St. Ismier, France","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","In component-based safety-critical real-time systems it is crucial to determine which component(s) caused the violation of a required system-level safety property, be it to issue a precise alert, or to determine liability of component providers. In this paper we present an approach for blaming in real-time systems whose component specifications are given as timed automata. The analysis is based on a single execution trace violating a safety property P. We formalize blaming using counterfactual reasoning (“what would have been the outcome if component C had behaved correctly?”) to distinguish component failures that actually contributed to the outcome from failures that had no impact on the violation of P. We then show how to effectively implement blaming by reducing it to a model-checking problem for timed automata, and demonstrate the feasibility of our approach on the models of a pacemaker and of a chemical reactor.","","","","10.1145/2656045.2656048","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986115","Logical causality;blaming;failure;model-checking;timed automata","Automata;Clocks;Delays;Indexes;Real-time systems;Safety;Semantics","automata theory;formal verification;object-oriented programming;real-time systems;safety-critical software","blaming;chemical reactor model;component failures;component provider liability;component specifications;component-based safety-critical real-time systems;counterfactual reasoning;execution trace;model-checking problem;pacemaker model;safety property violation;system-level safety property violation;timed automata","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Synthesising optimal timing delays for Timed I/O Automata","Diciolla, M.; Kim, C.H.P.; Kwiatkowska, M.; Mereacre, A.","Dept. of Comput. Sci., Univ. of Oxford, Oxford, UK","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","In many real-time embedded systems, the choice of values for the timing delays can crucially affect the safety or quantitative characteristics of their execution. We propose a parameter synthesis algorithm that finds optimal timing delays guaranteeing that the system satisfies a given quantitative property. As a modelling framework we consider networks of Timed Input/Output Automata (TIOA) with priorities and parametric guards. To express system properties we extend Metric Temporal Logic (MTL) with counting formulas. We implement the algorithm using constraint solving and Monte Carlo sampling, and demonstrate the feasibility of our approach on a simplified model of a pacemaker. We are able to synthesise timing delays that ensure with high probability that energy usage is minimised, while maintaining the basic safety property of the pacemaker.","","","","10.1145/2656045.2656073","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986124","Cardiac Pacemakers;Counting;Parametric Synthesis","Automata;Clocks;Cost accounting;Delays;Indexes;Pacemakers;Time factors","Monte Carlo methods;automata theory;delays;embedded systems;pacemakers;sampling methods;temporal logic;timing","MTL;Monte Carlo sampling;TIOA;constraint solving;energy usage;metric temporal logic;optimal timing delay synthesis;pacemaker safety property;parameter synthesis algorithm;quantitative characteristics;real-time embedded systems;timed I-O automata;timed input-output automata","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Precise piecewise affine models from input-output data","Alur, R.; Singhania, N.","Univ. of Pennsylvania, Philadelphia, PA, USA","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Formal design and analysis of embedded control software relies on mathematical models of dynamical systems, and such models can be hard to obtain. In this paper, we focus on automatic construction of piecewise affine models from input-output data. Given a set of examples, where each example consists of a d-dimensional real-valued input vector mapped to a real-valued output, we want to compute a set of affine functions that covers all the data points up to a specified degree of accuracy, along with a disjoint partitioning of the space of all inputs defined using a Boolean combination of affine inequalities with one region for each of the learnt functions. While traditional machine learning algorithms such as linear regression can be adapted to learn the set of affine functions, we develop new techniques based on automatic construction of interpolants to derive precise guards defining the desired partitioning corresponding to these functions. We report on a prototype tool, MOSAIC, implemented in Matlab. We evaluate its performance using some synthetic data, and compare it against known techniques using data-sets modeling electronic placement process in pick-and-place machines.","","","","10.1145/2656045.2656064","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986111","","Analytical models;Computational modeling;Data models;Linear regression;Mathematical model;Software;Vectors","Boolean functions;affine transforms;embedded systems;formal verification;interpolation;learning (artificial intelligence);mathematics computing;performance evaluation;regression analysis","Boolean combination;MOSAIC;Matlab;affine functions;affine inequalities;automatic interpolant construction;automatic piecewise affine model construction;d-dimensional real-valued input vector;data-set modeling electronic placement process;dynamical systems;embedded control software;formal analysis;formal design;input-output data;linear regression;machine learning algorithms;mathematical models;pick-and-place machines;prototype tool","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Deductive control synthesis for alternating-time logics","Dimitrova, R.; Majumdar, R.","","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Algorithmic design of control laws for continuous systems for complex temporal specifications is a key step toward automatic synthesis of controllers for cyber-physical systems. Current approaches either abstract the dynamical system to a finite-state approximation or search for certificates that imply invariance or reachability properties (barriers and Lyapunov functions, respectively). The first approach is limited by an exponential blow-up in the abstraction process; the second in the properties that can be controlled for. We present a deductive proof system for the control of alternating-time temporal properties on continuous systems. We show that reasoning about temporal logic constraints in ATL*, an expressive branching-time logic that allows for quantification over control strategies, can be reduced effectively to reasoning about combinations of barrier certificates and Lyapunov functions. Our approach enables the application of existing constraint-based techniques for finding barriers and Lyapunov functions to the design of controllers for complex temporal properties, while sidestepping the exponential cost of computing finite-state abstractions.","","","","10.1145/2656045.2656054","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986122","Barrier certificates;Control synthesis;Deductive proof systems;Lyapunov functions","Automata;Cognition;Color;Continuous time systems;Lyapunov methods;Safety;Trajectory","Lyapunov methods;continuous systems;control system synthesis;finite state machines;inference mechanisms;reachability analysis;temporal logic;theorem proving;time-varying systems","ATL;Lyapunov functions;abstraction process;algorithmic control law design;alternating-time logics;alternating-time temporal property control;automatic controller synthesis;complex temporal properties;complex temporal specifications;constraint-based techniques;continuous systems;cyber-physical systems;deductive control synthesis;deductive proof system;dynamical system;expressive branching-time logic;finite-state abstractions;finite-state approximation;reachability properties;reasoning about temporal logic constraints","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"A general approach for expressing infeasibility in Implicit Path Enumeration Technique","Raymond, P.","VERIMAG, Univ. Grenoble Alpes, Grenoble, France","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","9","Static timing analysis aims at computing a guaranteed upper bound to the Worst-Case Execution Time (WCET) of a program. It requires both an accurate modeling of the hardware, and a precise analysis of the program in order to reject infeasible executions (in particular, all infinite ones). For the actual computation of the worst-case execution, most of the existing tools and methods are based on the Implicit Path Enumeration Technique (IPET), which consist in encoding this search into a numerical optimization problem (Integer Linear Programming, ILP). An interest of this approach is that it naturally integrates the loop bounds. It also allows to implicitly prune infeasible paths, as far as they can be expressed using linear constraints. Several works on the subject are using this ability in order to enhance the WCET estimation: they identify specific property patterns (e.g., implications, exclusions) and propose ad hoc translation into numerical constraints. The goal of this paper is to go further than ad hoc reasoning by proposing a general method for translating infeasibility in terms of numerical constraints. It does not address the problem of finding infeasible paths, only the one of characterizing them as precisely as possible. Moreover the paper aims at exploring the limits of the method, and thus, it does not try to enhance the result using additional methods (e.g., graph transformation).","","","","10.1145/2656045.2656046","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986116","Integer Linear Programming;WCET;infeasible path","Avatars;Cognition;Concrete;Image edge detection;Integer linear programming;Linear programming;Radiation detectors","integer programming;linear programming;program diagnostics;reasoning about programs","ILP;IPET;WCET estimation;ad hoc translation;encoding;graph transformation;hardware modeling;implicit path enumeration technique;integer linear programming;numerical optimization problem;static timing analysis;worst-case execution time","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Exponentially timed SADF: Compositional semantics, reductions, and analysis","Katoen, J.-P.; Hao Wu","Software Modelling & Verification Group, RWTH Aachen Univ., Aachen, Germany","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","This paper presents a rigorous compositional semantics for SADF (Scenario-Aware Data Flow), an extension of SDF for scenario-based embedded system design which has its roots in digital signal processing. We show that Markov automata (MA), a novel combination of probabilistic automata and continuous-time Markov decision processes, provides a natural semantics when all execution times are exponential. The semantics is fully compositional, i.e., each SADF agent is modeled by a single automaton which are all put in parallel. We show how stochastic model checking can be used to analyse the MA, yielding measures such as expected time, long-run objectives, throughput, and timed reachability. Using aggressive reduction techniques for Markov automata that are akin to partial-order reduction, scalability of analysis is achieved, and all non-determinism can be eliminated.","","","","10.1145/2656045.2656058","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986109","Compositional semantics;SADF;State space reduction;Stochastic model checking","Detectors;Kernel;Markov processes;Ports (Computers);Probabilistic logic;Semantics;Synchronization","Markov processes;automata theory;data flow computing;decision making;embedded systems;formal verification;signal processing","MA;Markov automata;SADF agent;compositional analysis;compositional reductions;compositional semantics;continuous-time Markov decision processes;digital signal processing;execution times;exponentially timed SADF;natural semantics;partial-order reduction;probabilistic automata;scenario-aware data flow;scenario-based embedded system design;stochastic model checking;timed reachability","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Real-time system support for hybrid structural simulation","Ferry, D.; Bunting, G.; Maqhareh, A.; Prakash, A.; Dyke, S.; Aqrawal, K.; Gill, C.; Chenyang Lu","Dept. of Comput. Sci., Washington Univ., St. Louis, MO, USA","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Real-time hybrid simulation (RTHS) is an important tool in the design and testing of civil and mechanical structures when engineers and scientists wish to understand the performance of an isolated component within the context of a larger structure. Performing full-scale physical experimentation with a large structure can be prohibitively expensive. Instead, a hybrid testing framework connects part of a physical structure within a closed loop (through sensors and actuators) to a numerical simulation of the rest of the structure. If we wish to understand the dynamic response of the combined structure, this testing must be done in real-time, which significantly restricts both the size of the simulation and the rate at which it can be conducted. Adding parallelism to the numerical simulation can enable both larger and higher frequency real-time simulations, potentially increasing both the accuracy and the control stability of the test. We present a proof-of-concept exploration of the execution of real-time hybrid simulations (an exemplar of a more general class of cyber-mechanical systems) with parallel computations. We execute large numerical simulations within tight timing constraints and provide a reasonable assurance of timeliness and usability. We detail the operation of our system, its design features, and show how parallel execution could enable qualitatively better experimentation within the discipline of structural engineering.","","","","10.1145/2656045.2656067","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986133","C.3 [Special-Purpose and Application-Based Systems];D.1 [Programming Techniques]: Parallel programming;Real-time and embedded systems","Computational modeling;Hardware;Numerical models;Parallel processing;Program processors;Real-time systems;Sensors","closed loop systems;digital simulation;dynamic response;mechanical testing;numerical analysis;parallel processing;real-time systems;structural engineering computing","RTHS;civil structure testing;closed loop system;control stability;cyber-mechanical systems;dynamic response;full-scale physical experimentation;higher frequency real-time simulations;mechanical structure testing;numerical simulation;numerical simulations;parallel computations;parallel execution;proof-of-concept exploration;real-time hybrid simulation execution;real-time hybrid structural simulation;real-time system support;structural engineering","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Can we put concurrency back into redundant multithreading?","Dobe, B.; Hartig, H.","Tech. Univ. Dresden, Dresden, Germany","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Software-implemented fault tolerance (SIFT) mechanisms allow to tolerate transient hardware faults in commercial off-the-shelf (COTS) systems without using specialized resilient hardware. Unfortunately, existing SIFT methods at both the compiler and the operating system levels are often restricted to single-threaded applications and hence do not apply to multithreaded software on modern multicore platforms. We present RomainMT, an operating system service that provides replication for unmodified multithreaded applications. Replicating these programs is challenging, because scheduling-induced non-determinism may cause replicated threads to execute different valid code paths. This complicates the distinction between valid behavior and the effects of hardware errors. RomainMT solves these problems by transparently making multithreaded execution deterministic. We present two alternative mechanisms that differ in the assumptions made about the respective applications and investigate their performance implications. Our evaluation using the SPLASH2 benchmark suite shows that the overhead for triple-modular redundancy (TMR) is 24% for applications with two application threads and 65% for four application threads.","","","","10.1145/2656045.2656050","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986127","","Benchmark testing;Fault tolerance;Hardware;Instruction sets;Libraries;Multithreading;Synchronization","concurrency (computers);multi-threading;multiprocessing systems;operating systems (computers);program compilers;software fault tolerance","COTS systems;RomainMT;SIFT mechanisms;SIFT methods;SPLASH2 benchmark suite;TMR;code paths;commercial off-the-shelf systems;concurrency;hardware errors;multicore platforms;multithreaded execution deterministic;multithreaded software;operating system service;redundant multithreading;scheduling-induced nondeterminism;single-threaded applications;software-implemented fault tolerance mechanisms;transient hardware fault tolerance;triple-modular redundancy","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Robust strategy synthesis for probabilistic systems applied to risk-limiting renewable-energy pricing","Puggelli, A.; Sangiovanni-Vincentelli, A.L.; Seshia, S.A.","Dept. of Electr. Eng. & Comput. Sci., Univ. of California, Berkeley, Berkeley, CA, USA","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","We address the problem of synthesizing control strategies for Ellipsoidal Markov Decision Processes (EMDP), i.e., MDPs whose transition probabilities are expressed using ellipsoidal uncertainty sets. The synthesized strategy aims to maximize the total expected reward of the EMDP, constrained to a specification expressed in Probabilistic Computation Tree Logic (PCTL). We prove that the EMDP strategy synthesis problem for the fragment of PCTL disabling operators with a finite time bound is NP-complete and propose a novel sound and complete algorithm to solve it. We apply these results to the problem of synthesizing optimal energy pricing and dispatch strategies in smart grids that integrate renewable sources of energy. We use rewards to maximize the profit of the network operator and a PCTL specification to constrain the risk of power unbalance and guarantee quality-of-service for the users. The EMDP model used to represent the decision-making scenario was trained with measured data and quantitatively captures the uncertainty in the prediction of energy generation. An experimental comparison shows the effectiveness of our method with respect to previous approaches presented in the literature.","","","","10.1145/2656045.2656069","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986121","","Markov processes;Optimization;Pricing;Probabilistic logic;Quality of service;Uncertainty;Wind forecasting","Markov processes;computational complexity;decision making;pricing;probabilistic logic;probability;profitability;quality of service;renewable energy sources","EMDP model;EMDP strategy synthesis problem;NP-complete finite time bound;PCTL specification;control strategy synthesis;decision-making scenario;ellipsoidal Markov decision process;ellipsoidal uncertainty sets;energy generation;network operator;optimal energy pricing synthesis;probabilistic computation tree logic;probabilistic systems;quality-of-service;renewable energy sources;risk-limiting renewable-energy pricing;robust strategy synthesis;transition probabilities","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"EDF as an arbitration policy for wormhole-switched priority-preemptive NoCs — Myth or fact?","Nikolic, B.; Petters, S.M.","CISTER, Polytech. Inst. of Porto, Porto, Portugal","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","A constant increase in the number of processors integrated within multiprocessor platforms led to more apparent contentions for the interconnect medium. Consequently, inter-processor communication latencies significantly outgrew the threshold until which their effects on the real-time analysis of multiprocessors can be discarded as negligible. Yet, despite its ever increasing importance, the contention analysis of interconnects is still in its infancy! In that vein, we propose a novel arbitration policy for interconnect routers, which is based on the EDF paradigm - a well-established approach in the scheduling theory. First, we elaborate on the practical aspects of this model and propose the worst-case traffic delay analysis. Then, we experimentally evaluate the approach against the state-of-the-art methods, and also investigate its practical limitations, so as to give a complete answer to the question posed in the title of this work.","","","","10.1145/2656045.2656056","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986135","Embedded Systems;Multiprocessors;NoCs;Real;Time Systems;Wormhole Switching","Bismuth;Delays;Equations;Interference;Jitter;Program processors;Real-time systems","delays;multiprocessor interconnection networks;network-on-chip;processor scheduling;real-time systems","EDF paradigm;arbitration policy;contention analysis;interconnect routers;interprocessor communication latencies;multiprocessor platforms;real-time multiprocessors analysis;scheduling theory;wormhole-switched priority-preemptive NoCs;worst-case traffic delay analysis","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"On the existence of probe effect in multi-threaded embedded programs","Young Wn Song; Yann-Hang Lee","Comput. Sci. & Eng., Arizona State Univ., Tempe, AZ, USA","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","9","Software instrumentation has been a convenient and portable approach for dynamic analysis, debugging, or profiling of program execution. Unfortunately, instrumentation may change the temporal behavior of multi-threaded program execution and result in different ordering of thread operations, which is called probe effect. While the approaches to reduce instrumentation overhead, to enable reproducible execution, and to enforce deterministic threading have been studied, no research has yet answered if an instrumented execution has the same behavior as the program execution without any instrumentation and how the execution gets changed if there were any. In this paper, we propose a simulation-based analysis to detect the changes of execution event ordering that are induced by instrumentation operations. The execution model of a program is constructed from the trace of instrumented program execution and is used in a simulation analysis where instrumentation overhead is removed. As a consequence, we can infer the ordering of events in the original program execution and verify the existence of probe effect resulted from instrumentation.","","","","10.1145/2656045.2656062","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986126","event ordering;multi-threaded program;probe effect;profiling;reproducible execution;software instrumentation","Analytical models;Clocks;Instruction sets;Message systems;Probes;Timing","embedded systems;multi-threading;program debugging;program diagnostics","deterministic threading;dynamic analysis;instrumentation overhead;multithreaded embedded programs;multithreaded program execution profiling;probe effect;simulation-based analysis;software debugging;software instrumentation;thread operations","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Building high-performance smartphones via non-volatile memory: The swap approach","Kan Zhong; Tianzheng Wang; Xiao Zhu; Linbo Long; Duo Liu; Weichen Liu; Zili Shao; Sha, E.H.-M.","","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Smartphones are getting increasingly high-performance with advances in mobile processors and larger main memories to support feature-rich applications. However, the storage subsystem has always been a prohibitive factor that slows down the pace of reaching even higher performance while maintaining good user experience. Despite today's smart-phones are equipped with larger-than-ever main memories, they consume more energy and still run out of memory. But the slow NAND flash based storage vetoes the possibility of swapping-an important technique to extend main memory-and leaves a system that constantly terminates user applications under memory pressure. In this paper, we revisit swapping for smartphones with fast, byte-addressable, non-volatile memory (NVM) technologies. Instead of using flash, we build the swap area with NVM, to allow high performance without sacrificing user experience. Based on NVM's high performance and byte-addressability, we show that a copy-on-write swap-in scheme can achieve even better performance by avoiding unnecessary memory copy operations. To avoid fast worn-out of certain NVMs, we also propose Heap-Wear, a wear leveling algorithm that more evenly distributes writes in NVM. Evaluation results based on the Google Nexus 5 smartphone show that our solution can effectively enhance smartphone performance and give better wear-leveling of NVM.","","","","10.1145/2656045.2656049","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986137","","Ash;Cows;Memory management;Nonvolatile memory;Phase change materials;Random access memory;Smart phones","flash memories;random-access storage;smart phones","Google Nexus 5 smartphone;Heap-Wear;NAND flash based storage;NVM technologies;Swap approach;byte-addressable nonvolatile memory technologies;copy-on-write swap-in scheme;high-performance smartphones;memory copy operations;mobile processors;storage subsystem;user experience;wear leveling algorithm","","1","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
"Contract-based integration of cyber-physical analyses","Ruchkin, I.; de Niz, D.; Chaki, S.; Garlan, D.","Inst. for Software Res., Carnegie Mellon Univ., Pittsburgh, PA, USA","Embedded Software (EMSOFT), 2014 International Conference on","20141218","2014","","","1","10","Developing cyber-physical systems involves multiple engineering domains, e.g., timing, logical correctness, thermal resilience, and mechanical stress. In today's industrial practice, these domains rely on multiple analyses to obtain and verify critical system properties. Domain differences make the analyses abstract away interactions among themselves, potentially invalidating the results. Specifically, one challenge is to ensure that an analysis is never applied to a model that violates the assumptions of the analysis. Since such violation can originate from the updating of the model by another analysis, analyses must be executed in the correct order. Another challenge is to apply diverse analyses soundly and scalably over models of realistic complexity. To address these challenges, we develop an analysis integration approach that uses contracts to specify dependencies between analyses, determine their correct orders of application, and specify and verify applicability conditions in multiple domains. We implement our approach and demonstrate its effectiveness, scalability, and extensibility through a verification case study for thread and battery cell scheduling.","","","","10.1145/2656045.2656052","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6986131","Cyber;analysis;analysis contracts;battery scheduling;model checking;physical systems;real-time scheduling;thermal runaway;virtual integration","Algorithm design and analysis;Analytical models;Batteries;Contracts;Instruction sets;Processor scheduling;Runtime","computational complexity;contracts;cybernetics;software engineering","analysis integration approach;battery cell scheduling;contract-based integration;critical system properties;cyber-physical analysis;cyber-physical systems;logical correctness;mechanical stress;realistic complexity;thermal resilience;thread scheduling","","0","","","","","12-17 Oct. 2014","","IEEE","IEEE Conference Publications"
