"http://ieeexplore.ieee.org/search/searchresult.jsp?bulkSetSize=2000&matchBoolean%3Dtrue%26searchField%3DSearch_All%26queryText%3D%28p_Publication_Title%3AHardware%2FSoftware+Codesign+and+System+Synthesis+.LB.CODES.PLS.ISSS.RB.%2C+2010+IEEE%2FACM%2FIFIP+International+Conference+on%29",2015/07/23 13:39:09
"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Year","Volume","Issue","Start Page","End Page","Abstract","ISSN","ISBN","EISBN","DOI",PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","MeSH Terms",Article Citation Count,Patent Citation Count,"Reference Count","Copyright Year","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"An introduction to the SystemC synthesis subset standard","Coussy, P.; Takach, A.; McNamara, M.; Meredith, M.","Univ. de Bretagne-Sud, Lorient, France","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","183","184","High-level synthesis (HLS) offers the prospect of improving the productivity digital system design and the quality of the resulting implementations. Designing at higher levels of abstraction is a natural way for coping with system design complexity, for verifying earlier in the design process and for increasing design reuse. OSCI's synthesis working group (SWG) has led the effort of defining the synthesis subset for SystemC that is suitable for HLS. Draft version 1.3 of the document was released for public review in August 2009. While still in draft form, the released document provides guidance to both tool providers and users on the subset that is being proposed and the ability to provide feedback to the SWG on the draft. This tutorial will provide a brief introduction and three case studies on the use of HLS and the current SystemC synthesis subset draft for hardware design of digital systems.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751498","High-level synthesis","Hardware design languages;Resource management","computational complexity;digital systems;high level synthesis","OSCI synthesis working group;SystemC synthesis subset standard;hardware design;high level synthesis;productivity digital system design;system design complexity","","0","","7","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"A holistic approach to Network-on-Chip synthesis","Leary, G.; Chatha, K.S.","Dept. of CSE, Arizona State Univ., Tempe, AZ, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","213","222","Application specific Network-on-Chip (NoC) architectures have emerged as a leading technology to address the communication woes of multi-processor System-on-Chip architectures. Synthesis approaches for custom NoC must address several requirements including cumulative bandwidth and transaction level (TL) communication requirements, multiple application use-cases, deadlock avoidance, and router port bandwidth and arity constraints. In this paper we present a holistic algorithm for NoC synthesis which is able to address all these requirements together in an integrated manner. The approach is able to generate designs that consume minimum dynamic power consumption, and at most twice the number of routers (and leakage power) as an optimal solution. In terms of performance the technique is able to generate NoC designs with very low average communication latencies (verified by actual simulations) and equally low standard deviation (jitter) while utilizing simple best effort routers. We evaluated the effectiveness and quality of the proposed technique by comparisons with two existing approaches. Extensive experimental results are presented for synthetic/realistic multiple use case applications, cumulative/transaction traffic requirements, increasing application bandwidth requirements, and different port arity constraints.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751504","Best Effort;Deadlock Avoidance;Multiple Use-Cases;Network-on-Chip;Port Arity;Synthesis","Bandwidth;Complexity theory;Computer architecture;Libraries;Power demand;System recovery;Topology","network routing;network synthesis;network-on-chip","NoC architectures;bandwidth requirements;cumulative-transaction traffic requirements;deadlock avoidance;holistic approach;leakage power;minimum dynamic power consumption;multiprocessor system-on-chip architectures;network-on-chip synthesis;port arity constraints;router port bandwidth;transaction level communication requirements","","0","","10","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Hardware/software co-design for high performance computing: Challenges and opportunities","Hu, X.S.; Murphy, R.C.; Dosanjh, S.; Olukotun, K.; Poole, S.","Dept. of Comput. Sci. & Eng., Univ. of Notre Dame, Notre Dame, IN, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","63","64","This special session aims to introduce to the hardware/software codesign community challenges and opportunities in designing high performance computing (HPC) systems. Though embedded system design and HPC system design have traditionally been considered as two separate areas of research, they in fact share quite some common features, especially as CMOS devices continue along their scaling trends and the HPC community hits hard power and energy limits. Understanding the similarities and differences between the design practices adopted in the two areas will help bridge the two communities and lead to design tool developments benefiting both communities.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751525","High performance computing;hardware/software codesign","Communities;Computer architecture;Hardware;High performance computing;Program processors;System analysis and design","embedded systems;hardware-software codesign","CMOS device;HPC system design;embedded system design;hardware-software codesign;high performance computing;tool development","","0","","6","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"System-level reliability modeling for MPSoCs","Yun Xiang; Chantem, T.; Dick, R.P.; Hu, X.S.; Li Shang","EECS Dept., Univ. of Michigan, Ann Arbor, MI, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","297","306","The reliability of multi-processor systems-on-chip (MPSoCs) is affected by several inter-dependent system-level and physical effects. Accurate and fast reliability modeling is a primary challenge in the design and optimization of reliable MPSoCs. This paper presents a reliability modeling framework that integrates device-, component-, and system-level models. This framework contains modules for electromigration, time-dependent dielectric breakdown, stress migration, and variable-amplitude thermal cycling. A new statistical reliability distribution is proposed for accurate characterization of components containing too few devices for an extreme value distribution to be appropriate. A hierarchical system-level survival lattice based Monte Carlo technique is used to estimate the temporal fault distributions of MPSoCs that use arbitrary static and dynamic reliability-enhancing redundancy schemes. Physical process variation, which may have a significant impact on MPSoC reliability, is considered in the model. The proposed modeling technique has 5% average error in mean time to failure and reduces simulation time by nearly 3 orders of magnitude relative to a non-hierarchical Monte Carlo technique.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751514","Performance;Reliability","Equations;Mathematical model","Monte Carlo methods;electric breakdown;electromigration;multiprocessing systems;reliability;system-on-chip","Monte Carlo technique;electromigration;hierarchical system level survival lattice;multiprocessor systems-on-chip;physical process variation;stress migration;system level reliability modeling;temporal fault distributions;time dependent dielectric breakdown;variable amplitude thermal cycling","","3","","30","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"From ESL 2010 to ESL 2015","Jeremiassen, T.; Kogel, T.; Takach, A.; Martin, G.; Donlin, A.; Chatha, K.","","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","61","62","In 2010, a wave of consolidation swept over the Electronic System Level (ESL) design industry. It brought ESL providers together with mainstream EDA houses and created opportunities for new ESL ventures. This paper contains short summaries of presentations in a special session focusing on the future of ESL. The session has two goals: the first is to present the state of the art in ESL tools and practice and, second, share a vision of the technical challenges that the next generation of ESL companies should address. The session includes a mix of perspectives from both ESL solution vendors and end-users and touches all all four ESL use cases: software virtual platforms, performance analysis, high level synthesis and verification.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751524","ESL;SystemC;TLM","Adaptation model;Computer architecture;Hardware;Performance analysis;Prototypes;Software;System-on-a-chip","logic design;system-on-chip;virtual prototyping","ESL 2010;ESL 2015;ESL solution vendors;electronic system level design industry;performance analysis;software virtual platforms","","0","","","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Improving platform-based system synthesis by satisfiability modulo theories solving","Reimann, F.; Glass, M.; Haubelt, C.; Eberl, M.; Teich, J.","Univ. of Erlangen-Nuremberg, Erlangen, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","135","144","Due to the ever increasing system complexity, deciding whether a given platform is sufficient to implement a set of applications under given constraints becomes a serious bottleneck in platform-based design. As a remedy, the work at hand proposes a novel automatic platform-based system synthesis procedure, inspired by techniques developed in the context of automatic system verification known as Satisfiability Modulo Theories. It tightly couples the computation of a feasible allocation and binding with nonfunctional constraint checking where, in contrast to existing approaches, not only linear constraints but even nonlinear constraints are supported. This allows to efficiently prove whether there exists a feasible implementation of a set of applications on the given platform with respect to both, functional and nonfunctional constraints. Moreover, an approach for early learning based on feasibility checking of partial implementations is proposed that can significantly improve the synthesis runtime, especially in case the selected platform imposes stringent constraints on the implementation. The effectiveness of this approach is shown for an automotive ECU network design that requires Modular Performance Analysis to ensure nonfunctional nonlinear timing constraints.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751492","Algorithms;Design","Complexity theory;Decision trees;Encoding;Program processors;Resource management;Timing","computability;computational complexity;program verification","automatic platform-based system synthesis;automatic system verification;automotive ECU network;modular performance analysis;nonfunctional constraints;nonfunctional nonlinear timing constraints;nonlinear constraints;satisfiability modulo theories solving;system complexity","","2","","23","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"A task remapping technique for reliable multi-core embedded systems","Chanhee Lee; Hokeun Kim; Hae-woo Park; Sungchan Kim; Hyunok Oh; Soonhoi Ha","Seoul Nat. Univ., Seoul, South Korea","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","307","316","With the continuous scaling of semiconductor technology, the life-time of circuit is decreasing so that processor failure becomes an important issue in MPSoC design. A software solution to tolerate run-time processor failure is to migrate tasks from the failed processors to the live processors when failure occurs. Previous works on run-time task migration usually aim to minimize the migration overhead with or without a given latency constraint. For streaming applications, however, it is more important to minimize the throughput degradation than the migration overhead or the latency. Hence, we propose a task remapping technique to minimize the throughput degradation assuming that the migration overhead can be amortized safely. The target multi-core system assumed in this paper consists of processor pools and each pool consists of homogeneous processors. The proposed technique is based on an intensive compile-time analysis for all possible failure scenarios. It involves the following steps; (1) Determine the static mapping of tasks onto the live processors, aiming to minimize the throughput degradation: (2) Find an optimal processor-to-processor mapping to minimize the task migration overhead: and (3) Store the resultant task remapping information that includes task mapping and processor-to-processor mapping results. Since the task remapping information is pre-computed at compile-time for all possible failure scenarios, it should be efficiently represented and stored. At run-time, we simply remap the tasks following the compile-time decision. We examine the scalability of the proposed technique on both space and run-time overhead for compile-time analysis varying the number of failed processors. Through intensive experiments, we show that the proposed technique outperforms the previous works with respect to application throughput.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751515","Multi-core embedded systems;reliability;static task mapping","Computer architecture;Degradation;Embedded systems;Encoding;Processor scheduling;Reliability;Throughput","embedded systems;fault tolerant computing;multiprocessing systems;program compilers;system-on-chip","MPSoC design;compile time analysis;homogeneous processors;multicore embedded system relibility;optimal processor-to-processor mapping;processor failure;processor pool;semiconductor technology;task remapping technique","","2","","24","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Unconventional fabrics, architectures, and models for future multi-core systems","Marculescu, R.; Teuscher, C.; Pande, P.P.","Dept. of Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","327","328","Massive level of integration is making modern multi-core chips all-pervasive in several domains. Hence, high performance, robustness, and low power are crucial for the widespread adoption of such platforms. However, achieving all these goals forces us to re-think the basis of designing multi-core systems at nanoscale, starting with the very substrate we need to use to implement such systems in the future, particularly for nanowire (or carbon nanotube) based on-chip interconnect obtained through self-assembly techniques. Due to the lack of control over these processes, such interconnects are expected to be largely unstructured. While large unstructured networks are easy to fabricate, they require unconventional architectures and communication paradigms. For instance, by getting inspiration from many natural systems with network-based architectures, the future multi-core systems at nanoscale are expected to be hierarchical and heterogeneous in nature, as many powerful features such as increased performance, better resource utilization, and an increased robustness against failures of many natural networks come precisely from their heterogeneity, unstructuredness, and hierarchical nature. As such, an important performance limitation of multi-core chips designed with regular network architectures arises from planar metal interconnect-based multi-hop links, where the data transfer between two distant blocks can cause high latency and power consumption.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751517","Multi-core;architecture;interconnect;networks-on-chip;routing;self-assembly;workload","Measurement;Metals;Multicore processing;Optimization;System-on-a-chip;Wireless communication","multiprocessing systems;multiprocessor interconnection networks;nanowires","data transfer;multicore system;nanowire based onchip interconnect;network based architecture;planar metal interconnect based multihop links;power consumption;selfassembly technique","","0","","7","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Demand-based block-level address mapping in large-scale NAND flash storage systems","Zhiwei Qin; Yi Wang; Duo Liu; Zili Shao","Dept. of Comput., Hong Kong Polytech. Univ., Kowloon, China","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","173","182","The increasing capacity of NAND flash memory leads to large RAM footprint on address mapping in the Flash Translation Layer (FTL) design. This paper proposes a novel Demand-based block-level Address mapping scheme with two-level Caching mechanism (DAC) for large-scale NAND flash storage systems. The objective is to reduce RAM footprint without sacrificing too much system response time. In our technique, the block-level address mapping table is stored in fixed pages (called translation pages) in the flash memory. Considering temporal locality that workloads exhibit, we maintain one cache in RAM to store the on-demand block-level address mapping information. Meanwhile, by exploring both spatial locality and access frequency of workloads with another two caches, the second-level cache is designed to cache selected translation pages into RAM. In such a way, address mapping information for both sequential accesses and most-frequently-accessed translation pages can be found in the cache, and therefore, the system response time can be improved. We conduct experiments on a mixture of real-world and synthetic traces. The experimental results show that our technique can significantly reduce the RAM footprint while the average response time is kept well under control. Moreover, our technique shows big improvement on wear-leveling compared with the previous work.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751497","Block-Level Mapping;NAND Flash;Two-Level Cache","Digital video broadcasting","NAND circuits;cache storage;flash memories;integrated circuit design;random-access storage","NAND flash storage systems;RAM footprint;access frequency;caching mechanism;demand-based block-level address mapping;flash memory;flash translation layer design;spatial locality","","3","","29","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Towards a synthesis semantics for SystemC channels","Gruttner, K.; Kleen, H.; Oppenheimer, F.; Rettberg, A.; Nebel, W.","OFFIS - Inst. for Inf. Technol., Oldenburg, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","163","172","In this paper we propose a synthesis semantics for SystemC™ channels, which contribute to a clear separation between computation (algorithm) and communication, whereas communication related parts are modelled through either primitive or hierarchical channels. We present a synthesisable replacement for SystemC primitive channels that allows deterministic access scheduling and user-constrained refinement for HW/HW and HW/SW communication. We demonstrate the feasibility of our approach through synthesis and exploration of a communication intensive packet switch design under consideration of different configurations and communication refinements.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751496","Design","Encoding;Hardware;Indexes;Protocols;Schedules;Semantics;Synchronization","C++ language;hardware-software codesign;semantic networks;telecommunication channels","HW/HW communication;HW/SW communication;SystemC channels;deterministic access scheduling;packet switch design;synthesis semantics;user-constrained refinement","","1","","31","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Hardware/software optimization of error detection implementation for real-time embedded systems","Lifa, A.; Eles, P.; Zebo Peng; Izosimov, V.","Linkoping Univ., Linko&#x0308;ping, Sweden","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","41","50","This paper presents an approach to system-level optimization of error detection implementation in the context of fault-tolerant real-time distributed embedded systems used for safety-critical applications. An application is modeled as a set of processes communicating by messages. Processes are mapped on computation nodes connected to the communication infrastructure. To provide resiliency against transient faults, efficient error detection and recovery techniques have to be employed. Our main focus in this paper is on the efficient implementation of the error detection mechanisms. We have developed techniques to optimize the hardware/software implementation of error detection, in order to minimize the global worst-case schedule length, while meeting the imposed hardware cost constraints and tolerating multiple transient faults. We present two design optimization algorithms which are able to find feasible solutions given a limited amount of resources: the first one assumes that, when implemented in hardware, error detection is deployed on static reconfigurable FPGAs, while the second one considers partial dynamic reconfiguration capabilities of the FPGAs.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751522","Algorithms;Design;Performance;Reliability","Fault tolerance;Fault tolerant systems;Field programmable gate arrays;Hardware;Schedules;Software;Transient analysis","embedded systems;error detection;fault tolerant computing;field programmable gate arrays;hardware-software codesign;optimisation;safety-critical software","FPGA;communication infrastructure;error detection implementation;fault-tolerant real-time distributed embedded systems;global worst-case schedule length;hardware cost constraints;hardware-software optimization;multiple transient fault tolerance;partial dynamic reconfiguration capabilities;recovery techniques;safety-critical applications;system-level optimization;transient faults","","0","","23","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Statistical approach in a system level methodology to deal with process variation","Pineda, C.S.; Prieto, M.; Go&#x0301;mez, J.I.; Tenllado, C.; Catthoor, F.","Dipt. de Arquitectura de Comput. y Autom., Univ. Complutense de Madrid, Madrid, Spain","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","115","124","The impact of process variation in state of the art technology makes traditional (worst case) designs unnecessarily pessimistic, which translates to suboptimal designs in terms of both energy consumption and performance. In this context, developing variation aware design methodologies becomes a must. These techniques should provide better performance-energy balances while the percentage of faulty products keeps controlled. Furthermore, it would be advisable to consider adaptations of the system during lifetime, in order to provide robustness against ageing. In this paper we propose a design approach which tackles process variation on the memory system by using multimode memories. At design time we perform a heuristic exploration using probabilistic models of these memories, which generates a set of system configurations that minimize energy consumption for a given set of timing constraints. The percentage of systems that will satisfy these deadlines, even under process variation, is taken as a design parameter. Additionally, if system monitors are available, a setup stage optimizes the initial set of configurations for the actual memory parameters. Our simulations show that this methodology provides significant energy savings while still meeting timing constraints.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751490","Process variation;parametric yield;variability compensation","Delay;Design methodology;Energy consumption;Memory management;Monitoring;Temperature measurement","digital storage;integrated circuit design;statistical analysis","energy consumption;heuristic exploration;memory system;multimode memories;probabilistic models;process variation;statistical approach;system level methodology;variation aware design methodologies","","0","","25","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Modeling and analyzing real-time multiprocessor systems","Wiggers, M.; Thiele, L.; Lee, E.A.; Schliecker, S.; Bekooij, M.","Dept. of EEMCS, Univ. of Twente, Enschede, Netherlands","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","329","330","Researchers have proposed approaches to verify that real-time multiprocessor systems meet their timeliness constraints. These approaches make assumptions on the model of computation, the load placed on the multiprocessor system, and the faults that can arise. This heterogeneous set of assumptions make these approaches hard to compare. This tutorial will present an overview and positioning of four recently proposed approaches. We present for each approach, the application domain in which its assumptions are realistic and the dominant application requirements that have driven its development. Next to discussing timeliness guarantees, we give attention to the robustness aspects of each approach; e.g. against faults such as overload.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751518","Discrete-Event Models;Real-Time Calculus;SymTA/S;Timed Dataflow","Biological system modeling;Computational modeling;Embedded systems;Performance analysis;Processor scheduling;Real time systems","multiprocessing systems;real-time systems","real-time multiprocessor system modeling;timeliness constraint","","0","","18","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Verification of dynamically reconfigurable embedded systems by model transformation rules","Madlener, F.; Weingart, J.; Huss, S.A.","Integrated Circuits & Syst. Lab., Tech. Univ. Darmstadt, Darmstadt, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","33","40","This paper describes a methodology for the verification of reconfigurable embedded systems. The reconfigurable systems are described by means of the Reconfigurable Discrete Event Specified System (RecDEVS) computational model and the verification is performed by a model transformation from the RecDEVS model into an equivalent representation for the UPPAAL model checking methodology. We introduce an algorithm for the automatic transformation of such models, which originate from disjoint application domains. This allows the usage of an state-of-the art verification tool for the verification of arbitrary properties of system specifications denoted in RecDEVS. We also present a set of important system properties, which now may be verified. This set includes some fundamental reconfiguration domain specific properties, which were not addressed by previous formal verification methods. The feasibility of this approach is demonstrated for a complex automotive application.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751520","Design Methodology;Model Transformation;RecDEVS;Reconfigurable Systems;UPPAAL;Verification","Automata;Clocks;Computational modeling;Embedded systems;Hardware;Integrated circuit modeling;Synchronization","discrete event simulation;embedded systems;formal verification;reconfigurable architectures","RecDEVS model;UPPAAL;formal verification;model checking method;model transformation rules;reconfigurable discrete event specified system;reconfigurable embedded systems","","0","","18","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Optimal synthesis of latency and throughput constrained pipelined MPSoCs targeting streaming applications","Javaid, H.; Xin He; Ignjatovic, A.; Parameswaran, S.","Sch. of Comput. Sci. & Eng., Univ. of New South Wales, Sydney, NSW, Australia","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","75","84","A streaming application, characterized by a kernel that can be broken down into independent tasks which can be executed in a pipelined fashion, inherently allows its implementation on a pipeline of Application Specific Instruction set Processors (ASIPs), called a pipelined MPSoC. The latency and throughput requirements of streaming applications put constraints on the design of such a pipelined MPSoC, where each ASIP has a number of available configurations differing by additional instructions, and instruction and data cache sizes. Thus, the design space of a pipelined MPSoC is all the possible combinations of ASIP configurations (design points). In this paper, a methodology is proposed to optimize the area of a pipelined MPSoC under a latency or a throughput constraint. The final design point is a set of ASIP configurations with one configuration for each ASIP. We proposed an Integer Linear Programming (ILP) based solution to the area optimization problem under a latency constraint, and an algorithm for optimization of pipelined MPSoC area under a throughput constraint. The proposed solutions were evaluated using four streaming applications: JPEG encoder; JPEG decoder; MP3 encoder; and H.264 decoder. The time to find the Pareto front of each pipelined MPSoC was less than 4 minutes where design spaces had up to 10<sup>16</sup> design points, illustrating the applicability of our approach.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751527","Design Space Exploration;Integer Linear Programming","Clocks;Optimization;Pipelines;Program processors;Streaming media;Throughput;Transform coding","Pareto optimisation;application specific integrated circuits;integer programming;linear programming;multiprocessing systems;pipeline processing;system-on-chip","H.264 decoder;JPEG decoder;JPEG encoder;MP3 encoder;Pareto front;application specific instruction set processors;integer linear programming;optimal latency synthesis;streaming applications;throughput constrained pipelined MPSoC","","4","1","33","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Scheduling garbage collection in real-time systems","Kero, M.; Aittamaa, S.","Dept. of Comput. Sci., Lulea Univ. of Technol., Lule&#x00E5;, Sweden","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","51","60","The key to successful deployment of garbage collection in real-time systems is to enable provably safe schedulability tests of the real-time tasks. At the same time one must be able to determine the total heap usage of the system. Schedulability tests typically require a uniformed model of timing assumptions (inter-arrival times, deadlines, etc.). Incorporating the cost of garbage collection in such tests typically requires both artificial timing assumptions of the garbage collector and restricted capabilities of the task scheduler. In this paper, we pursue a different approach. We show how the reactive object model of the programming language Timber enables us to decouple the cost of a concurrently running copying garbage collector from the schedulability of the real-time tasks. I.e., we enable any regular schedulability analysis without the need of incorporating the cost of an interfering garbage collector. We present the garbage collection demand analysis, which determines if the garbage collector can be feasibly scheduled in the system.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751523","Schedulability analysis;reactive systems","Algorithm design and analysis;Data structures;Kernel;Message systems;Real time systems;Synchronization","programming languages;real-time systems;reproduction (copying);scheduling;storage management;task analysis","artificial timing assumption;concurrently running copying garbage collector cost;garbage collection demand analysis;garbage collection scheduling;heap usage;programming language;real-time system;real-time task schedulability;regular schedulability analysis;safe schedulability test;task scheduler","","0","1","30","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"FEMU: A firmware-based emulation framework for SoC verification","Hao Li; Dong Tong; Kan Huang; Xu Cheng","Microprocessor R&D Center, Peking Univ., Beijing, China","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","257","266","Full-system emulation on FPGA(Field-Programmable Gate Array) with real-world workloads can enhance the confidence of SoC(System-on-Chip) design. However, since FPGA emulation requires complete implementation of key modules and provides weak visibility, it is time-consuming. This paper proposes FEMU, a hybrid firmware/hardware emulation framework for SoC verification. The core of FEMU is implemented by transplanting QEMU, a full-system emulator, from OS level to BIOS level, so we can directly emulate devices upon hardware. Moreover, FEMU provides programming interfaces to simplify device modeling in firmware. Based on an auxiliary set of hardware modules, FEMU allows hybrid full-system emulation with the combination of real hardware and emulated firmware model. Therefore, FEMU can facilitate full-system emulation in three aspects. First, FEMU enables full-system emulation with the minimum hardware implementation, so the DUT (Design Under Test) module can be verified under target application as early as possible. Second, by comparing the execution traces generated using real hardware and emulated firmware model, respectively, FEMU helps locate and fix bugs occurred in the full-system emulation. Third, by replacing un-verified hardware modules with emulated firmware models, FEMU helps isolating design issues in multiple modules. In a practical SoC project, FEMU helped us identify several design issues in full-system emulation. In addition, the evaluation results show that the emulation speed of FEMU is comparable with QEMU after transplantation.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751510","Firmware;System Emulator;System-on-Chip;Verification","Debugging;Emulation;Field programmable gate arrays;Hardware;Software;Synchronization;System-on-a-chip","field programmable gate arrays;firmware;formal verification;integrated circuit design;system-on-chip","BIOS level;FEMU;QEMU;SoC verification;design under test module;field-programmable gate array;firmware-based emulation framework;hybrid full-system emulation;system-on-chip design","","0","1","19","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Embedded market: Challenges and opportunities","Ilderem, V.","Integrated Platform Research Lab, Intel Corporation, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","1","1","There is a convergence trend in the computing, communication and consumer markets and with a forecast of an additional 1 billion connected computing users by 2015, it is of high value to provide a common experience between the devices. Intel's vision of Compute Continuum will enable the users to realize the potential of a seamless cross-device experience with more consistency and accessibility to their information. The convergence trend and the Compute Continuum make System-on-Chip [SoC] a key ingredient for the embedded markets. At Intel Labs, we are focusing on delivering differentiating technology solutions to enable our business partners to successfully capture their targeted market segments. We are working on a variety of research that will enable modular system architecture and silicon technology breakthroughs for rapid customization and integration facilitating faster time-to-market. Intel's vision along with some technology challenges and possible solutions will be highlighted.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751502","Compute Continuum;System-on-a-Chip","Business;Computer architecture;Convergence;Focusing;Hardware;Silicon;System-on-a-chip","commerce;embedded systems;system-on-chip","Intel labs;compute continuum;consumer markets;embedded market;modular system architecture;rapid customization;silicon technology;system-on-chip","","0","","","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"NeuroNoC: Neural network inspired runtime adaptation for an on-chip communication architecture","Ebi, T.; Faruque, M.A.A.; Henkel, J.","Dept. of Embedded Syst., Karlsruhe Inst. of Technol. (KIT), Karlsruhe, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","223","230","The on-chip communication architecture presented in this paper, NeuroNoC, addresses the problems arising in large multi-core systems where global or local routing strategies do not work efficiently anymore since they either do not scale or lack information on the network state. Our communication architecture is runtime adaptive and it deploys a distributed artificial neural network to aid routing decisions. It thereby provides a light-weight mechanism for local routing information to propagate through the communication architecture and is capable of self-organizing efficiently (since scalable) to varying communication workload scenarios. The underlying basic concepts are borrowed from spiking neural networks, a special case of artificial neural networks. Our experiments show that already with low hardware overhead, a significant improvement of the runtime routing behavior compared to current state-of-the-art approaches is possible. We report an improvement of 23% in routing quality compared to wXY routing in terms of failed transactions.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751505","Adaptive system;Network-on-Chip;Spiking Neural Networks","Artificial neural networks;Bandwidth;Biomembranes;Computer architecture;Kernel;Neurons;Routing","multiprocessing systems;multiprocessor interconnection networks;network-on-chip;neural nets","NeuroNoC;communication workload scenario;distributed artificial neural networks;local routing information;multicore system;neural network inspired runtime adaptation;onchip communication architecture;routing decision;spiking neural networks","","1","","22","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Workload characterization and its impact on multicore platform design","Bogdan, P.; Marculescu, R.","Dept. of Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","231","240","Networks-on-chip (NoCs) have been proposed as a scalable solution to solving the communication problem in multicore systems. Although the queuing-based approaches have been traditionally used for performance analysis purposes, they cannot properly account for many of the traffic characteristics (e.g., non-stationary, self-similarity, higher order statistics) that are crucial for multicore platform design when communication happens via the NoC approach. To overcome this limitation, we propose a mean field approach to analyze the traffic dynamics in multicore systems and show how the non-stationary effects of the NoC workload can be effectively captured; this is of fundamental significance for rethinking the very basis of multicore systems design. Moreover, our experimental results demonstrate that both network architecture and application characteristics are the main sources of power law behavior observed in network traffic. Our findings open new research directions into NoC optimization which require accurate models of time- and space-dependent traffic behavior.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751506","Master Equation;Multi-processor systems;Networks-on-Chip;Systems-on-Chip","Analytical models;Equations;Fractals;Mathematical model;Multicore processing;Routing;Stochastic processes","multiprocessing systems;network-on-chip;queueing theory","NoC approach;multicore platform design;networks-on-chip;queuing-based approaches;workload characterization","","1","","26","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"A performance model and code overlay generator for scratchpad enhanced embedded processors","Baker, M.A.; Panda, A.; Ghadge, N.; Kadne, A.; Chatha, K.S.","Comput. Sci. & Eng. Dept., Arizona State Univ., Tempe, AZ, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","287","296","Software managed scratchpad memories (SPMs) provide improved performance and power in embedded processors by reducing required hardware resources. Performance depends strongly on the scheme used to map code and data onto the SPM, but generating optimal mappings can be extremely difficult. Here we address instruction mapping on SPMs and present a performance model and algorithm, “Code Overlay Generator” (COG), for producing high performance dynamic SPM code mappings. Our heuristic does not require profiling information, and is suitable for generating mapping solutions for large programs which are otherwise infeasible using previously proposed Integer Linear Programming (ILP) techniques. We compare our algorithm with a published heuristic and the code overlay mapping algorithm provided with the Cell Broadband Engine (CBE) Synergistic Processing Unit (SPU) compiler from IBM, spu-gcc. We find an average performance advantage of 34% compared to the previous algorithm, and 87% with respect to spu-gcc. We additionally show that our performance model enables improved tools for offline evaluation of code overlay performance and mapping selection.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751513","Cell Broadband Engine;Code Mapping;Code Overlay;Compiler;Embedded Systems;Scratchpad Memory","Algorithm design and analysis;Computer architecture;Generators;Heuristic algorithms;Interference;Performance evaluation;Software","embedded systems;microprocessor chips;performance evaluation;power aware computing;program compilers;random-access storage","code overlay generator;high performance dynamic SPM code mapping;instruction mapping;performance model;scratchpad enhanced embedded processor;software managed scratchpad memories","","0","","14","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Heap data management for limited local memory (LLM) multi-core processors","Ke Bai; Shrivastava, A.","Microarchitecture Lab., Arizona State Univ., Tempe, AZ, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","317","325","This paper presents a scheme to manage heap data in the local memory present in each core of a limited local memory (LLM) multi-core processor. While it is possible to manage heap data semi-automatically using software cache, managing heap data of a core through software cache may require changing the code of the other threads. Cross thread modifications are difficult to code and debug, and only become more difficult as we scale the number of cores. We propose a semi-automatic, and scalable scheme for heap data management that hides this complexity in a library with a much natural programming interface. Furthermore, for embedded applications, where the maximum heap size can be known at compile time, we propose optimizations on the heap management to significantly improve the application performance. Experiments on several benchmarks of MiBench executing on the Sony Playstation 3 show that our scheme is easier to use, and if we know the maximum size of heap data, then our optimizations can improve application performance by an average of 14%.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751516","Heap;IBM Cell;MPI;PS3;embedded systems;local memory;multi-core processor;scratch pad memory","Data structures;Instruction sets;Memory management;Multicore processing","cache storage;embedded systems;multiprocessing systems;optimisation","embedded systems;heap data management;limited local memory;multicore processor;natural programming interface;optimizations;software cache","","0","","30","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Accurate online power estimation and automatic battery behavior based power model generation for smartphones","Lide Zhang; Tiwana, B.; Dick, R.P.; Zhiyun Qian; Mao, Z.M.; Zhaoguang Wang; Lei Yang","EECS Dept., Univ. of Michigan, Ann Arbor, MI, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","105","114","This paper describes PowerBooter, an automated power model construction technique that uses built-in battery voltage sensors and knowledge of battery discharge behavior to monitor power consumption while explicitly controlling the power management and activity states of individual components. It requires no external measurement equipment. We also describe PowerTutor, a component power management and activity state introspection based tool that uses the model generated by PowerBooter for online power estimation. PowerBooter is intended to make it quick and easy for application developers and end users to generate power models for new smartphone variants, which each have different power consumption properties and therefore require different power models. PowerTutor is intended to ease the design and selection of power efficient software for embedded systems. Combined, PowerBooter and PowerTutor have the goal of opening power modeling and analysis for more smartphone variants and their users.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751489","Power modeling;battery;mobile phones","Batteries;Bluetooth;Brightness;Cameras;Global Positioning System;Ground penetrating radar;Monitoring","battery management systems;electric sensing devices;embedded systems;power consumption;power engineering computing","PowerBooter;automatic battery behavior;built-in battery voltage sensor;embedded system;online power estimation;power efficient software;power management;power model generation;smartphone variant","","64","","18","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Automatic parallelization of embedded software using hierarchical task graphs and integer linear programming","Cordes, D.; Marwedel, P.; Mallik, A.","Inf. Centrum Dortmund, Dortmund, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","267","276","The last years have shown that there is no way to disregard the advantages provided by multiprocessor System-on-Chip (MPSoC) architectures in the embedded systems domain. Using multiple cores in a single system enables to close the gap between energy consumption, problems concerning heat dissipation, and computational power. Nevertheless, these benefits do not come for free. New challenges arise, if existing applications have to be ported to these multiprocessor platforms. One of the most ambitious tasks is to extract efficient parallelism from these existing sequential applications. Hence, many parallelization tools have been developed, most of them are extracting as much parallelism as possible, which is in general not the best choice for embedded systems with their limitations in hardware and software support. In contrast to previous approaches, we present a new automatic parallelization tool, tailored to the particular requirements of the resource constrained embedded systems. Therefore, this paper presents an algorithm which automatically steers the granularity of the generated tasks, with respect to architectural requirements and the overall execution time reduction. For this purpose, we exploit hierarchical task graphs to simplify a new integer linear programming based approach in order to split up sequential programs in an efficient way. Results on real-life benchmarks have shown that the presented approach is able to speed sequential applications up by a factor of up to 3.7 on a four core MPSoC architecture.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751511","Automatic Parallelization;Embedded Software;Hierarchical Task Graph;Integer Linear Programming","Computer architecture;Embedded systems;Equations;Hardware;Integer linear programming;Mathematical model;Parallel processing","embedded systems;integer programming;linear programming;microprocessor chips;multiprocessing systems;parallel architectures;power aware computing;system-on-chip","automatic parallelization tool;computational power;embedded software;energy consumption;heat dissipation;hierarchical task graphs;integer linear programming;multiple cores;multiprocessor system-on-chip architectures;sequential programs","","2","","25","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Exploring models of computation with Ptolemy II","Brooks, C.; Lee, E.A.; Tripakis, S.","EECS Dept., Univ. of California, Berkeley, Berkeley, CA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","331","332","The Ptolemy project studies modeling, simulation, and design of concurrent, real-time, embedded systems. The focus is on assembly of concurrent components. The key underlying principle in the project is the use of well-defined models of computation that govern the interaction between components. A major problem area being addressed is the use of heterogeneous mixtures of models of computation. Ptolemy II takes a component view of design, in that models are constructed as a set of interacting components. A model of computation governs the semantics of the interaction, and thus imposes an execution-time discipline. Ptolemy II has implementations of many models of computation including Synchronous Data Flow, Kahn Process Networks, Discrete Event, Continuous Time, Synchronous/Reactive and Modal Models This hands-on tutorial explores how these models of computation are implemented in Ptolemy II and how to create new models of computation such as a ""non-dogmatic"" Process Networks example and a left-to-right execution policy example.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751519","Modeling;concurrency;simulation","Computational modeling;Data models;Object oriented modeling;Real time systems;Semantics;Software;Tutorials","embedded systems;object-oriented methods;public domain software","Kahn process networks;Ptolemy II;concurrent embedded systems;continuous time models;discrete event models;execution time discipline;left-to-right execution policy;modal models;non dogmatic process networks;real time embedded systems;synchronous data flow;synchronous-reactive models","","0","","8","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"High durability in NAND flash memory through effective page reuse mechanisms","Kwangyoon Lee; Orailoglu, A.","Dept. of Comput. Sci. & Eng., Univ. of California, La Jolla, CA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","205","211","In this paper, we introduce a highly effective page reuse mechanism to reduce the amount of block erasures and page programming in NAND based primary memory architectures. The proposed techniques provide a very high rate of page reuse by effectively incorporating bit differences in page updates along with a reduction in bit unprogrammability by minimizing programming interference among adjacent pages. We also propose an effective block reclamation scheme to alleviate overall programming stress in a block so as to reduce the probability of run-time cell defects. The page reordering scheme can further increase page reusability by reducing run-time programming disturbance. The experimental results show that our proposed techniques significantly diminish the amount of block reclamation and consequently enhance the durability of the NAND flash based storage systems. Furthermore, by alleviating overall bit stress in NAND flash memory, the probability of bit failure of each cell is also significantly reduced, enabling the construction of more reliable and durable NAND flash based memory.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751503","Durability;Memory Architecture;NAND Flash;Primary Memory","Ash;Embedded systems;Memory management;Microprocessors;Programming;Random access memory","NAND circuits;flash memories;memory architecture","NAND flash memory;block erasures;memory architectures;page programming;page reuse mechanisms;programming interference;run time cell defects;run time programming disturbance","","0","","13","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"OE+IOE: A novel turn model based fault tolerant routing scheme for networks-on-chip","Pasricha, S.; Yong Zou; Connors, D.; Siegel, H.J.","Dept. of Electr. & Comput. Eng., Colorado State Univ., Fort Collins, CO, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","85","93","Network-on-chip (NoC) communication architectures are increasingly being used today to interconnect cores on chip multiprocessors (CMPs). Permanent faults in NoCs due to fabrication challenges in ultra deep submicron (UDSM) technology nodes and due to wearout have led to an increased emphasis on fault tolerant design techniques. To ensure fault tolerant communication in NoCs, several fault tolerant routing algorithms have been proposed in recent years with the goal of routing flits around faults. A majority of these algorithms are based on the turn model approach due to its simplicity and inherent freedom from deadlock. However, existing turn model based fault tolerant routing algorithms are either too restrictive in the choice of paths that flits can traverse, or are tailored to work efficiently only on very specific fault distribution patterns. In this paper, we propose a novel low overhead fault tolerant routing scheme that combines the odd-even (OE) and inverted odd-even (IOE) turn models to achieve much better fault tolerance than traditional turn model based schemes. The proposed scheme uses replication opportunistically to optimize the balance between energy overhead and arrival rate. Our experimental results indicate that the proposed OE+IOE routing scheme provides better fault tolerance than existing turn model, N-random walk, and dual virtual channel based routing schemes that have been proposed in literature.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751528","Fault-tolerant routing;Networks-on-chip","Circuit faults;Fault tolerant systems;Redundancy;Routing;Runtime;System recovery","fault tolerance;microprocessor chips;multiprocessing systems;multiprocessor interconnection networks;network-on-chip","N-random walk;OE+IOE routing scheme;dual virtual channel based routing scheme;fault distribution pattern;fault tolerant routing scheme;interconnect core;inverted odd-even turn model;network-on-chip communication architecture;on chip multiprocessor;permanent fault;turn model approach;ultra deep submicron technology","","1","","42","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"[Title page]","","","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","1","13","The following topics are dealt with: embedded systems; application-specific algorithms and architectures; reconfigurable and real-time system; HW/SW co-design; high performance computing; optimising multiprocessor and NoC performance, QoS and reliability; power-aware design; MPSoC analysis and synthesis; memory and communication architecture; SystemC synthesis subset standard; compilation techniques for CGRAs; Network-on-Chip systems; accelerating system simulation; embedded software performance optimization; and multi-core systems.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751488","","","C language;application specific integrated circuits;embedded systems;hardware-software codesign;logic design;memory architecture;microprocessor chips;multiprocessing systems;network-on-chip;power aware computing;program compilers;reconfigurable architectures;software performance evaluation","CGRA;HW/SW co-design;MPSoC analysis;MPSoC synthesis;NoC performance;QoS;SystemC synthesis subset standard;accelerating system simulation;application-specific algorithms;application-specific architectures;communication architecture;compilation techniques;embedded software performance optimization;embedded systems;hardware/software codesign;high performance computing;memory architecture;multicore systems;network-on-chip systems;optimising multiprocessor;power-aware design;real-time system;reconfigurable system;reliability;system synthesis","","0","","","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Intermediate fabrics: Virtual architectures for circuit portability and fast placement and routing","Coole, J.; Stitt, G.","Dept. of Electr. & Comput. Eng., Univ. of Florida, Gainesville, FL, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","13","22","Although hardware/software partitioning of embedded applications onto FPGAs is widely known to have performance and power advantages, FPGA usage has been typically limited to hardware experts, due largely to several problems: 1) difficulty of integrating hardware design tools into well-established software tool flows, 2) increasingly lengthy FPGA design iterations due to placement and routing, and 3) a lack of portability and interoperability resulting from device/platform-specific tools and bitfiles. In this paper, we directly address the last two problems by introducing intermediate fabrics, which are virtual reconfigurable architectures specialized for different application domains, implemented on top of commercial-off-the-shelf devices. Such specialization enables near-instantaneous placement and routing by hiding the complexity of fine-grained physical devices, while also enabling circuit portability across all devices that implement the intermediate fabric. When combined with existing work on runtime synthesis from software binaries, intermediate fabrics reduce the effects of all three problems by enabling transparent usage of COTS FPGAs by software designers. In this paper, we explore intermediate fabric architectures using specialization techniques to minimize area and performance overhead of the virtual fabric while maximizing routability and speedup of placement and routing. We present results showing an average placement and routing speedup of 554×, with an average area overhead of 10% and clock overhead of 18%, which corresponds to an average frequency of 195 MHz.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751493","FPGA;intermediate fabrics;placement and routing;speedup;virtualization","Computer architecture;Digital signal processing;Fabrics;Field programmable gate arrays;Integrated circuit modeling;Libraries;Routing","electronic engineering computing;field programmable gate arrays;hardware-software codesign;network routing;open systems;reconfigurable architectures;virtual reality","COTS;FPGA design;circuit portability;circuit routing;commercial-off-the-shelf devices;device-platform-specific tool;embedded application;field programmable gate arrays;hardware design tool;hardware-software partitioning;intermediate fabrics;interoperability;runtime synthesis;virtual reconfigurable architecture","","4","1","36","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Exploring programming model-driven QoS support for NoC-based platforms","Joven, J.; Marongiu, A.; Angiolini, F.; Benini, L.; De Micheli, G.","LSI, EPFL, Lausanne, Switzerland","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","65","74","Networks-on-Chip (NoCs) are being increasingly considered as a central enabling technology to communication-centric designs as more and more IP blocks are integrated on the same SoC. Embedded applications, in turn, are becoming extremely sophisticated, and often require guaranteed levels of service and performance. The complex and non-uniform nature of network traffic generated by parallel applications running on a large number of possibly heterogeneous IPs makes a strong case for providing Quality of Service (QoS) support for traffic streams over the NoC infrastructure. In this paper we consider an integrated hardware/software approach for delivering QoS at the application level. We designed NoC hardware support, low-level middleware and APIs which enable QoS control at the application level. Furthermore, we identify a set of programming abstractions useful to associate the notion of priority to each running task in the system. An initial implementation of this programming model is also presented, which leverages a set of extensions to a MPSoC-specific OpenMP compiler and run-time environment.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751526","Design;Performance","Argon;Computer architecture;Flip-flops;Programming;Quality of service;Runtime;Software","middleware;multiprocessing systems;network-on-chip;program compilers;quality of service","API;IP blocks;MPSoC-specific OpenMP compiler;NoC hardware support;communication-centric designs;low-level middleware;networks-on-chip;programming abstractions;programming model-driven QoS support;quality of service","","0","","39","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Performance modeling of embedded applications with zero architectural knowledge","Lattuada, M.; Ferrandi, F.","Dipt. di Elettron. e Inf., Politec. di Milano, Milan, Italy","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","277","286","Performance estimation is a key step in the development of an embedded system. Normally, the performance evaluation is performed using a simulator or a performance mathematical model of the target architecture. However, both these approaches are usually based on the knowledge of the architectural details of the target. In this paper we present a methodology for automatically building an analytical model to estimate the performance of an application on a generic processor without requiring any information about the processor architecture but the one provided by the GNU GCC Intermediate Representation. The proposed methodology exploits the linear regression technique based on an application analysis performed on the Register Transfer Level internal representation of the GNU GCC compiler. The benefits of working with this type of model and with this intermediate representation are three: we take into account most of the compiler optimizations, we implicitly consider some architectural characteristics of the target processor and we can easily estimate the performance of portions of the specification. We validate our approach by evaluating with cross-validation technique the accuracy and the generality of the performance models built for the ARM926EJ-S and the LEON3 processors.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751512","GNU GCC;Performance Estimation;profiling","Analytical models;Assembly;Estimation;Feature extraction;Linear regression;Numerical models;Optimization","embedded systems;multiprocessing systems;program compilers;regression analysis","ARM926EJ-S;GNU GCC intermediate representation;LEON3 processors;cross-validation technique;embedded system;generic processor;linear regression technique;performance estimation;performance evaluation;performance mathematical model;processor architecture;register transfer level internal representation;zero architectural knowledge","","0","","25","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Power aware SID-based simulator for embedded multicore DSP subsystems","Cheng-Yen Lin; Po-Yu Chen; Chun-Kai Tseng; Chung-Wen Huang; Chia-Chieh Weng; Chi-Bang Kuan; Shih-Han Lin; Shi-Yu Huang; Jenq-Kuen Lee","Nat. Tsing-Hua Univ., Hsinchu, Taiwan","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","95","103","The embedded multicore DSP systems are playing increasingly important role for consumer electronic design. Such systems try to optimize the objective for both performance and power with mobile devices. Embedded application developers will then devise designs to optimize embedded applications for not only performance but also power. However, currently there are no power metrics support for popular application design platforms such as QEMU and SID, where application developers develop their applications. This hinders application developers to help tune optimizations for power. In this paper, we propose a power aware simulation framework on embedded multicore DSP subsystems for SID framework. To the best of our knowledge, this is the first work to attempt to build a power aware simulator based on SID simulation framework. The power estimation flow includes two phases, IP level power modeling and system level power power profiling. In the IP level power modeling, PowerMixer<sup>IP</sup> is employed to build up the power model for PAC DSP and major IPs. In the system level power profiling, we provide a power profiling hierarchy that meets the demand of embedded software developers. The granularity of power profiling can be configured to the whole simulation stage or any specific time slot in the simulation such as a dedicated function loop. In our experiments, DSP programs with SIMD intrinsics for DSPStone benchmark are examined with our proposed power aware simulator. In addition, a face detection application is deployed as a running example on multi-core DSP systems to show how our power simulator can be used to help collaborate with developers in the optimization process to illustrate views of power dissipations of applications.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751529","DSP;Embedded Processor;Multicore Simulation;Power","Artificial neural networks;Digital signal processing;Multicore processing;Random access memory;Switches","consumer electronics;digital signal processing chips;embedded systems;logic design;logic simulation;mobile computing;multiprocessing systems;parallel processing;power aware computing","DSPStone benchmark;IP level power modeling;PAC DSP;PowerMixer7;SIMD;consumer electronic design;embedded application optimize;embedded multicore DSP subsystem;embedded software developer;mobile device;power aware SID-based simulator;power aware simulation framework;power estimation flow;power profiling hierarchy;system level power profiling","","0","","31","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Automatic Memory Partitioning: Increasing memory parallelism via data structure partitioning","Ben Asher, Y.; Rotem, N.","Comput. Sci. Dept., Haifa Univ., Haifa, Israel","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","155","161","In high-level synthesis, pipelined designs are often restricted by the number of memory banks available to the synthesis system. Using multiple memory banks can improve the performance of accelerated applications. Currently, programmers must manually assign data structures to specific memory banks on the accelerator. This paper presents Automatic Memory Partitioning, a method for automatically partitioning data structures into multiple memory banks for increased parallelism and performance. We use source code instrumentation to collect memory traces in order to detect linear memory access patterns. The memory traces are used to split data structures into disjoint memory regions and determine which segments may benefit from parallel memory access. Experiments show significant improvements in performance while using a minimal number of memory banks.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751495","FPGA;Memory;Parallelism","Arrays;Color;Field programmable gate arrays;Hardware;Instruments;Resource management","data structures;high level synthesis;logic partitioning;parallel memories","automatic memory partitioning;data structure partitioning;high level synthesis;memory parallelism;multiple memory bank;parallel memory access","","2","","24","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"An elastic software cache with fast prefetching for Motion Compensation in video decoding","Ping Chao; Youn-Long Lin","Dept. of Comput. Sci., Nat. Tsing Hua Univ., Hsinchu, Taiwan","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","23","32","Real-time decoding of ultrahigh resolution video using multicore architectures is important for future embedded systems. However, memory bandwidth is still a bottleneck of system performance. Video coding performs irregular DRAM access resulting in very low and unstable efficiency. The conventional cache approach is insufficient because it reduces only the redundant accesses to data that has already been fetched during prior-macroblock decoding. We present an Elastic Software Cache (ESC) for ultrahigh resolution video decoding on Scratchpad Memory (SPM)-based systems. Utilizing access region analysis, our latency-optimized prefetching scheme rearranges accesses to minimize both data redundancy and DRAM access latency. Compared to the conventional cache approach, our scheme requires only 4.6 Kbytes of SPM space but it can save up to 25% of memory access cycles resulting in both higher performance and lower power.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751507","H.264/AVC;Memory Access Optimization;Motion Compensation;Software Cache;Video Decoding","Bandwidth;Decoding;Merging;Motion segmentation;Prefetching;Random access memory","DRAM chips;cache storage;embedded systems;motion compensation;multiprocessing systems;optimisation;video coding","DRAM access;elastic software cache;embedded systems;memory access cycles;memory access optimization;memory bandwidth;motion compensation;multicore architectures;prefetching;prior-macroblock decoding;scratchpad memory;video decoding","","0","","11","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"parSC: Synchronous parallel SystemC simulation on multi-core host architectures","Schumacher, C.; Leupers, R.; Petras, D.; Hoffmann, A.","Inst. for Integrated Signal Process. Syst., RWTH Aachen Univ., Aachen, Germany","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","241","246","Time-consuming cycle-accurate MPSoC simulation is often needed for debugging and verification. Its practicability is put at risk by the growing MPSoC complexity. This work presents a conservative synchronous parallel simulation approach along with a SystemC framework to accelerate tightly-coupled MPSoC simulations on multi-core hosts. Key contribution is the implementation strategy, which utilizes techniques from the high-performance computing domain. Results show speed-ups of up to 4.4 on four host cores.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751508","Experimentation;Measurement;Performance","Computational modeling;Data models;Kernel;Load modeling;Logic gates;Prefetching;Synchronization","computer debugging;multiprocessing systems;network interfaces;parallel architectures;system-on-chip","MPSoC complexity;high performance computing domain;multicore host architectures;multicore host core;synchronous parallel systemC simulation;tightly coupled MPSoC simulation;time consuming cycle accurate MPSoC simulation","","10","","19","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"A case for lifetime-aware task mapping in embedded chip multiprocessors","Hartman, A.S.; Thomas, D.E.; Meyer, B.H.","Dept. of Electr. & Comput. Eng., Carnegie Mellon Univ., Pittsburgh, PA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","145","154","Temperature-aware design is emerging as a popular approach to addressing a variety of challenges, including system lifetime. In the case of task mapping, temperature-aware approaches indeed improve lifetime due to lifetime's strong dependence on tempera-ture. However, temperature-aware design neglects several important factors that also influence lifetime: (a) physical parameters such as supply voltage and current density, as well as (b) application and architecture characteristics that affect what failures are survivable. Only lifetime-aware task mapping can expose the relationship between physical parameters, component failure, and system lifetime, and therefore find lifetime-optimal mappings. To address this need, we have developed a new lifetime-aware task mapping technique based on ant colony optimization (ACO). Our technique produces task mappings resulting in lifetimes with-in 17.9% of the observed optimal results on average, outperform-ing a lifetime-agnostic task mapping approach by an average of 32.3%. We also observed that the lifetimes resulting from task mappings within 1% of the best maximum system temperature vary by an average of 20.1% while the lifetimes resulting from task mappings within 1% of the best average system temperature vary by an average of 32.6%. Our observations lead us to conclude that one cannot depend on temperature-aware task mapping when system lifetime is a design constraint, but one may depend on lifetime-aware task mapping when one or both of lifetime and temperature are design constraints.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751494","Task mapping;ant colony optimization;lifetime-aware;temperature-aware","Equations;Failure analysis;Mathematical model;Optimization;Program processors;Temperature dependence;Temperature distribution","integrated circuit reliability;microprocessor chips;optimisation;power aware computing","ant colony optimization;current density;embedded chip multiprocessors;lifetime-agnostic task mapping;lifetime-aware task mapping technique;lifetime-optimal mappings;supply voltage;system lifetime;task mapping;temperature-aware design","","0","","25","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Worst-case performance analysis of Synchronous Dataflow scenarios","Geilen, M.; Stuijk, S.","Eindhoven Univ. of Technol., Den Dolech, Netherlands","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","125","134","Synchronous Dataflow (SDF) is a powerful analysis tool for regular, cyclic, parallel task graphs. The behaviour of SDF graphs however is static and therefore not always able to accurately capture the behaviour of modern, dynamic dataflow applications, such as embedded multimedia codecs. An approach to tackle this limitation is by means of scenarios. In this paper we introduce a technique and a tool to automatically analyse a scenario-aware dataflow model for its worst-case performance. A system is specified as a collection of SDF graphs representing individual scenarios of behaviour and a finite state machine that specifies the possible orders of scenario occurrences. This combination accurately captures more dynamic applications and this way provides tighter results than an existing analysis based on a conservative static dataflow model, which is too pessimistic, while looking only at the `worst-case' individual scenario, without considering scenario transitions, can be too optimistic. We introduce a formal semantics of the model, in terms of (max; +) linear system-theory and in particular (max; +) automata. Leveraging existing results and algorithms from this domain, we give throughput analysis and state space generation algorithms for worst-case performance analysis. The method is implemented in a tool and the effectiveness of the approach is experimentally evaluated.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751491","(max; +) algebra;Synchronous Data Flow;worst-case performance analysis","","computational complexity;data analysis;data flow analysis;data flow graphs;finite state machines","SDF graph;embedded multimedia codecs;finite state machine;formal semantics;linear system theory;parallel task graph;scenario-aware dataflow model;state space generation algorithm;synchronous dataflow scenario;worst case performance analysis","","3","","29","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Rank based dynamic voltage and frequency scaling for tiled graphics processors","Silpa, B.V.N.; Krishnaiah, G.; Panda, P.R.","Dept. of CSE, IIT Delhi, New Delhi, India","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","3","12","With increasing interest in sophisticated graphics capabilities in mobile systems, energy consumption of graphics hardware is becoming a major design concern in addition to the traditional performance enhancement criteria. Our study of various modern games substantiates the observation that the workload of games varies significantly with time and hence can benefit from dynamic voltage and frequency scaling (DVFS). Since visual quality of graphics applications is highly dependent on the rate at which frames are processed, it is important to devise a DVFS scheme that minimizes deadline misses due to inaccuracies in workload prediction. In this paper, we demonstrate that tiled-graphics renderers exhibit substantial advantages over immediate-mode renderers in obtaining access to frame parameters that help in enhancing the workload estimation accuracy. We also show that, operating at a finer granularity of “tiles” as opposed to “frames” allows early detection and corrective action in case of a mis-prediction. We propose an accurate workload estimation technique and two DVFS schemes: (i) tile-history based DVFS and (ii) tile-rank based DVFS for tiled-rendering architectures. The proposed schemes are demonstrated to be more efficient in terms of power and performance than the frame level DVFS schemes proposed in recent literature. With a system with 8 DVFS levels, our tile-history based DVFS scheme results in 60% improvement in quality (deadline misses) over the frame history based DVFS schemes and gives 58% saving in energy. The more sophisticated tile-rank based scheme achieves 75% improvement in quality over the frame history based DVFS scheme and results in 58% saving in energy. We have also compared the efficiency of the proposed tile-level DVFS schemes with frame-level schemes for different number of DVFS levels, and found that while the frame-level schemes suffer from increasing deadline misses as the frequency levels increase, the im pact on tile-level schemes is negligible. The Energy per Frame-rate for our scheme is the minimum, indicating that it delivers the best performance-energy results.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751521","Dynamic Voltage and Frequency Scaling;Graphics Processor;Low Power;Workload Prediction","Computer architecture;Equations;Graphics;Graphics processing unit;Lead","computer graphic equipment;coprocessors;power aware computing;rendering (computer graphics)","DVFS schemes;energy per frame-rate;rank based dynamic frequency scaling;rank based dynamic voltage scaling;tile-history based DVFS;tile-rank based DVFS;tiled graphics processors;tiled-rendering architectures;workload estimation technique;workload prediction","","2","","19","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"A greedy buffer allocation algorithm for power-aware communication in body sensor networks","Ghasemzadeh, H.; Jafari, R.","Dept. of Electr. Eng., Univ. of Texas at Dallas, Richardson, TX, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","195","204","Monitoring human movements using wireless sensory devices promises to revolutionize the delivery of healthcare services. In spite of their potentials for many application domains, power requirements and wearability have limited the commercialization of these systems. In this paper, we propose a novel approach for optimizing communication energy by reducing inter-node data transmissions. This is accomplished by introducing buffers that limit communication to short bursts, and therefore decrease power usage and simplify the communication. Our buffer allocation is a greedy algorithm that can operate both in a centralized and distributed architecture. We experimentally demonstrate the effectiveness of our power reduction techniques. Our results show that, compared with an unbuffered system, our system achieves more than 30% reduction in energy consumption.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751501","Body Sensor Networks;Buffer Allocation;Collaborative Signal Processing;Communication;Energy","Collaboration;Greedy algorithms;Memory management;Optimization;Resource management;Signal processing;Wireless sensor networks","body sensor networks;data communication;gait analysis;greedy algorithms;health care;patient monitoring;power aware computing","body sensor networks;communication energy optimization;greedy buffer allocation algorithm;healthcare services;human movement monitoring;inter-node data transmissions;power-aware communication;wireless sensory devices","","0","","23","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Dynamic, non-linear cache architecture for power-sensitive mobile processors","Bournoutian, G.; Orailoglu, A.","Univ. of California, San Diego, La Jolla, CA, USA","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","187","194","Today, mobile smartphones are expected to be able to run the same complex, algorithm-heavy, memory-intensive applications that were originally designed and coded for general-purpose processors. All the while, it is also expected that these mobile processors be power-conscientious as well as of minimal area impact. These devices pose unique usage demands of ultra-portability, but also demand an always-on, continuous data access paradigm. As a result, this dichotomy of continuous execution versus long battery life poses a difficult challenge. This paper explores a novel approach to mitigating mobile processor power consumption, with a nonlinear degradation in execution speed. The concept relies on using dynamic application memory behavior to intelligently target adjustments in the cache to significantly reduce overall processor power, taking into account both the dynamic and leakage power footprint of the cache subsystem. The simulation results show a significant reduction in power consumption of approximately 16% to 19%, while only incurring a nominal increase in execution time and area.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751500","","Algorithm design and analysis;Logic gates;Mobile communication;Power demand;Program processors;Registers;Smart phones","cache storage;low-power electronics;memory architecture;microprocessor chips;mobile handsets;power aware computing","continuous data access;dynamic nonlinear cache architecture;general-purpose processor;memory-intensive application;mobile processor power consumption;mobile smart phone;power-sensitive mobile processor;ultra-portability","","0","","20","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"FastFwd: An efficient hardware acceleration technique for trace-driven network-on-chip simulation","Krishnaiah, G.; Silpa, B.V.N.; Panda, P.R.; Kumar, A.","Dept. of CSE, IIT Delhi, New Delhi, India","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","247","256","We present an efficient emulation-based technique to accelerate architecture exploration of networks-on-chip (NoCs). The large design space of NoC along with its growing complexity that results in low simulation speeds on host machines have motivated the need for hardware accelerators for speeding up the simulation. For example, simulation of applications with real life problem sizes could take weeks on a host machine. FPGA acceleration is a promising strategy for speeding up NoC simulations by several orders of magnitude. However, it is required to simulate a few billion network transactions of the application during NoC exploration, and this could still take tens of minutes even with an FPGA-based emulator. With the increasing complexity of architectures and applications, reducing emulation time is a key concern. We propose a technique, FastFwd, to minimize emulation time by efficiently identifying and eliminating redundant cycles during a trace-based NoC simulation. We have studied the implications of the additional FPGA hardware required for implementing our technique. A naïve implementation could lead to poor scalability and increase the required DRAM bandwidth, both of which ultimately impact the emulation speed negatively. We propose a hierarchical controller architecture to resolve the scalability issue, and a compressed representation of traces for mitigating the increased DRAM bandwidth requirement. Our experiments with several benchmarks have shown that the FPGA emulation with our technique reduces the average emulation time by a factor of 2 when compared to a conventional emulation.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751509","FPGA Emulation;Hardware Acceleration;Network-on-Chip;Performance Analysis;Trace-driven Simulation","Acceleration;Benchmark testing;Emulation;Field programmable gate arrays;Hardware;Network topology;Software","field programmable gate arrays;network-on-chip;performance evaluation","DRAM bandwidth;FPGA acceleration;FastFwd;emulation based technique;hardware acceleration technique;hierarchical controller architecture;trace driven network-on-chip simulation","","0","","27","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Embedded tutorial — Compilation techniques for CGRAs: Exploring all parallelization approaches","Vander Aa, T.; Raghavan, P.; Mahlke, S.; De Sutter, B.; Shrivastava, A.; Hannig, F.","Imec, Leuven, Belgium","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","185","186","Coarse-Grained Reconfigurable Array (CGRA) processors accelerate inner loops of applications by exploiting instructionlevel parallelism (ILP) and in some cases also data-level and task-level parallelism (DLP & TLP). The aim of this tutorial is to give insight in CGRA architectures and their compilation techniques to exploit parallelism. These topics will be covered: · Polymorphic pipeline arrays, expanding coarse-grained arrays beyond innermost loops (Scott Mahlke, University of Michigan) · Code-generation for coarse-grained arrays: flexibility and programmer productivity (Bjorn De Sutter, Ghent University) · Memory-aware compilation techniques for CGRAs (Aviral Shrivastava, Arizona State University) · Retargetable Mapping of Loop Programs on Coarse-grained Reconfigurable Arrays (Frank Hannig, University of Erlangen-Nuremberg).","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751499","Design;Performance","Arrays;Parallel processing;Pipelines;Productivity;Software;Streaming media","program compilers;reconfigurable architectures","CGRA architecture;DLP;TLP;coarse grained reconfigurable array processor;code generation;data level parallelism;loop program;memory aware compilation technique;polymorphic pipeline array;task level parallelism","","0","","","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"Author index","","","Hardware/Software Codesign and System Synthesis (CODES+ISSS), 2010 IEEE/ACM/IFIP International Conference on","20110415","2010","","","1","7","The author index contains an entry for each author and coauthor included in the proceedings record.","","978-1-6055-8905-3","","","http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5751487","","","","","","0","","","","","24-29 Oct. 2010","","IEEE","IEEE Conference Publications"
"TPC","Givargis, T.","University of California, Irvine"
"TPC","Donlin, A.","Xilinx, USA"
"TPC","Jerraya, A.","CEA"
"TPC","Vincentelli, A.","University of California, Berkeley"
"TPC","Orailoglu, A.","University of California, San Diego"
"TPC","Gerstlauer, A.","Universtiy of Texas, Austin"
"TPC","Kuehlmann, A.","Cadence"
"TPC","Pimentel, A.","University of Amsterdam"
"TPC","Ross, A.","University of Florida, Gainsville"
"TPC","Shrivastava, A.","Arizona State University"
"TPC","Jantsch, A.","KTH Royal Institute of Technology"
"TPC","Hashimi, B.","University of Southampton"
"TPC","Gebotys, C.","University of Waterloo"
"TPC","Haubelt, C.","University of Erlangen-Nuremberg"
"TPC","Sebeke, C.","Bosch, Germany"
"TPC","Bouganis, C.","Imperial College, London"
"TPC","Gajski, D.","University of California, Irvine"
"TPC","Serpanos, D.","University of Patras"
"TPC","Thomas, D.","Carnegie Mellon University"
"TPC","Sciuto, D.","Politecnico di Milano, Italy"
"TPC","Sha, E.","University of Texas, Dallas"
"TPC","Kock, E.","NXP Semiconductors"
"TPC","Wolf, F.","Volkswagen, Germany"
"TPC","Kurdahi, F.","University of California, Irvine"
"TPC","Fummi, F.","University of Verona"
"TPC","Vahid, F.","University of California, Riverside"
"TPC","Dittmann, G.","IBM"
"TPC","Martin, G.","Tensilica"
"TPC","Tomiyama, H.","Nagoya University"
"TPC","Madsen, J.","Technical University of Denmark"
"TPC","Zhu, J.","University of Toronto"
"TPC","Paul, J.","Virginia Tech"
"TPC","Henkel, J.","Karlsruhe Institute of Technology"
"TPC","Bainbridge, J.","Silistix"
"TPC","Teich, J.","University of Erlangen-Nuremberg"
"TPC","Chatha, K.","Arizona State University"
"TPC","Wakabayashi, K.","NEC, Japan"
"TPC","Goossens, K.","TU Delft"
"TPC","Choi, K.","Seoul National University"
"TPC","Bauer, L.","Karlsruhe Institute of Technology"
"TPC","Pozzi, L.","University of Lugano"
"TPC","Benini, L.","University of Bologna"
"TPC","Lavagno, L.","Cadence"
"TPC","Carro, L.","UFRGS, Brazil"
"TPC","Wolf, M.","Georgia Tech"
"TPC","Palesi, M.","University of Catania"
"TPC","Miranda, M.","IMEC"
"TPC","Saito, M.","Toshiba"
"TPC","Chang, N.","Seoul National University"
"TPC","Jha, N.","Princeton University"
"TPC","Bringmann, O.","FZI Karlsruhe"
"TPC","Chou, P.","University of California, Irvine"
"TPC","Hsiung, P.","National Chung Cheng University"
"TPC","Pop, P.","Technical University of Denmark"
"TPC","Kjeldsberg, P.","Norwegian University of Science and Technology"
"TPC","Gron, P.","ARM"
"TPC","Marwedel, P.","TU Dortmund"
"TPC","Eles, P.","Linkoping University"
"TPC","Mishra, P.","University of Florida"
"TPC","Panda, P.","Indian Institute of Technology, Delhi"
"TPC","Marculescu, R.","Carnegie Mellon University"
"TPC","Doerner, R.","University of California, Irvine"
"TPC","Gupta, R.","University of California, San Diego"
"TPC","Bergamaschi, R.","Odysci"
"TPC","Dick, R.","University of Michigan, Ann Arbor"
"TPC","Walker, R.","Kent State University"
"TPC","Ernst, R.","TU Braunschweig"
"TPC","Hermida, R.","University of Madrid"
"TPC","Lysecky, R.","University of Arizona"
"TPC","Chakraborty, S.","TU Munich"
"TPC","Mahlke, S.","University of Michigan, Ann Arbor"
"TPC","Ha, S.","Seoul National University"
"TPC","Parameswaran, S.","University of New South Wales"
"TPC","Edwards, S.","Columbia University"
"TPC","Banerjee, S.","University of California, Irvine"
"TPC","Pasricha, S.","Colorado State University"
"TPC","Yoo, S.","Pohang University of Science and Technology"
"TPC","Kim, T.","Seoul National University"
"TPC","Kogel, T.","CoWare"
"TPC","Stefanov, T.","Leiden University"
"TPC","Jeremiassen, T.","Texas Instruments"
"TPC","Mooney, V.","Georgia Tech"
"TPC","Kruijtzer, W.","Virage Logic"
"TPC","Ecker, W.","Irifineon"
"TPC","Hu, X.","University of Notre Dame"
"TPC","Watanabe, Y.","Cadence"
"TPC","Lin, Y.","National Tsing Hua University"
"TPC","Xie, Y.","Pennsylvania State University"
"TPC","Nakamura, Y.","Kyoto University"
"TPC","Lu, Y.","Purdue University "